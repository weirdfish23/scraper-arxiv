title,author,abstractstract,main_subject,other_subjects,submission_date
Multi-adjoint concept lattices via quantaloid-enriched categories,"Hongliang Lai, Lili Shen","With quantaloids carefully constructed from multi-adjoint frames, it is shown
that multi-adjoint concept lattices, multi-adjoint property-oriented concept
lattices and multi-adjoint object-oriented concept lattices are derivable from
Isbell adjunctions, Kan adjunctions and dual Kan adjunctions between
quantaloid-enriched categories, respectively.",Logic in Computer Science (cs.LO),; Category Theory (math.CT),"[Submitted on 21 Mar 2019 (v1), last revised 11 Mar 2020 (this version, v2)]"
Learning with Batch-wise Optimal Transport Loss for 3D Shape Recognition,"Lin Xu, Han Sun, Yuai Liu","Deep metric learning is essential for visual recognition. The widely used
pair-wise (or triplet) based loss objectives cannot make full use of semantical
information in training samples or give enough attention to those hard samples
during optimization. Thus, they often suffer from a slow convergence rate and
inferior performance. In this paper, we show how to learn an importance-driven
distance metric via optimal transport programming from batches of samples. It
can automatically emphasize hard examples and lead to significant improvements
in convergence. We propose a new batch-wise optimal transport loss and combine
it in an end-to-end deep metric learning manner. We use it to learn the
distance metric and deep feature representation jointly for recognition.
Empirical results on visual retrieval and classification tasks with six
benchmark datasets, i.e., MNIST, CIFAR10, SHREC13, SHREC14, ModelNet10, and
ModelNet40, demonstrate the superiority of the proposed method. It can
accelerate the convergence rate significantly while achieving a
state-of-the-art recognition performance. For example, in 3D shape recognition
experiments, we show that our method can achieve better recognition performance
within only 5 epochs than what can be obtained by mainstream 3D shape
recognition approaches after 200 epochs.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 21 Mar 2019]
Smart Radio Environments Empowered by AI Reconfigurable Meta-Surfaces: An Idea Whose Time Has Come,"Marco Di Renzo, Merouane Debbah, Dinh-Thuy Phan-Huy, Alessio Zappone, Mohamed-Slim Alouini, Chau Yuen, Vincenzo Sciancalepore, George C. Alexandropoulos, Jakob Hoydis, Haris Gacanin, Julien de Rosny, Ahcene Bounceu, Geoffroy Lerosey, Mathias Fink","Future wireless networks are expected to constitute a distributed intelligent
wireless communications, sensing, and computing platform, which will have the
challenging requirement of interconnecting the physical and digital worlds in a
seamless and sustainable manner.
Currently, two main factors prevent wireless network operators from building
such networks: 1) the lack of control of the wireless environment, whose impact
on the radio waves cannot be customized, and 2) the current operation of
wireless radios, which consume a lot of power because new signals are generated
whenever data has to be transmitted.
In this paper, we challenge the usual ""more data needs more power and
emission of radio waves"" status quo, and motivate that future wireless networks
necessitate a smart radio environment: A transformative wireless concept, where
the environmental objects are coated with artificial thin films of
electromagnetic and reconfigurable material (that are referred to as
intelligent reconfigurable meta-surfaces), which are capable of sensing the
environment and of applying customized transformations to the radio waves.
Smart radio environments have the potential to provide future wireless networks
with uninterrupted wireless connectivity, and with the capability of
transmitting data without generating new signals but recycling existing radio
waves.
This paper overviews the current research efforts on smart radio
environments, the enabling technologies to realize them in practice, the need
of new communication-theoretic models for their analysis and design, and the
long-term and open research issues to be solved towards their massive
deployment. In a nutshell, this paper is focused on discussing how the
availability of intelligent reconfigurable meta-surfaces will allow wireless
network operators to redesign common and well-known network communication
paradigms.",Information Theory (cs.IT),,[Submitted on 21 Mar 2019]
Solving the Steiner Tree Problem in Graphs using Physarum-inspired Algorithms,Yahui Sun,"Some biological experiments show that the tubular structures of Physarum
polycephalum are often analogous to those of Steiner trees. Therefore, the
emerging Physarum-inspired Algorithms (PAs) have the potential of computing
Steiner trees. In this paper, we propose two PAs to solve the Steiner Tree
Problem in Graphs (STPG). We apply some widely-used artificial and real-world
VLSI design instances to evaluate the performance of our PAs. The experimental
results show that: 1) for instances with hundreds of vertices, our first PA can
find feasible solutions with an average error of 0.19%, while the Genetic
Algorithm (GA), the Discrete Particle Swarm Optimization (DPSO) algorithm and a
widely-used Steiner tree approximation algorithm: the Shortest Path Heuristic
(SPH) algorithm can only find feasible solutions with an average error above
4.96%; and 2) for larger instances with up to tens of thousands of vertices,
where our first PA, GA and DPSO are too slow to be used, our second PA can find
feasible solutions with an average error of 3.69%, while SPH can only find
feasible solutions with an average error of 6.42%. These experimental results
indicate that PAs can compute Steiner trees, and it may be preferable to apply
our PAs to solve STPG in some cases.",Emerging Technologies (cs.ET),,"[Submitted on 21 Mar 2019 (v1), last revised 6 Apr 2019 (this version, v2)]"
Mediating role of managing information technology and its impact on firm performance: insight from China,"Aboobucker Ilmudeen, Yukun Bao","Purpose: Managing IT with firm performance has always been a debatable topic
in literature and practice. Prior studies examining the above relationship have
reported mixed results and have yet ignored the eminent managing IT practices.
The purpose of this paper is to empirically investigate the relevance of ValIT
2.0 practice in managing IT investment, and its mediating role in the firm
performance context. Design,methodology,approach:This paper developed on two
themes of literature. First managing IT as a firm's IT capability in order to
generate value from IT investment. Second IT as a firm's resource under
resource-based view offers firm's competence that deploys potentials in
achieving firm performance. The structural equation modeling with PLS
techniques used for analyzing data collected from 176 organization's IT, and
business executives in China. Findings: The results of this study show
empirical evidence that Val-IT's components (value governance, portfolio
management, and investment management) are significantly linked to the
management of IT, and it found to be a significant mediator between Val-IT
components and firm performance. Research implications: This research
contributes to the literature and practice by way of highlighting the value
generation through managing IT on firm performance. Originality: This study is
fully based on ValIT 2.0 with the firm performance where the managing IT
mediate this relationship in a country-specific study in China. This study adds
to the Chinese information system literature which suffers the lack of
empirical studies in the context of management of IT research.",Computers and Society (cs.CY),,[Submitted on 21 Mar 2019]
An empirical analysis of exact algorithms for the unbounded knapsack problem,"Henrique Becker, Luciana S. Buriol","This work presents an empirical analysis of exact algorithms for the
unbounded knapsack problem, which includes seven algorithms from the
literature, two commercial solvers, and more than ten thousand instances. The
terminating step-off, a dynamic programming algorithm from 1966, presented the
lowest mean time to solve the most recent benchmark from the literature. The
threshold and collective dominances are properties of the unbounded knapsack
problem first discussed in 1998, and exploited by the current state-of-the-art
algorithms. The terminating step-off algorithm did not exploit such dominances,
but has an alternative mechanism for dealing with dominances which does not
explicitly exploits collective and threshold dominances. Also, the pricing
subproblems found when solving hard cutting stock problems with column
generation can cause branch-and-bound algorithms to display worst-case times.
The authors present a new class of instances which favors the branch-and-bound
approach over the dynamic programming approach but do not have high amounts of
simple, multiple and collective dominated items. This behaviour illustrates how
the definition of hard instances changes among algorithm approachs. The codes
used for solving the unbounded knapsack problem and for instance generation are
all available online.",Data Structures and Algorithms (cs.DS),,[Submitted on 21 Mar 2019]
Dynamic Power Management for Neuromorphic Many-Core Systems,"Sebastian Hoeppner, Bernhard Vogginger, Yexin Yan, Andreas Dixius, Stefan Scholze, Johannes Partzsch, Felix Neumaerker, Stephan Hartmann, Stefan Schiefer, Georg Ellguth, Love Cederstroem, Luis Plana, Jim Garside, Steve Furber, Christian Mayr","This work presents a dynamic power management architecture for neuromorphic
many core systems such as SpiNNaker. A fast dynamic voltage and frequency
scaling (DVFS) technique is presented which allows the processing elements (PE)
to change their supply voltage and clock frequency individually and
autonomously within less than 100 ns. This is employed by the neuromorphic
simulation software flow, which defines the performance level (PL) of the PE
based on the actual workload within each simulation cycle. A test chip in 28 nm
SLP CMOS technology has been implemented. It includes 4 PEs which can be scaled
from 0.7 V to 1.0 V with frequencies from 125 MHz to 500 MHz at three distinct
PLs. By measurement of three neuromorphic benchmarks it is shown that the total
PE power consumption can be reduced by 75%, with 80% baseline power reduction
and a 50% reduction of energy per neuron and synapse computation, all while
maintaining temporary peak system performance to achieve biological real-time
operation of the system. A numerical model of this power management model is
derived which allows DVFS architecture exploration for neuromorphics. The
proposed technique is to be used for the second generation SpiNNaker
neuromorphic many core system.",Neural and Evolutionary Computing (cs.NE),,[Submitted on 21 Mar 2019]
Biasing MCTS with Features for General Games,"Dennis J. N. J. Soemers, Éric Piette, Cameron Browne","This paper proposes using a linear function approximator, rather than a deep
neural network (DNN), to bias a Monte Carlo tree search (MCTS) player for
general games. This is unlikely to match the potential raw playing strength of
DNNs, but has advantages in terms of generality, interpretability and resources
(time and hardware) required for training. Features describing local patterns
are used as inputs. The features are formulated in such a way that they are
easily interpretable and applicable to a wide range of general games, and might
encode simple local strategies. We gradually create new features during the
same self-play training process used to learn feature weights. We evaluate the
playing strength of an MCTS player biased by learnt features against a standard
upper confidence bounds for trees (UCT) player in multiple different board
games, and demonstrate significantly improved playing strength in the majority
of them after a small number of self-play training games.",Artificial Intelligence (cs.AI),; Machine Learning (stat.ML),[Submitted on 21 Mar 2019]
The CASE Dataset of Candidate Spaces for Advert Implantation,"Soumyabrata Dev, Murhaf Hossari, Matthew Nicholson, Killian McCabe, Atul Nautiyal, Clare Conran, Jian Tang, Wei Xu, François Pitié","With the advent of faster internet services and growth of multimedia content,
we observe a massive growth in the number of online videos. The users generate
these video contents at an unprecedented rate, owing to the use of smart-phones
and other hand-held video capturing devices. This creates immense potential for
the advertising and marketing agencies to create personalized content for the
users. In this paper, we attempt to assist the video editors to generate
augmented video content, by proposing candidate spaces in video frames. We
propose and release a large-scale dataset of outdoor scenes, along with
manually annotated maps for candidate spaces. We also benchmark several
deep-learning based semantic segmentation algorithms on this proposed dataset.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 29 Apr 2019 (this version, v2)]"
Iteratively Learning Embeddings and Rules for Knowledge Graph Reasoning,"Wen Zhang, Bibek Paudel, Liang Wang, Jiaoyan Chen, Hai Zhu, Wei Zhang, Abraham Bernstein, Huajun Chen","Reasoning is essential for the development of large knowledge graphs,
especially for completion, which aims to infer new triples based on existing
ones. Both rules and embeddings can be used for knowledge graph reasoning and
they have their own advantages and difficulties. Rule-based reasoning is
accurate and explainable but rule learning with searching over the graph always
suffers from efficiency due to huge search space. Embedding-based reasoning is
more scalable and efficient as the reasoning is conducted via computation
between embeddings, but it has difficulty learning good representations for
sparse entities because a good embedding relies heavily on data richness. Based
on this observation, in this paper we explore how embedding and rule learning
can be combined together and complement each other's difficulties with their
advantages. We propose a novel framework IterE iteratively learning embeddings
and rules, in which rules are learned from embeddings with proper pruning
strategy and embeddings are learned from existing triples and new triples
inferred by rules. Evaluations on embedding qualities of IterE show that rules
help improve the quality of sparse entity embeddings and their link prediction
results. We also evaluate the efficiency of rule learning and quality of rules
from IterE compared with AMIE+, showing that IterE is capable of generating
high quality rules more efficiently. Experiments show that iteratively learning
embeddings and rules benefit each other during learning and prediction.",Artificial Intelligence (cs.AI),; Computation and Language (cs.CL),[Submitted on 21 Mar 2019]
Improving Machine Hearing on Limited Data Sets,"Pavol Harar, Roswitha Bammer, Anna Breger, Monika Dörfler, Zdenek Smekal","Convolutional neural network (CNN) architectures have originated and
revolutionized machine learning for images. In order to take advantage of CNNs
in predictive modeling with audio data, standard FFT-based signal processing
methods are often applied to convert the raw audio waveforms into an image-like
representations (e.g. spectrograms). Even though conventional images and
spectrograms differ in their feature properties, this kind of pre-processing
reduces the amount of training data necessary for successful training. In this
contribution we investigate how input and target representations interplay with
the amount of available training data in a music information retrieval setting.
We compare the standard mel-spectrogram inputs with a newly proposed
representation, called Mel scattering. Furthermore, we investigate the impact
of additional target data representations by using an augmented target loss
function which incorporates unused available information. We observe that all
proposed methods outperform the standard mel-transform representation when
using a limited data set and discuss their strengths and limitations. The
source code for reproducibility of our experiments as well as intermediate
results and model checkpoints are available in an online repository.",Sound (cs.SD),; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP); Machine Learning (stat.ML),"[Submitted on 21 Mar 2019 (v1), last revised 12 Jul 2019 (this version, v3)]"
Learning Multi-Level Information for Dialogue Response Selection by Highway Recurrent Transformer,"Ting-Rui Chiang, Chao-Wei Huang, Shang-Yu Su, Yun-Nung Chen","With the increasing research interest in dialogue response generation, there
is an emerging branch formulating this task as selecting next sentences, where
given the partial dialogue contexts, the goal is to determine the most probable
next sentence. Following the recent success of the Transformer model, this
paper proposes (1) a new variant of attention mechanism based on multi-head
attention, called highway attention, and (2) a recurrent model based on
transformer and the proposed highway attention, so-called Highway Recurrent
Transformer. Experiments on the response selection task in the seventh Dialog
System Technology Challenge (DSTC7) show the capability of the proposed model
of modeling both utterance-level and dialogue-level information; the
effectiveness of each module is further analyzed as well.",Computation and Language (cs.CL),,[Submitted on 21 Mar 2019]
Distributed State Estimation for AC Power Systems using Gauss-Newton ALADIN,"Xu Du, Alexander Engelmann, Yuning Jiang, Timm Faulwasser, Boris Houska","This paper proposes a structure exploiting algorithm for solving non-convex
power system state estimation problems in distributed fashion. Because the
power flow equations in large electrical grid networks are non-convex equality
constraints, we develop a tailored state estimator based on Augmented
Lagrangian Alternating Direction Inexact Newton (ALADIN) method, which can
handle the nonlinearities efficiently. Here, our focus is on using Gauss-Newton
Hessian approximations within ALADIN in order to arrive at at an efficient
(computationally and communicationally) variant of ALADIN for network maximum
likelihood estimation problems. Analyzing the IEEE 30-Bus system we illustrate
how the proposed algorithm can be used to solve highly non-trivial network
state estimation problems. We also compare the method with existing distributed
parameter estimation codes in order to illustrate its performance.",Systems and Control (eess.SY),; Optimization and Control (math.OC),[Submitted on 21 Mar 2019]
Short-Term Prediction and Multi-Camera Fusion on Semantic Grids,"Lukas Hoyer, Patrick Kesper, Anna Khoreva, Volker Fischer","An environment representation (ER) is a substantial part of every autonomous
system. It introduces a common interface between perception and other system
components, such as decision making, and allows downstream algorithms to deal
with abstracted data without knowledge of the used sensor. In this work, we
propose and evaluate a novel architecture that generates an egocentric,
grid-based, predictive, and semantically-interpretable ER. In particular, we
provide a proof of concept for the spatio-temporal fusion of multiple camera
sequences and short-term prediction in such an ER. Our design utilizes a strong
semantic segmentation network together with depth and egomotion estimates to
first extract semantic information from multiple camera streams and then
transform these separately into egocentric temporally-aligned bird's-eye view
grids. A deep encoder-decoder network is trained to fuse a stack of these grids
into a unified semantic grid representation and to predict the dynamics of its
surrounding. We evaluate this representation on real-world sequences of the
Cityscapes dataset and show that our architecture can make accurate predictions
in complex sensor fusion scenarios and significantly outperforms a model-driven
baseline in a category-based evaluation.",Computer Vision and Pattern Recognition (cs.CV),; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO),"[Submitted on 21 Mar 2019 (v1), last revised 26 Jul 2019 (this version, v2)]"
An Energy-Efficient Resource Management System for a Mobile Ad Hoc Cloud,Sayed Chhattan Shah,"Recently, mobile ad hoc clouds have emerged as a promising technology for
mobile cyber-physical system applications, such as mobile intelligent video
surveillance and smart homes. Resource management plays a key role in
maximizing resource utilization and application performance in mobile ad hoc
clouds. Unlike resource management in traditional distributed computing
systems, such as clouds, resource management in a mobile ad hoc cloud poses
numerous challenges owing to the node mobility, limited battery power, high
latency, and the dynamic network environment. The real-time requirements
associated with mobile cyber-physical system applications make the problem even
more challenging. Currently, existing resource management systems for mobile ad
hoc clouds are not designed to support mobile cyber-physical system
applications and energy-efficient communication between application tasks. In
this paper, we propose a new energy-efficient resource management system for
mobile ad hoc clouds. The proposed system consists of two layers: a network
layer and a middleware layer. The network layer provides ad hoc network and
communication services to the middleware layer and shares the collected
information in order to allow efficient and robust resource management
decisions. It uses (1) a transmission power control mechanism to improve energy
efficiency and network capacity, (2) link lifetimes to reduce communication and
energy consumption costs, and (3) link quality to estimate data transfer times.
The middleware layer is responsible for the discovery, monitoring, migration,
and allocation of resources. It receives application tasks from users and
allocates tasks to nodes on the basis of network and node-level information.","Distributed, Parallel, and Cluster Computing (cs.DC)",,[Submitted on 21 Mar 2019]
Multi-Task Time Series Analysis applied to Drug Response Modelling,"Alex Bird, Christopher K. I. Williams, Christopher Hawthorne","Time series models such as dynamical systems are frequently fitted to a
cohort of data, ignoring variation between individual entities such as
patients. In this paper we show how these models can be personalised to an
individual level while retaining statistical power, via use of multi-task
learning (MTL). To our knowledge this is a novel development of MTL which
applies to time series both with and without control inputs. The modelling
framework is demonstrated on a physiological drug response problem which
results in improved predictive accuracy and uncertainty estimation over
existing state-of-the-art models.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 21 Mar 2019]
HELPER: Heterogeneous Efficient Low Power Radio for Enabling Ad Hoc Emergency Public Safety Networks,"Jithin Jagannath, Sean Furman, Anu Jagannath, Luther Ling, Andrew Burger, Andrew Drozd","Natural and man-made disasters have been causing destruction and distress to
humanity all over the world. In these scenarios, communication infrastructures
are the most affected entities making emergency response operations extremely
challenging. This invokes a need to equip the affected people and the emergency
responders with the ability to rapidly set up and use independent means of
communication. Therefore, in this work, we present a complete end-to-end
solution that can connect survivors of a disaster with each other and the
authorities using a completely self-sufficient ad hoc network that can be setup
rapidly. Accordingly, we develop a Heterogeneous Efficient Low Power Radio
(HELPER) that acts as an access point for end-users to connect using custom
website application. These HELPERs then coordinate with each other to form a
LoRa based ad hoc network. To this end, we propose a novel cross-layer
optimized distributed energy-efficient routing (SEEK) algorithm that aims to
maximize the network lifetime. The HELPER is prototyped using WiFi enabled
Raspberry Pi and LoRa module that is configured to run using Li-ion batteries.
We implement the required cross-layer protocol stack along with the SEEK
routing algorithm. We have conducted demonstrations to establish the
feasibility of exchanging of text messages over the HELPER network, live map
updates, ability to send distress messages to authorities. Emergency responders
can leverage this technology to remotely monitor the connectivity of the
affected area and alert users of imminent dangers. SEEK algorithm was shown to
outperform a greedy geographical routing algorithm implemented on HELPER
testbed by up to 53 % in terms of network lifetime and up to 28 % in terms of
throughput. Overall, we hope this technology will become instrumental in
improving the efficiency and effectiveness of public safety activities.",Networking and Internet Architecture (cs.NI),,[Submitted on 21 Mar 2019]
SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval),"Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, Ritesh Kumar","We present the results and the main findings of SemEval-2019 Task 6 on
Identifying and Categorizing Offensive Language in Social Media (OffensEval).
The task was based on a new dataset, the Offensive Language Identification
Dataset (OLID), which contains over 14,000 English tweets. It featured three
sub-tasks. In sub-task A, the goal was to discriminate between offensive and
non-offensive posts. In sub-task B, the focus was on the type of offensive
content in the post. Finally, in sub-task C, systems had to detect the target
of the offensive posts. OffensEval attracted a large number of participants and
it was one of the most popular tasks in SemEval-2019. In total, about 800 teams
signed up to participate in the task, and 115 of them submitted results, which
we present and analyze in this report.",Computation and Language (cs.CL),,"[Submitted on 19 Mar 2019 (v1), last revised 27 Apr 2019 (this version, v3)]"
Multi-hop Byzantine Reliable Broadcast with Honest Dealer Made Practical,"Silvia Bonomi, Giovanni Farina (NPA), Sébastien Tixeuil (NPA, LINCS)","We revisit Byzantine tolerant reliable broadcast with honest dealer
algorithms in multi-hop networks. To tolerate Byzantine faulty nodes
arbitrarily spread over the network, previous solutions require a factorial
number of messages to be sent over the network if the messages are not
authenticated (e.g. digital signatures are not available). We propose
modifications that preserve the safety and liveness properties of the original
unauthenticated protocols, while highly decreasing their observed message
complexity when simulated on several classes of graph topologies, potentially
opening to their employment.","Distributed, Parallel, and Cluster Computing (cs.DC)",,"[Submitted on 21 Mar 2019 (v1), last revised 12 Sep 2019 (this version, v2)]"
Utilizing Mobile Nodes for Congestion Control in Wireless Sensor Networks,"Antonia Nicolaou, Natalie Temene, Charalampos Sergiou, Chryssis Georgiou, Vasos Vassiliou","Congestion control and avoidance in Wireless Sensor Networks (WSNs) is a
subject that has attracted a lot of research attention in the last decade.
Besides rate and resource control, the utilization of mobile nodes has also
been suggested as a way to control congestion. In this work, we present a
Mobile Congestion Control (MobileCC) algorithm with two variations, to assist
existing congestion control algorithms in facing congestion in WSNs. The first
variation employs mobile nodes that create locally-significant alternative
paths leading to the sink. The second variation employs mobile nodes that
create completely individual (disjoint) paths to the sink. Simulation results
show that both variations can significantly contribute to the alleviation of
congestion in WSNs.",Networking and Internet Architecture (cs.NI),,[Submitted on 21 Mar 2019]
A unified spectra analysis workflow for the assessment of microbial contamination of ready to eat green salads: Comparative study and application of non-invasive sensors,"Panagiotis Tsakanikas, Lemonia Christina Fengou, Evanthia Manthou, Alexandra Lianou, Efstathios Z. Panagou, George John E. Nychas","The present study provides a comparative assessment of non-invasive sensors
as means of estimating the microbial contamination and time-on-shelf (i.e.
storage time) of leafy green vegetables, using a novel unified spectra analysis
workflow. Two fresh ready-to-eat green salads were used in the context of this
study for the purpose of evaluating the efficiency and practical application of
the presented workflow: rocket and baby spinach salads. The employed analysis
workflow consisted of robust data normalization, powerful feature selection
based on random forests regression, and selection of the number of partial
least squares regression coefficients in the training process by estimating the
knee-point on the explained variance plot. Training processes were based on
microbiological and spectral data derived during storage of green salad samples
at isothermal conditions (4, 8 and 12C), whereas testing was performed on data
during storage under dynamic temperature conditions (simulating real-life
temperature fluctuations in the food supply chain). Since an increasing
interest in the use of non-invasive sensors in food quality assessment has been
made evident in recent years, the unified spectra analysis workflow described
herein, by being based on the creation/usage of limited sized featured sets,
could be very useful in food-specific low-cost sensor development.",Machine Learning (cs.LG),; Machine Learning (stat.ML),"[Submitted on 21 Mar 2019 (v1), last revised 26 Mar 2019 (this version, v2)]"
Cylindrical Algebraic Decomposition with Equational Constraints,"Matthew England, Russell Bradford, James H. Davenport","Cylindrical Algebraic Decomposition (CAD) has long been one of the most
important algorithms within Symbolic Computation, as a tool to perform
quantifier elimination in first order logic over the reals. More recently it is
finding prominence in the Satisfiability Checking community as a tool to
identify satisfying solutions of problems in nonlinear real arithmetic.
The original algorithm produces decompositions according to the signs of
polynomials, when what is usually required is a decomposition according to the
truth of a formula containing those polynomials. One approach to achieve that
coarser (but hopefully cheaper) decomposition is to reduce the polynomials
identified in the CAD to reflect a logical structure which reduces the solution
space dimension: the presence of Equational Constraints (ECs).
This paper may act as a tutorial for the use of CAD with ECs: we describe all
necessary background and the current state of the art. In particular, we
present recent work on how McCallum's theory of reduced projection may be
leveraged to make further savings in the lifting phase: both to the polynomials
we lift with and the cells lifted over. We give a new complexity analysis to
demonstrate that the double exponent in the worst case complexity bound for CAD
reduces in line with the number of ECs. We show that the reduction can apply to
both the number of polynomials produced and their degree.",Symbolic Computation (cs.SC),,[Submitted on 20 Mar 2019]
Towards a Forensic Event Ontology to Assist Video Surveillance-based Vandalism Detection,"Faranak Sobhani, Umberto Straccia","The detection and representation of events is a critical element in automated
surveillance systems. We present here an ontology for representing complex
semantic events to assist video surveillance-based vandalism detection. The
ontology contains the definition of a rich and articulated event vocabulary
that is aimed at aiding forensic analysis to objectively identify and represent
complex events. Our ontology has then been applied in the context of London
Riots, which took place in 2011. We report also on the experiments conducted to
support the classification of complex criminal events from video data.",Artificial Intelligence (cs.AI),; Image and Video Processing (eess.IV),[Submitted on 21 Mar 2019]
Localization of Unmanned Aerial Vehicles in Corridor Environments using Deep Learning,"Ram Prasad Padhy, Shahzad Ahmad, Sachin Verma, Pankaj Kumar Sa, Sambit Bakshi","Vision-based pose estimation of Unmanned Aerial Vehicles (UAV) in unknown
environments is a rapidly growing research area in the field of robot vision.
The task becomes more complex when the only available sensor is a static single
camera (monocular vision). In this regard, we propose a monocular vision
assisted localization algorithm, that will help a UAV to navigate safely in
indoor corridor environments. Always, the aim is to navigate the UAV through a
corridor in the forward direction by keeping it at the center with no
orientation either to the left or right side. The algorithm makes use of the
RGB image, captured from the UAV front camera, and passes it through a trained
deep neural network (DNN) to predict the position of the UAV as either on the
left or center or right side of the corridor. Depending upon the divergence of
the UAV with respect to the central bisector line (CBL) of the corridor, a
suitable command is generated to bring the UAV to the center. When the UAV is
at the center of the corridor, a new image is passed through another trained
DNN to predict the orientation of the UAV with respect to the CBL of the
corridor. If the UAV is either left or right tilted, an appropriate command is
generated to rectify the orientation. We also propose a new corridor dataset,
named NITRCorrV1, which contains images as captured by the UAV front camera
when the UAV is at all possible locations of a variety of corridors. An
exhaustive set of experiments in different corridors reveal the efficacy of the
proposed algorithm.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 21 Mar 2019]
Subgraph Networks with Application to Structural Feature Space Expansion,"Qi Xuan, Jinhuan Wang, Minghao Zhao, Junkun Yuan, Chenbo Fu, Zhongyuan Ruan, Guanrong Chen","Real-world networks exhibit prominent hierarchical and modular structures,
with various subgraphs as building blocks. Most existing studies simply
consider distinct subgraphs as motifs and use only their numbers to
characterize the underlying network. Although such statistics can be used to
describe a network model, or even to design some network algorithms, the role
of subgraphs in such applications can be further explored so as to improve the
results. In this paper, the concept of subgraph network (SGN) is introduced and
then applied to network models, with algorithms designed for constructing the
1st-order and 2nd-order SGNs, which can be easily extended to build
higher-order ones. Furthermore, these SGNs are used to expand the structural
feature space of the underlying network, beneficial for network classification.
Numerical experiments demonstrate that the network classification model based
on the structural features of the original network together with the 1st-order
and 2nd-order SGNs always performs the best as compared to the models based
only on one or two of such networks. In other words, the structural features of
SGNs can complement that of the original network for better network
classification, regardless of the feature extraction method used, such as the
handcrafted, network embedding and kernel-based methods.",Social and Information Networks (cs.SI),; Machine Learning (cs.LG),"[Submitted on 21 Mar 2019 (v1), last revised 15 Dec 2019 (this version, v3)]"
Recent advances in conversational NLP : Towards the standardization of Chatbot building,Maali Mnasri,"Dialogue systems have become recently essential in our life. Their use is
getting more and more fluid and easy throughout the time. This boils down to
the improvements made in NLP and AI fields. In this paper, we try to provide an
overview to the current state of the art of dialogue systems, their categories
and the different approaches to build them. We end up with a discussion that
compares all the techniques and analyzes the strengths and weaknesses of each.
Finally, we present an opinion piece suggesting to orientate the research
towards the standardization of dialogue systems building.",Computation and Language (cs.CL),; Artificial Intelligence (cs.AI),[Submitted on 21 Mar 2019]
Bandwidth Extension on Raw Audio via Generative Adversarial Networks,"Sung Kim, Visvesh Sathe","Neural network-based methods have recently demonstrated state-of-the-art
results on image synthesis and super-resolution tasks, in particular by using
variants of generative adversarial networks (GANs) with supervised feature
losses. Nevertheless, previous feature loss formulations rely on the
availability of large auxiliary classifier networks, and labeled datasets that
enable such classifiers to be trained. Furthermore, there has been
comparatively little work to explore the applicability of GAN-based methods to
domains other than images and video. In this work we explore a GAN-based method
for audio processing, and develop a convolutional neural network architecture
to perform audio super-resolution. In addition to several new architectural
building blocks for audio processing, a key component of our approach is the
use of an autoencoder-based loss that enables training in the GAN framework,
with feature losses derived from unlabeled data. We explore the impact of our
architectural choices, and demonstrate significant improvements over previous
works in terms of both objective and perceptual quality.",Sound (cs.SD),; Audio and Speech Processing (eess.AS),[Submitted on 21 Mar 2019]
Generative Models For Deep Learning with Very Scarce Data,"Juan Maroñas, Roberto Paredes, Daniel Ramos","The goal of this paper is to deal with a data scarcity scenario where deep
learning techniques use to fail. We compare the use of two well established
techniques, Restricted Boltzmann Machines and Variational Auto-encoders, as
generative models in order to increase the training set in a classification
framework. Essentially, we rely on Markov Chain Monte Carlo (MCMC) algorithms
for generating new samples. We show that generalization can be improved
comparing this methodology to other state-of-the-art techniques, e.g.
semi-supervised learning with ladder networks. Furthermore, we show that RBM is
better than VAE generating new samples for training a classifier with good
generalization capabilities.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 21 Mar 2019]
Equivariant Entity-Relationship Networks,"Devon Graham, Junhao Wang, Siamak Ravanbakhsh","The relational model is a ubiquitous representation of big-data, in part due
to its extensive use in databases. In this paper, we propose the Equivariant
Entity-Relationship Network (EERN), which is a Multilayer Perceptron
equivariant to the symmetry transformations of the Entity-Relationship model.
To this end, we identify the most expressive family of linear maps that are
exactly equivariant to entity relationship symmetries, and further show that
they subsume recently introduced equivariant maps for sets, exchangeable
tensors, and graphs. The proposed feed-forward layer has linear complexity in
the data and can be used for both inductive and transductive reasoning about
relational databases, including database embedding, and the prediction of
missing records. This provides a principled theoretical foundation for the
application of deep learning to one of the most abundant forms of data.
Empirically, EERN outperforms different variants of coupled matrix tensor
factorization in both synthetic and real-data experiments.",Machine Learning (cs.LG),; Machine Learning (stat.ML),"[Submitted on 21 Mar 2019 (v1), last revised 5 Jun 2020 (this version, v4)]"
Exploiting Promising Sub-Sequences of Jobs to solve the No-Wait Flowshop Scheduling Problem,"Lucien Mousin, Marie-Eléonore Kessaci, Clarisse Dhaenens","The no-wait flowshop scheduling problem is a variant of the classical
permutation flowshop problem, with the additional constraint that jobs have to
be processed by the successive machines without waiting time. To efficiently
address this NP-hard combinatorial optimization problem we conduct an analysis
of the structure of good quality solutions. This analysis shows that the
No-Wait specificity gives them a common structure: they share identical
sub-sequences of jobs, we call super-jobs. After a discussion on the way to
identify these super-jobs, we propose IG-SJ, an algorithm that exploits
super-jobs within the state-of-the-art algorithm for the classical permutation
flowshop, the well-known Iterated Greedy (IG) algorithm. An iterative approach
of IG-SJ is also proposed. Experiments are conducted on Taillard's instances.
The experimental results show that exploiting super-jobs is successful since
IG-SJ is able to find 64 new best solutions.",Artificial Intelligence (cs.AI),,[Submitted on 21 Mar 2019]
Megapixel Photon-Counting Color Imaging using Quanta Image Sensor,"Abhiram Gnanasambandam, Omar Elgendy, Jiaju Ma, and Stanley H. Chan","Quanta Image Sensor (QIS) is a single-photon detector designed for extremely
low light imaging conditions. Majority of the existing QIS prototypes are
monochrome based on single-photon avalanche diodes (SPAD). Passive color
imaging has not been demonstrated with single-photon detectors due to the
intrinsic difficulty of shrinking the pixel size and increasing the spatial
resolution while maintaining acceptable intra-pixel cross-talk. In this paper,
we present image reconstruction of the first color QIS with a resolution of
$1024 \times 1024$ pixels, supporting both single-bit and multi-bit photon
counting capability. Our color image reconstruction is enabled by a customized
joint demosaicing-denoising algorithm, leveraging truncated Poisson statistics
and variance stabilizing transforms. Experimental results of the new sensor and
algorithm demonstrate superior color imaging performance for very low-light
conditions with a mean exposure of as low as a few photons per pixel in both
real and simulated images.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 20 May 2019 (this version, v2)]"
An Optimal Stable Selective Model Inversion for Nonminimum-phase Systems,"Dan Wang, Xu Chen","Stably inverting a dynamic system model is the foundation of numerous servo
designs. Existing inversion techniques have provided accurate model
approximations that are often highly effective in feedforward controls.
However, when the inverse is implemented in a feedback system, additional
considerations are needed for assuring causality, closed-loop stability, and
robustness. In pursuit of bridging the gap between the best model matching and
a robust feedback performance under closed-loop constraints, this paper
provides a modern review of frequency-domain model inversion techniques and a
new treatment of unstable zeros. We provide first a pole-zero-map-based
intuitive inverse tuning for motion control systems. Then for general
nonminimum-phase and unstable systems, we propose an optimal inversion
algorithm that can attain model accuracy at the frequency regions of interest
and meanwhile constrain noise amplification elsewhere to guarantee system
robustness. The design goals are achieved by a multi-objective H infinity
formulation and all-pass factorization that consider model matching, causality
of transfer functions, frequency-domain gain constraints, and factorization of
unstable system modes in a unified scheme. The proposed algorithm is validated
on motion control systems and complex high-order systems.",Systems and Control (eess.SY),,"[Submitted on 21 Mar 2019 (v1), last revised 15 Nov 2019 (this version, v2)]"
An Efficient Solution to Non-Minimal Case Essential Matrix Estimation,Ji Zhao,"Finding relative pose between two calibrated images is a fundamental task in
computer vision. Given five point correspondences, the classical five-point
methods can be used to calculate the essential matrix efficiently. For the case
of $N$ ($N > 5$) inlier point correspondences, which is called $N$-point
problem, existing methods are either inefficient or prone to local minima. In
this paper, we propose a certifiably globally optimal and efficient solver for
the $N$-point problem. First we formulate the problem as a quadratically
constrained quadratic program (QCQP). Then a certifiably globally optimal
solution to this problem is obtained by semidefinite relaxation. This allows us
to obtain certifiably globally optimal solutions to the original non-convex
QCQPs in polynomial time. The theoretical guarantees of the semidefinite
relaxation are also provided, including tightness and local stability. To deal
with outliers, we propose a robust $N$-point method using M-estimators. Though
global optimality cannot be guaranteed for the overall robust framework, the
proposed robust $N$-point method can achieve good performance when the outlier
ratio is not high. Extensive experiments on synthetic and real-world datasets
demonstrated that our $N$-point method is $2\sim3$ orders of magnitude faster
than state-of-the-art methods. Moreover, our robust $N$-point method
outperforms state-of-the-art methods in terms of robustness and accuracy.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 7 Oct 2020 (this version, v3)]"
Quotienting Impertinent Camera Kinematics for 3D Video Stabilization,"Thomas W. Mitchel, Christian Wuelker, Jin Seob Kim, Sipu Ruan, Gregory S. Chirikjian","With the recent advent of methods that allow for real-time computation, dense
3D flows have become a viable basis for fast camera motion estimation. Most
importantly, dense flows are more robust than the sparse feature matching
techniques used by existing 3D stabilization methods, able to better handle
large camera displacements and occlusions similar to those often found in
consumer videos. Here we introduce a framework for 3D video stabilization that
relies on dense scene flow alone. The foundation of this approach is a novel
camera motion model that allows for real-world camera poses to be recovered
directly from 3D motion fields. Moreover, this model can be extended to
describe certain types of non-rigid artifacts that are commonly found in
videos, such as those resulting from zooms. This framework gives rise to
several robust regimes that produce high-quality stabilization of the kind
achieved by prior full 3D methods while avoiding the fragility typically
present in feature-based approaches. As an added benefit, our framework is
fast: the simplicity of our motion model and efficient flow calculations
combine to enable stabilization at a high frame rate.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 5 Aug 2019 (this version, v2)]"
Principal Component Analysis Based Broadband Hybrid Precoding for Millimeter-Wave Massive MIMO Systems,"Yiwei Sun, Zhen Gao, Hua Wang, Byonghyo Shim, Guan Gui, Guoqiang Mao, Fumiyuki Adachi","Hybrid analog-digital precoding is challenging for broadband millimeter-wave
(mmWave) massive MIMO systems, since the analog precoder is frequency-flat but
the mmWave channels are frequency-selective. In this paper, we propose a
principal component analysis (PCA)-based broadband hybrid precoder/combiner
design, where both the fully-connected array and partially-connected subarray
(including the fixed and adaptive subarrays) are investigated. Specifically, we
first design the hybrid precoder/combiner for fully-connected array and fixed
subarray based on PCA, whereby a low-dimensional frequency-flat
precoder/combiner is acquired based on the optimal high-dimensional
frequency-selective precoder/combiner. Meanwhile, the near-optimality of our
proposed PCA approach is theoretically proven. Moreover, for the adaptive
subarray, a low-complexity shared agglomerative hierarchical clustering
algorithm is proposed to group the antennas for the further improvement of
spectral efficiency (SE) performance. Besides, we theoretically prove that the
proposed antenna grouping algorithm is only determined by the slow time-varying
channel parameters in the large antenna limit. Simulation results demonstrate
the superiority of the proposed solution over state-of-the-art schemes in SE,
energy efficiency (EE), bit-error-rate performance, and the robustness to
time-varying channels. Our work reveals that the EE advantage of adaptive
subarray over fully-connected array is obvious for both active and passive
antennas, but the EE advantage of fixed subarray only holds for passive
antennas.",Information Theory (cs.IT),; Signal Processing (eess.SP),"[Submitted on 21 Mar 2019 (v1), last revised 11 Jun 2020 (this version, v6)]"
On the Impact of Satellite Communications over Mobile Networks: An Experimental Analysis,"Engin Zeydan, Yekta Turk","Future telecommunication systems are expected to co-exist with different
backhauling nodes such as terrestrial or satellite systems. Satellite
connectivity can add flexibility to backhauling networks and provide an
alternative route for transmission. This paper presents experimental
comparisons of satellite and terrestrial cellular networks and evaluates their
performances in terms of different Key Performance Indicators (KPIs) including
Channel Quality Index (CQI), Modulation Coding Scheme (MCS) index, Downlink
throughput, Frame Utilization (FU) and number of Resource Block (RB)
utilization ratios. Our experimental satellite network system uses a real
satellite backhaul deployment and works in Ka band (with two specific sub-bands
on 19 Ghz in downlink and 29 Ghz in uplink). As a benchmark, we compare our
system with live terrestrial network in which backhaul connection is cellular
backhaul. Our experiments reveal three main observations: First observation is
that there exists FU and number of RB utilization problems in the satellite
link even though there exists a single test user equipment (UE) with high CQI
and MCS index values. Second observation is that in satellite link relatively
low number of Protocol Data Units (PDUs) are generated at Radio Link Controller
(RLC) layer compared to the Packet Data Convergence Control (PDCP) layer.
Finally, our third observation concludes that the excessive existence of PDCP
PDUs can be due to existence of General Packet Radio Service (GPRS) Tunneling
Protocol-User Plane (GTP-U) accelerator where an optimal balance between the
caching size and the number of UEs using satellite eNodeB is needed. For this
reason, our experimental results reveal the existence of a trade-off between
the supported number of users on satellite link and the GTP-U acceleration
rate.",Networking and Internet Architecture (cs.NI),,"[Submitted on 21 Mar 2019 (v1), last revised 13 Nov 2019 (this version, v2)]"
Accurate prediction of melt pool shapes in laser powder bed fusion by the non-linear temperature equation including phase changes - isotropic versus anisotropic conductivity,"Stefan Kollmannsberger, Massimo Carraturo, Alessandro Reali, Ferdinando Auricchio","In this contribution, we validate a physical model based on a transient
temperature equation (including latent heat) w.r.t. the experimental set
AMB2018-02 provided within the additive manufacturing benchmark series,
established at the National Institute of Standards and Technology, USA. We aim
at predicting the following quantities of interest: width, depth, and length of
the melt pool by numerical simulation and report also on the obtainable
numerical results of the cooling rate. We first assume the laser to posses a
double ellipsoidal shape and demonstrate that a well calibrated, purely thermal
model based on isotropic thermal conductivity is able to predict all the
quantities of interest, up to a deviation of maximum 7.3\% from the
experimentally measured values.
However, it is interesting to observe that if we directly introduce, whenever
available, the measured laser profile in the model (instead of the double
ellipsoidal shape) the investigated model returns a deviation of 19.3\% from
the experimental values. This motivates a model update by introducing
anisotropic conductivity, which is intended to be a simplistic model for heat
material convection inside the melt pool. Such an anisotropic model enables the
prediction of all quantities of interest mentioned above with a maximum
deviation from the experimental values of 6.5\%.
We note that, although more predictive, the anisotropic model induces only a
marginal increase in computational complexity.","Computational Engineering, Finance, and Science (cs.CE)",,[Submitted on 21 Mar 2019]
Budget-constrained Edge Service Provisioning with Demand Estimation via Bandit Learning,"Lixing Chen, Jie Xu","Shared edge computing platforms, which enable Application Service Providers
(ASPs) to deploy applications in close proximity to mobile users are providing
ultra-low latency and location-awareness to a rich portfolio of services.
Though ubiquitous edge service provisioning, i.e., deploying the application at
all possible edge sites, is always preferable, it is impractical due to often
limited operational budget of ASPs. In this case, an ASP has to cautiously
decide where to deploy the edge service and how much budget it is willing to
use. A central issue here is that the service demand received by each edge
site, which is the key factor of deploying benefit, is unknown to ASPs a
priori. What's more complicated is that this demand pattern varies temporally
and spatially across geographically distributed edge sites. In this paper, we
investigate an edge resource rental problem where the ASP learns service demand
patterns for individual edge sites while renting computation resource at these
sites to host its applications for edge service provisioning. An online
algorithm, called Context-aware Online Edge Resource Rental (COERR), is
proposed based on the framework of Contextual Combinatorial Multi-armed Bandit
(CC-MAB). COERR observes side-information (context) to learn the demand
patterns of edge sites and decides rental decisions (including where to rent
the computation resource and how much to rent) to maximize ASP's utility given
a limited budget. COERR provides a provable performance achieving sublinear
regret compared to an Oracle algorithm that knows exactly the expected service
demand of edge sites. Experiments are carried out on a real-world dataset and
the results show that COERR significantly outperforms other benchmarks.",Computer Science and Game Theory (cs.GT),,[Submitted on 21 Mar 2019]
Profile-Based Privacy for Locally Private Computations,"Joseph Geumlek, Kamalika Chaudhuri","Differential privacy has emerged as a gold standard in privacy-preserving
data analysis. A popular variant is local differential privacy, where the data
holder is the trusted curator. A major barrier, however, towards a wider
adoption of this model is that it offers a poor privacy-utility tradeoff.
In this work, we address this problem by introducing a new variant of local
privacy called profile-based privacy. The central idea is that the problem
setting comes with a graph G of data generating distributions, whose edges
encode sensitive pairs of distributions that should be made indistinguishable.
This provides higher utility because unlike local differential privacy, we no
longer need to make every pair of private values in the domain
indistinguishable, and instead only protect the identity of the underlying
distribution. We establish privacy properties of the profile-based privacy
definition, such as post-processing invariance and graceful composition.
Finally, we provide mechanisms that are private in this framework, and show via
simulations that they achieve higher utility than the corresponding local
differential privacy mechanisms.",Cryptography and Security (cs.CR),; Machine Learning (cs.LG); Machine Learning (stat.ML),"[Submitted on 21 Jan 2019 (v1), last revised 16 Jun 2019 (this version, v2)]"
On-line Search History-assisted Restart Strategy for Covariance Matrix Adaptation Evolution Strategy,"Yang Lou, Shiu Yin Yuen, Guanrong Chen, Xin Zhang","Restart strategy helps the covariance matrix adaptation evolution strategy
(CMA-ES) to increase the probability of finding the global optimum in
optimization, while a single run CMA-ES is easy to be trapped in local optima.
In this paper, the continuous non-revisiting genetic algorithm (cNrGA) is used
to help CMA-ES to achieve multiple restarts from different sub-regions of the
search space. The CMA-ES with on-line search history-assisted restart strategy
(HR-CMA-ES) is proposed. The entire on-line search history of cNrGA is stored
in a binary space partitioning (BSP) tree, which is effective for performing
local search. The frequently sampled sub-region is reflected by a deep position
in the BSP tree. When leaf nodes are located deeper than a threshold, the
corresponding sub-region is considered a region of interest (ROI). In
HR-CMA-ES, cNrGA is responsible for global exploration and suggesting ROI for
CMA-ES to perform an exploitation within or around the ROI. CMA-ES restarts
independently in each suggested ROI. The non-revisiting mechanism of cNrGA
avoids to suggest the same ROI for a second time. Experimental results on the
CEC 2013 and 2017 benchmark suites show that HR-CMA-ES performs better than
both CMA-ES and cNrGA. A positive synergy is observed by the memetic
cooperation of the two algorithms.",Neural and Evolutionary Computing (cs.NE),,[Submitted on 16 Mar 2019]
Flying through a narrow gap using neural network: an end-to-end planning and control approach,"Jiarong Lin, Luqi Wang, Fei Gao, Shaojie Shen, Fu Zhang","In this paper, we investigate the problem of enabling a drone to fly through
a tilted narrow gap, without a traditional planning and control pipeline. To
this end, we propose an end-to-end policy network, which imitates from the
traditional pipeline and is fine-tuned using reinforcement learning. Unlike
previous works which plan dynamical feasible trajectories using motion
primitives and track the generated trajectory by a geometric controller, our
proposed method is an end-to-end approach which takes the flight scenario as
input and directly outputs thrust-attitude control commands for the quadrotor.
Key contributions of our paper are: 1) presenting an imitate-reinforce training
framework. 2) flying through a narrow gap using an end-to-end policy network,
showing that learning based method can also address the highly dynamic control
problem as the traditional pipeline does (see attached video:
this https URL). 3) propose a robust imitation of
an optimal trajectory generator using multilayer perceptrons. 4) show how
reinforcement learning can improve the performance of imitation learning, and
the potential to achieve higher performance over the model-based method.",Robotics (cs.RO),,"[Submitted on 21 Mar 2019 (v1), last revised 3 Aug 2019 (this version, v2)]"
Learning Personalized Thermal Preferences via Bayesian Active Learning with Unimodality Constraints,"Nimish Awalgaonkar, Ilias Bilionis, Xiaoqi Liu, Panagiota Karava, Athanasios Tzempelikos","Thermal preferences vary from person to person and may change over time. The
main objective of this paper is to sequentially pose intelligent queries to
occupants in order to optimally learn the indoor air temperature values which
maximize their satisfaction. Our central hypothesis is that an occupant's
preference relation over indoor air temperature can be described using a scalar
function of these temperatures, which we call the ""occupant's thermal utility
function"". Information about an occupant's preference over these temperatures
is available to us through their response to thermal preference queries :
""prefer warmer,"" ""prefer cooler"" and ""satisfied"" which we interpret as
statements about the derivative of their utility function, i.e. the utility
function is ""increasing"", ""decreasing"" and ""constant"" respectively. We model
this hidden utility function using a Gaussian process prior with built-in
unimodality constraint, i.e., the utility function has a unique maximum, and we
train this model using Bayesian inference. This permits an expected improvement
based selection of next preference query to pose to the occupant, which takes
into account both exploration (sampling from areas of high uncertainty) and
exploitation (sampling from areas which are likely to offer an improvement over
current best observation). We use this framework to sequentially design
experiments and illustrate its benefits by showing that it requires drastically
fewer observations to learn the maximally preferred temperature values as
compared to other methods. This framework is an important step towards the
development of intelligent HVAC systems which would be able to respond to
occupants' personalized thermal comfort needs. In order to encourage the use of
our PE framework and ensure reproducibility in results, we publish an
implementation of our work named GPPrefElicit as an open-source package in
Python.",Machine Learning (cs.LG),; Human-Computer Interaction (cs.HC); Machine Learning (stat.ML),"[Submitted on 21 Mar 2019 (v1), last revised 1 Apr 2019 (this version, v2)]"
Scanning Probe State Recognition With Multi-Class Neural Network Ensembles,"O. Gordon, P. D'Hondt, L. Knijff, S. Freeney, F. Junqueira, P. Moriarty, I. Swart","One of the largest obstacles facing scanning probe microscopy is the constant
need to correct flaws in the scanning probe in situ. This is currently a
manual, time-consuming process that would benefit greatly from automation. Here
we introduce a convolutional neural network protocol that enables automated
recognition of a variety of desirable and undesirable scanning probe tip states
on both metal and non-metal surfaces. By combining the best performing models
into majority voting ensembles, we find that the desirable states of H:Si(100)
can be distinguished with a mean precision of 0.89 and an average
receiver-operator-characteristic curve area of 0.95. More generally, high and
low-quality tips can be distinguished with a mean precision of 0.96 and near
perfect area-under-curve of 0.98. With trivial modifications, we also
successfully automatically identify undesirable, non-surface-specific states on
surfaces of Au(111) and Cu(111). In these cases we find mean precisions of 0.95
and 0.75 and area-under-curves of 0.98 and 0.94, respectively.",Machine Learning (cs.LG),"; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)",[Submitted on 21 Mar 2019]
"Forecasting Time-to-Collision from Monocular Video: Feasibility, Dataset, and Challenges","Aashi Manglik, Xinshuo Weng, Eshed Ohn-Bar, Kris M. Kitani","We explore the possibility of using a single monocular camera to forecast the
time to collision between a suitcase-shaped robot being pushed by its user and
other nearby pedestrians. We develop a purely image-based deep learning
approach that directly estimates the time to collision without the need of
relying on explicit geometric depth estimates or velocity information to
predict future collisions. While previous work has focused on detecting
immediate collision in the context of navigating Unmanned Aerial Vehicles, the
detection was limited to a binary variable (i.e., collision or no collision).
We propose a more fine-grained approach to collision forecasting by predicting
the exact time to collision in terms of milliseconds, which is more helpful for
collision avoidance in the context of dynamic path planning. To evaluate our
method, we have collected a novel dataset of over 13,000 indoor video segments
each showing a trajectory of at least one person ending in a close proximity (a
near collision) with the camera mounted on a mobile suitcase-shaped platform.
Using this dataset, we do extensive experimentation on different temporal
windows as input using an exhaustive list of state-of-the-art convolutional
neural networks (CNNs). Our results show that our proposed multi-stream CNN is
the best model for predicting time to near-collision. The average prediction
error of our time to near collision is 0.75 seconds across the test videos.",Robotics (cs.RO),,"[Submitted on 21 Mar 2019 (v1), last revised 9 Aug 2019 (this version, v2)]"
Distributed Transactional Systems Cannot Be Fast,"Diego Didona, Panagiota Fatourou, Rachid Guerraoui, Jingjing Wang, Willy Zwaenepoel","We prove that no fully transactional system can provide fast read
transactions (including read-only ones that are considered the most frequent in
practice). Specifically, to achieve fast read transactions, the system has to
give up support of transactions that write more than one object. We prove this
impossibility result for distributed storage systems that are causally
consistent, i.e., they do not require to ensure any strong form of consistency.
Therefore, our result holds also for any system that ensures a consistency
level stronger than causal consistency, e.g., strict serializability. The
impossibility result holds even for systems that store only two objects (and
support at least two servers and at least four clients). It also holds for
systems that are partially replicated. Our result justifies the design choices
of state-of-the-art distributed transactional systems and insists that system
designers should not put more effort to design fully-functional systems that
support both fast read transactions and ensure causal or any stronger form of
consistency.","Distributed, Parallel, and Cluster Computing (cs.DC)",,"[Submitted on 21 Mar 2019 (v1), last revised 10 Apr 2019 (this version, v2)]"
Levelling the Playing Field: A Comprehensive Comparison of Visual Place Recognition Approaches under Changing Conditions,"Mubariz Zaffar, Ahmad Khaliq, Shoaib Ehsan, Michael Milford, Klaus McDonald-Maier","In recent years there has been significant improvement in the capability of
Visual Place Recognition (VPR) methods, building on the success of both
hand-crafted and learnt visual features, temporal filtering and usage of
semantic scene information. The wide range of approaches and the relatively
recent growth in interest in the field has meant that a wide range of datasets
and assessment methodologies have been proposed, often with a focus only on
precision-recall type metrics, making comparison difficult. In this paper we
present a comprehensive approach to evaluating the performance of 10
state-of-the-art recently-developed VPR techniques, which utilizes three
standardized metrics: (a) Matching Performance b) Matching Time c) Memory
Footprint. Together this analysis provides an up-to-date and widely
encompassing snapshot of the various strengths and weaknesses of contemporary
approaches to the VPR problem. The aim of this work is to help move this
particular research field towards a more mature and unified approach to the
problem, enabling better comparison and hence more progress to be made in
future research.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 29 Apr 2019 (this version, v2)]"
A Principled Approach for Learning Task Similarity in Multitask Learning,"Changjian Shui, Mahdieh Abbasi, Louis-Émile Robitaille, Boyu Wang, Christian Gagné","Multitask learning aims at solving a set of related tasks simultaneously, by
exploiting the shared knowledge for improving the performance on individual
tasks. Hence, an important aspect of multitask learning is to understand the
similarities within a set of tasks. Previous works have incorporated this
similarity information explicitly (e.g., weighted loss for each task) or
implicitly (e.g., adversarial loss for feature adaptation), for achieving good
empirical performances. However, the theoretical motivations for adding task
similarity knowledge are often missing or incomplete. In this paper, we give a
different perspective from a theoretical point of view to understand this
practice. We first provide an upper bound on the generalization error of
multitask learning, showing the benefit of explicit and implicit task
similarity knowledge. We systematically derive the bounds based on two distinct
task similarity metrics: H divergence and Wasserstein distance. From these
theoretical results, we revisit the Adversarial Multi-task Neural Network,
proposing a new training algorithm to learn the task relation coefficients and
neural network parameters iteratively. We assess our new algorithm empirically
on several benchmarks, showing not only that we find interesting and robust
task relations, but that the proposed approach outperforms the baselines,
reaffirming the benefits of theoretical insight in algorithm design.",Machine Learning (cs.LG),; Machine Learning (stat.ML),"[Submitted on 21 Mar 2019 (v1), last revised 31 May 2019 (this version, v2)]"
Exploratory studies of human gait changes using depth cameras and considering measurement errors,Behnam Malmir,"This research aims to quantify human walking patterns through depth cameras
to (1) detect walking pattern changes of a person with and without a
motion-restricting device or a walking aid, and to (2) identify distinct
walking patterns from different persons of similar physical attributes.
Microsoft Kinect devices, often used for video games, were used to provide and
track coordinates of 25 different joints of people over time to form a human
skeleton. Then multiple machine learning (ML) models were applied to the SE
datasets from ten college-age subjects - five males and five females. In
particular, ML models were applied to classify subjects into two categories:
normal walking and abnormal walking (i.e. with motion-restricting devices). The
best ML model (K-nearest neighborhood) was able to predict 97.3% accuracy using
10-fold cross-validation. Finally, ML models were applied to classify five gait
conditions: walking normally, walking while wearing the ankle brace, walking
while wearing the ACL brace, walking while using a cane, and walking while
using a walker. The best ML model was again the K-nearest neighborhood
performing at 98.7% accuracy rate.",Human-Computer Interaction (cs.HC),; Applications (stat.AP); Computation (stat.CO),[Submitted on 21 Mar 2019]
Closed-Form Optimal Two-View Triangulation Based on Angular Errors,"Seong Hun Lee, Javier Civera","In this paper, we study closed-form optimal solutions to two-view
triangulation with known internal calibration and pose. By formulating the
triangulation problem as $L_1$ and $L_\infty$ minimization of angular
reprojection errors, we derive the exact closed-form solutions that guarantee
global optimality under respective cost functions. To the best of our
knowledge, we are the first to present such solutions. Since the angular error
is rotationally invariant, our solutions can be applied for any type of central
cameras, be it perspective, fisheye or omnidirectional. Our methods also
require significantly less computation than the existing optimal methods.
Experimental results on synthetic and real datasets validate our theoretical
derivations.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 29 Jul 2019 (this version, v3)]"
Finite Sample Analysis of Stochastic System Identification,"Anastasios Tsiamis, George J. Pappas","In this paper, we analyze the finite sample complexity of stochastic system
identification using modern tools from machine learning and statistics. An
unknown discrete-time linear system evolves over time under Gaussian noise
without external inputs. The objective is to recover the system parameters as
well as the Kalman filter gain, given a single trajectory of output
measurements over a finite horizon of length $N$. Based on a subspace
identification algorithm and a finite number of $N$ output samples, we provide
non-asymptotic high-probability upper bounds for the system parameter
estimation errors. Our analysis uses recent results from random matrix theory,
self-normalized martingales and SVD robustness, in order to show that with high
probability the estimation errors decrease with a rate of $1/\sqrt{N}$. Our
non-asymptotic bounds not only agree with classical asymptotic results, but are
also valid even when the system is marginally stable.",Machine Learning (cs.LG),; Systems and Control (eess.SY); Optimization and Control (math.OC); Machine Learning (stat.ML),[Submitted on 21 Mar 2019]
PProCRC: Probabilistic Collaboration of Image Patches,"Tapabrata Chakraborti, Brendan McCane, Steven Mills, Umapada Pal","We present a conditional probabilistic framework for collaborative
representation of image patches. It in-corporates background compensation and
outlier patch suppression into the main formulation itself, thus doingaway with
the need for pre-processing steps to handle the same. A closed form
non-iterative solution of the costfunction is derived. The proposed method
(PProCRC) outperforms earlier related patch based (PCRC, GP-CRC)as well as the
state-of-the-art probabilistic (ProCRC and EProCRC) models on several
fine-grained benchmarkimage datasets for face recognition (AR and LFW) and
species recognition (Oxford Flowers and Pets) tasks.We also expand our recent
endemic Indian birds (IndBirds) dataset and report results on it. The demo code
andIndBirds dataset are available through lead author.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 11 Dec 2019 (this version, v2)]"
Controllability-Gramian Submatrices for a Network Consensus Model,"Sandip Roy, Mengran Xue","Principal submatrices of the controllability Gramian and their inverses are
examined, for a network-consensus model with inputs at a subset of network
nodes. Specifically, several properties of the Gramian submatrices and their
inverses -- including dominant eigenvalues and eigenvectors, diagonal entries,
and sign patterns -- are characterized by exploiting the special
doubly-nonnegative structure of the matrices. In addition, majorizations for
these properties are obtained in terms of cutsets in the network's graph, based
on the diffusive form of the model. The asymptotic (long time horizon)
structure of the controllability Gramian is also analyzed. The results on the
Gramian are used to study metrics for target control of the network-consensus
model.",Systems and Control (eess.SY),; Signal Processing (eess.SP); Dynamical Systems (math.DS); Physics and Society (physics.soc-ph),[Submitted on 21 Mar 2019]
Progressive Sparse Local Attention for Video object detection,"Chaoxu Guo, Bin Fan, Jie Gu, Qian Zhang, Shiming Xiang, Veronique Prinet, Chunhong Pan","Transferring image-based object detectors to the domain of videos remains a
challenging problem. Previous efforts mostly exploit optical flow to propagate
features across frames, aiming to achieve a good trade-off between accuracy and
efficiency. However, introducing an extra model to estimate optical flow can
significantly increase the overall model size. The gap between optical flow and
high-level features can also hinder it from establishing spatial correspondence
accurately. Instead of relying on optical flow, this paper proposes a novel
module called Progressive Sparse Local Attention (PSLA), which establishes the
spatial correspondence between features across frames in a local region with
progressively sparser stride and uses the correspondence to propagate features.
Based on PSLA, Recursive Feature Updating (RFU) and Dense Feature Transforming
(DenseFT) are proposed to model temporal appearance and enrich feature
representation respectively in a novel video object detection framework.
Experiments on ImageNet VID show that our method achieves the best accuracy
compared to existing methods with smaller model size and acceptable runtime
speed.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 16 Aug 2019 (this version, v3)]"
Perturbed-History Exploration in Stochastic Linear Bandits,"Branislav Kveton, Csaba Szepesvari, Mohammad Ghavamzadeh, Craig Boutilier","We propose a new online algorithm for minimizing the cumulative regret in
stochastic linear bandits. The key idea is to build a perturbed history, which
mixes the history of observed rewards with a pseudo-history of randomly
generated i.i.d. pseudo-rewards. Our algorithm, perturbed-history exploration
in a linear bandit (LinPHE), estimates a linear model from its perturbed
history and pulls the arm with the highest value under that model. We prove a
$\tilde{O}(d \sqrt{n})$ gap-free bound on the expected $n$-round regret of
LinPHE, where $d$ is the number of features. Our analysis relies on novel
concentration and anti-concentration bounds on the weighted sum of Bernoulli
random variables. To show the generality of our design, we extend LinPHE to a
logistic reward model. We evaluate both algorithms empirically and show that
they are practical.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 21 Mar 2019]
Harmless interpolation of noisy data in regression,"Vidya Muthukumar, Kailas Vodrahalli, Vignesh Subramanian, Anant Sahai","A continuing mystery in understanding the empirical success of deep neural
networks is their ability to achieve zero training error and generalize well,
even when the training data is noisy and there are more parameters than data
points. We investigate this overparameterized regime in linear regression,
where all solutions that minimize training error interpolate the data,
including noise. We characterize the fundamental generalization (mean-squared)
error of any interpolating solution in the presence of noise, and show that
this error decays to zero with the number of features. Thus,
overparameterization can be explicitly beneficial in ensuring harmless
interpolation of noise. We discuss two root causes for poor generalization that
are complementary in nature -- signal ""bleeding"" into a large number of alias
features, and overfitting of noise by parsimonious feature selectors. For the
sparse linear model with noise, we provide a hybrid interpolating scheme that
mitigates both these issues and achieves order-optimal MSE over all possible
interpolating solutions.",Machine Learning (cs.LG),; Machine Learning (stat.ML),"[Submitted on 21 Mar 2019 (v1), last revised 9 Sep 2019 (this version, v2)]"
Quantitative Depth Quality Assessment of RGBD Cameras At Close Range Using 3D Printed Fixtures,"Michele Pratusevich, Jason Chrisos, Shreyas Aditya","Mobile robots that manipulate their environments require high-accuracy scene
understanding at close range. Typically this understanding is achieved with
RGBD cameras, but the evaluation process for selecting an appropriate RGBD
camera for the application is minimally quantitative. Limited
manufacturer-published metrics do not translate to observed quality in
real-world cluttered environments, since quality is application-specific. To
bridge the gap, we present a method for quantitatively measuring depth quality
using a set of extendable 3D printed fixtures that approximate real-world
conditions. By framing depth quality as point cloud density and root mean
square error (RMSE) from a known geometry, we present a method that is
extendable by other system integrators for custom environments. We show a
comparison of 3 cameras and present a case study for camera selection, provide
reference meshes and analysis code, and discuss further extensions.",Computer Vision and Pattern Recognition (cs.CV),; Robotics (cs.RO),[Submitted on 21 Mar 2019]
Towards automatic construction of multi-network models for heterogeneous multi-task learning,"Unai Garciarena, Alexander Mendiburu, Roberto Santana","Multi-task learning, as it is understood nowadays, consists of using one
single model to carry out several similar tasks. From classifying hand-written
characters of different alphabets to figuring out how to play several Atari
games using reinforcement learning, multi-task models have been able to widen
their performance range across different tasks, although these tasks are
usually of a similar nature. In this work, we attempt to widen this range even
further, by including heterogeneous tasks in a single learning procedure. To do
so, we firstly formally define a multi-network model, identifying the necessary
components and characteristics to allow different adaptations of said model
depending on the tasks it is required to fulfill. Secondly, employing the
formal definition as a starting point, we develop an illustrative model example
consisting of three different tasks (classification, regression and data
sampling). The performance of this model implementation is then analyzed,
showing its capabilities. Motivated by the results of the analysis, we
enumerate a set of open challenges and future research lines over which the
full potential of the proposed model definition can be exploited.",Machine Learning (cs.LG),; Artificial Intelligence (cs.AI),[Submitted on 21 Mar 2019]
Bootstrapping Cookbooks for APIs from Crowd Knowledge on Stack Overflow,"Lucas B. L. Souza, Eduardo C. Campos, Fernanda Madeiral, Klérisson Paixão, Adriano M. Rocha, Marcelo de Almeida Maia","Well established libraries typically have API documentation. However, they
frequently lack examples and explanations, possibly making difficult their
effective reuse. Stack Overflow is a question-and-answer website oriented to
issues related to software development. Despite the increasing adoption of
Stack Overflow, the information related to a particular topic (e.g., an API) is
spread across the website. Thus, Stack Overflow still lacks organization of the
crowd knowledge available on it. Our target goal is to address the problem of
the poor quality documentation for APIs by providing an alternative artifact to
document them based on the crowd knowledge available on Stack Overflow, called
crowd cookbook. A cookbook is a recipe-oriented book, and we refer to our
cookbook as crowd cookbook since it contains content generated by a crowd. The
cookbooks are meant to be used through an exploration process, i.e. browsing.
In this paper, we present a semi-automatic approach that organizes the crowd
knowledge available on Stack Overflow to build cookbooks for APIs. We have
generated cookbooks for three APIs widely used by the software development
community: SWT, LINQ and QT. We have also defined desired properties that crowd
cookbooks must meet, and we conducted an evaluation of the cookbooks against
these properties with human subjects. The results showed that the cookbooks
built using our approach, in general, meet those properties. As a highlight,
most of the recipes were considered appropriate to be in the cookbooks and have
self-contained information. We concluded that our approach is capable to
produce adequate cookbooks automatically, which can be as useful as manually
produced cookbooks. This opens an opportunity for API designers to enrich
existent cookbooks with the different points of view from the crowd, or even to
generate initial versions of new cookbooks.",Software Engineering (cs.SE),,[Submitted on 21 Mar 2019]
Long range teleoperation for fine manipulation tasks under time-delay network conditions,"Jun Jin, Laura Petrich, Shida He, Masood Dehghan, Martin Jagersand","We present a coarse-to-fine approach based semi-autonomous teleoperation
system using vision guidance. The system is optimized for long range
teleoperation tasks under time-delay network conditions and does not require
prior knowledge of the remote scene. Our system initializes with a self
exploration behavior that senses the remote surroundings through a freely
mounted eye-in-hand web cam. The self exploration stage estimates hand-eye
calibration and provides a telepresence interface via real-time 3D geometric
reconstruction. The human operator is able to specify a visual task through the
interface and a coarse-to-fine controller guides the remote robot enabling our
system to work in high latency networks. Large motions are guided by coarse 3D
estimation, whereas fine motions use image cues (IBVS). Network data
transmission cost is minimized by sending only sparse points and a final image
to the human side. Experiments from Singapore to Canada on multiple tasks were
conducted to show our system's capability to work in long range teleoperation
tasks.",Robotics (cs.RO),,[Submitted on 21 Mar 2019]
Comparison of State-of-the-Art Deep Learning APIs for Image Multi-Label Classification using Semantic Metrics,"Adam Kubany, Shimon Ben Ishay, Ruben-sacha Ohayon, Armin Shmilovici, Lior Rokach, Tomer Doitshman","Image understanding heavily relies on accurate multi-label classification. In
recent years, deep learning algorithms have become very successful for such
tasks, and various commercial and open-source APIs have been released for
public use. However, these APIs are often trained on different datasets, which,
besides affecting their performance, might pose a challenge to their
performance evaluation. This challenge concerns the different object-class
dictionaries of the APIs' training dataset and the benchmark dataset, in which
the predicted labels are semantically similar to the benchmark labels but
considered different simply because they have different wording in the
dictionaries. To face this challenge, we propose semantic similarity metrics to
obtain richer understating of the APIs predicted labels and thus their
performance. In this study, we evaluate and compare the performance of 13 of
the most prominent commercial and open-source APIs in a best-of-breed challenge
on the Visual Genome and Open Images benchmark datasets. Our findings
demonstrate that, while using traditional metrics, the Microsoft Computer
Vision, Imagga, and IBM APIs performed better than others. However, applying
semantic metrics also unveil the InceptionResNet-v2, Inception-v3, and ResNet50
APIs, which are trained only with the simple ImageNet dataset, as challengers
for top semantic performers.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 11 Jun 2020 (this version, v4)]"
Hierarchical Propagation Networks for Fake News Detection: Investigation and Exploitation,"Kai Shu, Deepak Mahudeswaran, Suhang Wang, Huan Liu","Consuming news from social media is becoming increasingly popular. However,
social media also enables the widespread of fake news. Because of its
detrimental effects brought by social media, fake news detection has attracted
increasing attention. However, the performance of detecting fake news only from
news content is generally limited as fake news pieces are written to mimic true
news. In the real world, news pieces spread through propagation networks on
social media. The news propagation networks usually involve multi-levels. In
this paper, we study the challenging problem of investigating and exploiting
news hierarchical propagation network on social media for fake news detection.
In an attempt to understand the correlations between news propagation
networks and fake news, first, we build a hierarchical propagation network from
macro-level and micro-level of fake news and true news; second, we perform a
comparative analysis of the propagation network features of linguistic,
structural and temporal perspectives between fake and real news, which
demonstrates the potential of utilizing these features to detect fake news;
third, we show the effectiveness of these propagation network features for fake
news detection. We further validate the effectiveness of these features from
feature important analysis. Altogether, this work presents a data-driven view
of hierarchical propagation network and fake news and paves the way towards a
healthier online news ecosystem.",Social and Information Networks (cs.SI),,[Submitted on 21 Mar 2019]
Sparse2Dense: From direct sparse odometry to dense 3D reconstruction,"Jiexiong Tang, John Folkesson, Patric Jensfelt","In this paper, we proposed a new deep learning based dense monocular SLAM
method. Compared to existing methods, the proposed framework constructs a dense
3D model via a sparse to dense mapping using learned surface normals. With
single view learned depth estimation as prior for monocular visual odometry, we
obtain both accurate positioning and high quality depth reconstruction. The
depth and normal are predicted by a single network trained in a tightly coupled
manner.Experimental results show that our method significantly improves the
performance of visual tracking and depth prediction in comparison to the
state-of-the-art in deep monocular dense SLAM.",Robotics (cs.RO),; Computer Vision and Pattern Recognition (cs.CV),[Submitted on 21 Mar 2019]
Rate-Flexible Fast Polar Decoders,"Seyyed Ali Hashemi, Carlo Condo, Marco Mondelli, Warren J. Gross","Polar codes have gained extensive attention during the past few years and
recently they have been selected for the next generation of wireless
communications standards (5G). Successive-cancellation-based (SC-based)
decoders, such as SC list (SCL) and SC flip (SCF), provide a reasonable error
performance for polar codes at the cost of low decoding speed. Fast SC-based
decoders, such as Fast-SSC, Fast-SSCL, and Fast-SSCF, identify the special
constituent codes in a polar code graph off-line, produce a list of operations,
store the list in memory, and feed the list to the decoder to decode the
constituent codes in order efficiently, thus increasing the decoding speed.
However, the list of operations is dependent on the code rate and as the rate
changes, a new list is produced, making fast SC-based decoders not
rate-flexible. In this paper, we propose a completely rate-flexible fast
SC-based decoder by creating the list of operations directly in hardware, with
low implementation complexity. We further propose a hardware architecture
implementing the proposed method and show that the area occupation of the
rate-flexible fast SC-based decoder in this paper is only $38\%$ of the total
area of the memory-based base-line decoder when 5G code rates are supported.",Information Theory (cs.IT),,[Submitted on 21 Mar 2019]
A Simulation Based Dynamic Evaluation Framework for System-wide Algorithmic Fairness,"Efrén Cruz Cortés, Debashis Ghosh","We propose the use of Agent Based Models (ABMs) inside a reinforcement
learning framework in order to better understand the relationship between
automated decision making tools, fairness-inspired statistical constraints, and
the social phenomena giving rise to discrimination towards sensitive groups.
There have been many instances of discrimination occurring due to the
applications of algorithmic tools by public and private institutions. Until
recently, these practices have mostly gone unchecked. Given the large-scale
transformation these new technologies elicit, a joint effort of social sciences
and machine learning researchers is necessary. Much of the research has been
done on determining statistical properties of such algorithms and the data they
are trained on. We aim to complement that approach by studying the social
dynamics in which these algorithms are implemented. We show how bias can be
accumulated and reinforced through automated decision making, and the
possibility of finding a fairness inducing policy. We focus on the case of
recidivism risk assessment by considering simplified models of arrest. We find
that if we limit our attention to what is observed and manipulated by these
algorithmic tools, we may determine some blatantly unfair practices as fair,
illustrating the advantage of analyzing the otherwise elusive property with a
system-wide model. We expect the introduction of agent based simulation
techniques will strengthen collaboration with social scientists, arriving at a
better understanding of the social systems affected by technology and to
hopefully lead to concrete policy proposals that can be presented to
policymakers for a true systemic transformation.",Computers and Society (cs.CY),,[Submitted on 21 Mar 2019]
Exact Topology Learning in a Network of Cyclostationary Processes,"Harish Doddi, Saurav Talukdar, Deepjyoti Deka, Murti Salapaka","Learning the structure of a network from time series data, in particular
cyclostationary data, is of significant interest in many disciplines such as
power grids, biology and finance. In this article, an algorithm is presented
for reconstruction of the topology of a network of cyclostationary processes.
To the best of our knowledge, this is the first work to guarantee exact
recovery without any assumptions on the underlying structure. The method is
based on a lifting technique by which cyclostationary processes are mapped to
vector wide sense stationary processes and further on semi-definite properties
of matrix Wiener filters for the said processes.We demonstrate the performance
of the proposed algorithm on a Resistor-Capacitor network and present the
accuracy of reconstruction for varying sample sizes.",Systems and Control (eess.SY),,"[Submitted on 21 Mar 2019 (v1), last revised 19 Sep 2019 (this version, v2)]"
Multi-person Articulated Tracking with Spatial and Temporal Embeddings,"Sheng Jin, Wentao Liu, Wanli Ouyang, Chen Qian","We propose a unified framework for multi-person pose estimation and tracking.
Our framework consists of two main components,~\ie~SpatialNet and TemporalNet.
The SpatialNet accomplishes body part detection and part-level data association
in a single frame, while the TemporalNet groups human instances in consecutive
frames into trajectories. Specifically, besides body part detection heatmaps,
SpatialNet also predicts the Keypoint Embedding (KE) and Spatial Instance
Embedding (SIE) for body part association. We model the grouping procedure into
a differentiable Pose-Guided Grouping (PGG) module to make the whole part
detection and grouping pipeline fully end-to-end trainable. TemporalNet extends
spatial grouping of keypoints to temporal grouping of human instances. Given
human proposals from two consecutive frames, TemporalNet exploits both
appearance features encoded in Human Embedding (HE) and temporally consistent
geometric features embodied in Temporal Instance Embedding (TIE) for robust
tracking. Extensive experiments demonstrate the effectiveness of our proposed
model. Remarkably, we demonstrate substantial improvements over the
state-of-the-art pose tracking method from 65.4\% to 71.8\% Multi-Object
Tracking Accuracy (MOTA) on the ICCV'17 PoseTrack Dataset.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 21 Mar 2019]
Ensemble Observability of Bloch Equations with Unknown Population Density,Xudong Chen,"We introduce in the paper a novel observability problem for a continuum
ensemble of nonholonomic control systems with unknown population density. We
address the problem by focussing on a prototype of such ensemble system,
namely, the ensemble of Bloch equations. The dynamics of the equations are
structurally identical, but show variations in Larmor dispersion and radio
frequency (rf) inhomogeneity. We assume that the initial state of every
individual system is unknown and, moreover, the population density of these
individual systems is also unknown. Furthermore, we assume that at any time,
there is only one scalar measurement output at our disposal. The measurement
output integrates a certain observation function, common to all individual
systems, over the continuum ensemble. The observability problem we pose in the
paper is thus the following: Whether one is able to use the common control
input (i.e., the rf field) and the single measurement output to estimate the
initial states of the individual systems and, moreover, to identify the
population density? Amongst other things, we establish a sufficient condition
for the ensemble system to be observable: We show that if the common
observation function is any harmonic homogeneous polynomial of positive degree,
then the ensemble system is observable. The main focus of the paper is to
demonstrate how to leverage tools from representation theory of Lie algebras to
address the observability problem. Although the results we establish in the
paper are for the specific ensemble of Bloch equations, the approach we develop
along the analysis can be generalized to investigate observability of other
general ensembles of nonholonomic control systems with a single, integrated
measurement output.",Systems and Control (eess.SY),,"[Submitted on 21 Mar 2019 (v1), last revised 29 Apr 2020 (this version, v2)]"
Recovering the Lowest Layer of Deep Networks with High Threshold Activations,"Surbhi Goel, Rina Panigrahy","Giving provable guarantees for learning neural networks is a core challenge
of machine learning theory. Most prior work gives parameter recovery guarantees
for one hidden layer networks, however, the networks used in practice have
multiple non-linear layers. In this work, we show how we can strengthen such
results to deeper networks -- we address the problem of uncovering the lowest
layer in a deep neural network under the assumption that the lowest layer uses
a high threshold before applying the activation, the upper network can be
modeled as a well-behaved polynomial and the input distribution is Gaussian.",Machine Learning (cs.LG),; Machine Learning (stat.ML),"[Submitted on 21 Mar 2019 (v1), last revised 20 Feb 2020 (this version, v2)]"
SkelNetOn 2019: Dataset and Challenge on Deep Learning for Geometric Shape Understanding,"Ilke Demir, Camilla Hahn, Kathryn Leonard, Geraldine Morin, Dana Rahbani, Athina Panotopoulou, Amelie Fondevilla, Elena Balashova, Bastien Durix, Adam Kortylewski","We present SkelNetOn 2019 Challenge and Deep Learning for Geometric Shape
Understanding workshop to utilize existing and develop novel deep learning
architectures for shape understanding. We observed that unlike traditional
segmentation and detection tasks, geometry understanding is still a new area
for deep learning techniques. SkelNetOn aims to bring together researchers from
different domains to foster learning methods on global shape understanding
tasks. We aim to improve and evaluate the state-of-the-art shape understanding
approaches, and to serve as reference benchmarks for future research. Similar
to other challenges in computer vision, SkelNetOn proposes three datasets and
corresponding evaluation methodologies; all coherently bundled in three
competitions with a dedicated workshop co-located with CVPR 2019 conference. In
this paper, we describe and analyze characteristics of datasets, define the
evaluation criteria of the public competitions, and provide baselines for each
task.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 22 Jun 2019 (this version, v3)]"
Scalable Similarity Joins of Tokenized Strings,"Ahmed Metwally, Chun-Heng Huang","This work tackles the problem of fuzzy joining of strings that naturally
tokenize into meaningful substrings, e.g., full names. Tokenized-string joins
have several established applications in the context of data integration and
cleaning. This work is primarily motivated by fraud detection, where attackers
slightly modify tokenized strings, e.g., names on accounts, to create numerous
identities that she can use to defraud service providers, e.g., Google, and
LinkedIn. To detect such attacks, all the accounts are pair-wise compared, and
the resulting similar accounts are considered suspicious and are further
investigated. Comparing the tokenized-string features of a large number of
accounts requires an intuitive tokenized-string distance that can detect subtle
edits introduced by an adversary, and a very scalable algorithm. This is not
achievable by existing distance measure that are unintuitive, hard to tune, and
whose join algorithms are serial and hence unscalable. We define a novel
intuitive distance measure between tokenized strings, Normalized Setwise
Levenshtein Distance (NSLD). To the best of our knowledge, NSLD is the first
metric proposed for comparing tokenized strings. We propose a scalable
distributed framework, Tokenized-String Joiner (TSJ), that adopts existing
scalable string-join algorithms as building blocks to perform NSLD-joins. We
carefully engineer optimizations and approximations that dramatically improve
the efficiency of TSJ. The effectiveness of the TSJ framework is evident from
the evaluation conducted on tens of millions of tokenized-string names from
Google accounts. The superiority of the tokenized-string-specific TSJ framework
over the general-purpose metric-spaces joining algorithms has been established.",Information Retrieval (cs.IR),; Databases (cs.DB),[Submitted on 21 Mar 2019]
Deep Radiomics for Brain Tumor Detection and Classification from Multi-Sequence MRI,"Subhashis Banerjee, Sushmita Mitra, Francesco Masulli, Stefano Rovetta","Glioma constitutes 80% of malignant primary brain tumors and is usually
classified as HGG and LGG. The LGG tumors are less aggressive, with slower
growth rate as compared to HGG, and are responsive to therapy. Tumor biopsy
being challenging for brain tumor patients, noninvasive imaging techniques like
Magnetic Resonance Imaging (MRI) have been extensively employed in diagnosing
brain tumors. Therefore automated systems for the detection and prediction of
the grade of tumors based on MRI data becomes necessary for assisting doctors
in the framework of augmented intelligence. In this paper, we thoroughly
investigate the power of Deep ConvNets for classification of brain tumors using
multi-sequence MR images. We propose novel ConvNet models, which are trained
from scratch, on MRI patches, slices, and multi-planar volumetric slices. The
suitability of transfer learning for the task is next studied by applying two
existing ConvNets models (VGGNet and ResNet) trained on ImageNet dataset,
through fine-tuning of the last few layers. LOPO testing, and testing on the
holdout dataset are used to evaluate the performance of the ConvNets. Results
demonstrate that the proposed ConvNets achieve better accuracy in all cases
where the model is trained on the multi-planar volumetric dataset. Unlike
conventional models, it obtains a testing accuracy of 95% for the low/high
grade glioma classification problem. A score of 97% is generated for
classification of LGG with/without 1p/19q codeletion, without any additional
effort towards extraction and selection of features. We study the properties of
self-learned kernels/ filters in different layers, through visualization of the
intermediate layer outputs. We also compare the results with that of
state-of-the-art methods, demonstrating a maximum improvement of 7% on the
grading performance of ConvNets and 9% on the prediction of 1p/19q codeletion
status.",Computer Vision and Pattern Recognition (cs.CV),; Image and Video Processing (eess.IV),[Submitted on 21 Mar 2019]
Repairing mappings under policy views,"Angela Bonifati, Ugo Comignani, Efthymia Tsamoura","The problem of data exchange involves a source schema, a target schema and a
set of mappings from transforming the data between the two schemas. We study
the problem of data exchange in the presence of privacy restrictions on the
source. The privacy restrictions are expressed as a set of policy views
representing the information that is safe to expose over all instances of the
source. We propose a protocol that provides formal privacy guarantees and is
data-independent, i.e., if certain criteria are met, then the protocol
guarantees that the mappings leak no sensitive information independently of the
data that lies in the source. We also propose an algorithm for repairing an
input mapping w.r.t. a set of policy views, in cases where the input mapping
leaks sensitive information. The empirical evaluation of our work shows that
the proposed algorithm is quite efficient, repairing sets of 300 s-t tgds in an
average time of 5s on a commodity machine. To the best of our knowledge, our
work is the first one that studies the problems of exchanging data and
repairing mappings under such privacy restrictions. Furthermore, our work is
the first to provide practical algorithms for a logical privacy-preservation
paradigm, described as an open research challenge in previous work on this
area.",Databases (cs.DB),,[Submitted on 21 Mar 2019]
Inferring Compact Representations for Efficient Natural Language Understanding of Robot Instructions,"Siddharth Patki, Andrea F. Daniele, Matthew R. Walter, Thomas M. Howard","The speed and accuracy with which robots are able to interpret natural
language is fundamental to realizing effective human-robot interaction. A great
deal of attention has been paid to developing models and approximate inference
algorithms that improve the efficiency of language understanding. However,
existing methods still attempt to reason over a representation of the
environment that is flat and unnecessarily detailed, which limits scalability.
An open problem is then to develop methods capable of producing the most
compact environment model sufficient for accurate and efficient natural
language understanding. We propose a model that leverages environment-related
information encoded within instructions to identify the subset of observations
and perceptual classifiers necessary to perceive a succinct,
instruction-specific environment representation. The framework uses three
probabilistic graphical models trained from a corpus of annotated instructions
to infer salient scene semantics, perceptual classifiers, and grounded symbols.
Experimental results on two robots operating in different environments
demonstrate that by exploiting the content and the structure of the
instructions, our method learns compact environment representations that
significantly improve the efficiency of natural language symbol grounding.",Robotics (cs.RO),; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG),[Submitted on 21 Mar 2019]
Low Resource Text Classification with ULMFit and Backtranslation,Sam Shleifer,"In computer vision, virtually every state-of-the-art deep learning system is
trained with data augmentation. In text classification, however, data
augmentation is less widely practiced because it must be performed before
training and risks introducing label noise. We augment the IMDB movie reviews
dataset with examples generated by two families of techniques: random token
perturbations introduced by Wei and Zou [2019] and backtranslation --
translating to a second language then back to English. In low resource
environments, backtranslation generates significant improvement on top of the
state of-the-art ULMFit model. A ULMFit model pretrained on wikitext103 and
then fine-tuned on only 50 IMDB examples and 500 synthetic examples generated
by backtranslation achieves 80.6% accuracy, an 8.1% improvement over the
augmentation-free baseline with only 9 minutes of additional training time.
Random token perturbations do not yield any improvements but incur equivalent
computational cost. The benefits of training with backtranslated examples
decreases with the size of the available training data. On the full dataset,
neither augmentation technique improves upon ULMFit's state of the art
performance. We address this by using backtranslations as a form of test time
augmentation as well as ensembling ULMFit with other models, and achieve small
improvements.",Computation and Language (cs.CL),; Machine Learning (cs.LG),"[Submitted on 21 Mar 2019 (v1), last revised 25 Mar 2019 (this version, v2)]"
Trainable Time Warping: Aligning Time-Series in the Continuous-Time Domain,"Soheil Khorram, Melvin G McInnis, Emily Mower Provost","DTW calculates the similarity or alignment between two signals, subject to
temporal warping. However, its computational complexity grows exponentially
with the number of time-series. Although there have been algorithms developed
that are linear in the number of time-series, they are generally quadratic in
time-series length. The exception is generalized time warping (GTW), which has
linear computational cost. Yet, it can only identify simple time warping
functions. There is a need for a new fast, high-quality multisequence alignment
algorithm. We introduce trainable time warping (TTW), whose complexity is
linear in both the number and the length of time-series. TTW performs alignment
in the continuous-time domain using a sinc convolutional kernel and a
gradient-based optimization technique. We compare TTW and GTW on 85 UCR
datasets in time-series averaging and classification. TTW outperforms GTW on
67.1% of the datasets for the averaging tasks, and 61.2% of the datasets for
the classification tasks.",Machine Learning (cs.LG),; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Machine Learning (stat.ML),[Submitted on 21 Mar 2019]
Explain3D: Explaining Disagreements in Disjoint Datasets,"Xiaolan Wang, Alexandra Meliou","Data plays an important role in applications, analytic processes, and many
aspects of human activity. As data grows in size and complexity, we are met
with an imperative need for tools that promote understanding and explanations
over data-related operations. Data management research on explanations has
focused on the assumption that data resides in a single dataset, under one
common schema. But the reality of today's data is that it is frequently
un-integrated, coming from different sources with different schemas. When
different datasets provide different answers to semantically similar questions,
understanding the reasons for the discrepancies is challenging and cannot be
handled by the existing single-dataset solutions.
In this paper, we propose Explain3D, a framework for explaining the
disagreements across disjoint datasets (3D). Explain3D focuses on identifying
the reasons for the differences in the results of two semantically similar
queries operating on two datasets with potentially different schemas. Our
framework leverages the queries to perform a semantic mapping across the
relevant parts of their provenance; discrepancies in this mapping point to
causes of the queries' differences. Exploiting the queries gives Explain3D an
edge over traditional schema matching and record linkage techniques, which are
query-agnostic. Our work makes the following contributions: (1) We formalize
the problem of deriving optimal explanations for the differences of the results
of semantically similar queries over disjoint datasets. (2) We design a 3-stage
framework for solving the optimal explanation problem. (3) We develop a
smart-partitioning optimizer that improves the efficiency of the framework by
orders of magnitude. (4)~We experiment with real-world and synthetic data to
demonstrate that Explain3D can derive precise explanations efficiently.",Databases (cs.DB),,[Submitted on 21 Mar 2019]
CityFlow: A City-Scale Benchmark for Multi-Target Multi-Camera Vehicle Tracking and Re-Identification,"Zheng Tang, Milind Naphade, Ming-Yu Liu, Xiaodong Yang, Stan Birchfield, Shuo Wang, Ratnesh Kumar, David Anastasiu, Jenq-Neng Hwang","Urban traffic optimization using traffic cameras as sensors is driving the
need to advance state-of-the-art multi-target multi-camera (MTMC) tracking.
This work introduces CityFlow, a city-scale traffic camera dataset consisting
of more than 3 hours of synchronized HD videos from 40 cameras across 10
intersections, with the longest distance between two simultaneous cameras being
2.5 km. To the best of our knowledge, CityFlow is the largest-scale dataset in
terms of spatial coverage and the number of cameras/videos in an urban
environment. The dataset contains more than 200K annotated bounding boxes
covering a wide range of scenes, viewing angles, vehicle models, and urban
traffic flow conditions. Camera geometry and calibration information are
provided to aid spatio-temporal analysis. In addition, a subset of the
benchmark is made available for the task of image-based vehicle
re-identification (ReID). We conducted an extensive experimental evaluation of
baselines/state-of-the-art approaches in MTMC tracking, multi-target
single-camera (MTSC) tracking, object detection, and image-based ReID on this
dataset, analyzing the impact of different network architectures, loss
functions, spatio-temporal models and their combinations on task effectiveness.
An evaluation server is launched with the release of our benchmark at the 2019
AI City Challenge (this https URL) that allows researchers to
compare the performance of their newest techniques. We expect this dataset to
catalyze research in this field, propel the state-of-the-art forward, and lead
to deployed traffic optimization(s) in the real world.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 21 Mar 2019 (v1), last revised 5 Apr 2019 (this version, v4)]"
Distributed off-Policy Actor-Critic Reinforcement Learning with Policy Consensus,"Yan Zhang, Michael M. Zavlanos","In this paper, we propose a distributed off-policy actor critic method to
solve multi-agent reinforcement learning problems. Specifically, we assume that
all agents keep local estimates of the global optimal policy parameter and
update their local value function estimates independently. Then, we introduce
an additional consensus step to let all the agents asymptotically achieve
agreement on the global optimal policy function. The convergence analysis of
the proposed algorithm is provided and the effectiveness of the proposed
algorithm is validated using a distributed resource allocation example.
Compared to relevant distributed actor critic methods, here the agents do not
share information about their local tasks, but instead they coordinate to
estimate the global policy function.",Machine Learning (cs.LG),; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML),[Submitted on 21 Mar 2019]
Local Interactions for Cohesive Flexible Swarms,"Rotem Manor, Ariel Barel, Alfred M. Bruckstein","Distributed gathering algorithms aim to achieve complete visibility graphs
via a ""never lose a neighbour"" policy. We suggest a method to maintain
connected graph topologies, while reducing the number of effective edges in the
graph to order n. This allows to achieve different goals and swarming
behaviours: the system remains connected but flexible, hence can maneuver in
environments that are replete with obstacles and narrow passages, etc.",Multiagent Systems (cs.MA),,[Submitted on 21 Mar 2019]
Deep Learning with Anatomical Priors: Imitating Enhanced Autoencoders in Latent Space for Improved Pelvic Bone Segmentation in MRI,"Duc Duy Pham, Gurbandurdy Dovletov, Sebastian Warwas, Stefan Landgraeber, Marcus Jäger, Josef Pauli","We propose a 2D Encoder-Decoder based deep learning architecture for semantic
segmentation, that incorporates anatomical priors by imitating the encoder
component of an autoencoder in latent space. The autoencoder is additionally
enhanced by means of hierarchical features, extracted by an U-Net module. Our
suggested architecture is trained in an end-to-end manner and is evaluated on
the example of pelvic bone segmentation in MRI. A comparison to the standard
U-Net architecture shows promising improvements.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 21 Mar 2019]
Reduction of Markov Chains using a Value-of-Information-Based Approach,"Isaac J. Sledge, Jose C. Principe","In this paper, we propose an approach to obtain reduced-order models of
Markov chains. Our approach is composed of two information-theoretic processes.
The first is a means of comparing pairs of stationary chains on different state
spaces, which is done via the negative Kullback-Leibler divergence defined on a
model joint space. Model reduction is achieved by solving a
value-of-information criterion with respect to this divergence. Optimizing the
criterion leads to a probabilistic partitioning of the states in the high-order
Markov chain. A single free parameter that emerges through the optimization
process dictates both the partition uncertainty and the number of state groups.
We provide a data-driven means of choosing the `optimal' value of this free
parameter, which sidesteps needing to a priori know the number of state groups
in an arbitrary chain.",Information Theory (cs.IT),,[Submitted on 21 Mar 2019]
A Computer-Aided System for Determining the Application Range of a Warfarin Clinical Dosing Algorithm Using Support Vector Machines with a Polynomial Kernel Function,"Ashkan Sharabiani, Adam Bress, William Galanter, Rezvan Nazempour, Houshang Darabi","Determining the optimal initial dose for warfarin is a critically important
task. Several factors have an impact on the therapeutic dose for individual
patients, such as patients' physical attributes (Age, Height, etc.), medication
profile, co-morbidities, and metabolic genotypes (CYP2C9 and VKORC1). These
wide range factors influencing therapeutic dose, create a complex environment
for clinicians to determine the optimal initial dose. Using a sample of 4,237
patients, we have proposed a companion classification model to one of the most
popular dosing algorithms (International Warfarin Pharmacogenetics Consortium
(IWPC) clinical model), which identifies the appropriate cohort of patients for
applying this model. The proposed model functions as a clinical decision
support system which assists clinicians in dosing. We have developed a
classification model using Support Vector Machines, with a polynomial kernel
function to determine if applying the dose prediction model is appropriate for
a given patient. The IWPC clinical model will only be used if the patient is
classified as ""Safe for model"". By using the proposed methodology, the dosing
mode's prediction accuracy increases by 15 percent in terms of Root Mean
Squared Error and 17 percent in terms of Mean Absolute Error in dose estimates
of patients classified as ""Safe for model"".",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 21 Mar 2019]
Using association rule mining and ontologies to generate metadata recommendations from multiple biomedical databases,"Marcos Martínez-Romero, Martin J. O'Connor, Attila L. Egyedi, Debra Willrett, Josef Hardi, John Graybeal, Mark A. Musen","Metadata-the machine-readable descriptions of the data-are increasingly seen
as crucial for describing the vast array of biomedical datasets that are
currently being deposited in public repositories. While most public
repositories have firm requirements that metadata must accompany submitted
datasets, the quality of those metadata is generally very poor. A key problem
is that the typical metadata acquisition process is onerous and time consuming,
with little interactive guidance or assistance provided to users. Secondary
problems include the lack of validation and sparse use of standardized terms or
ontologies when authoring metadata. There is a pressing need for improvements
to the metadata acquisition process that will help users to enter metadata
quickly and accurately. In this paper we outline a recommendation system for
metadata that aims to address this challenge. Our approach uses association
rule mining to uncover hidden associations among metadata values and to
represent them in the form of association rules. These rules are then used to
present users with real-time recommendations when authoring metadata. The
novelties of our method are that it is able to combine analyses of metadata
from multiple repositories when generating recommendations and can enhance
those recommendations by aligning them with ontology terms. We implemented our
approach as a service integrated into the CEDAR Workbench metadata authoring
platform, and evaluated it using metadata from two public biomedical
repositories: US-based National Center for Biotechnology Information (NCBI)
BioSample and European Bioinformatics Institute (EBI) BioSamples. The results
show that our approach is able to use analyses of previous entered metadata
coupled with ontology-based mappings to present users with accurate
recommendations when authoring metadata.",Databases (cs.DB),; Machine Learning (cs.LG),[Submitted on 21 Mar 2019]
Fast and accurate reconstruction of HARDI using a 1D encoder-decoder convolutional network,"Shi Yin, Zhengqiang Zhang, Qinmu Peng, Xinge You","High angular resolution diffusion imaging (HARDI) demands a lager amount of
data measurements compared to diffusion tensor imaging, restricting its use in
practice. In this work, we explore a learning-based approach to reconstruct
HARDI from a smaller number of measurements in q-space. The approach aims to
directly learn the mapping relationship between the measured and HARDI signals
from the collecting HARDI acquisitions of other subjects. Specifically, the
mapping is represented as a 1D encoder-decoder convolutional neural network
under the guidance of the compressed sensing (CS) theory for HARDI
reconstruction. The proposed network architecture mainly consists of two parts:
an encoder network produces the sparse coefficients and a decoder network
yields a reconstruction result. Experiment results demonstrate we can robustly
reconstruct HARDI signals with the accurate results and fast speed.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 21 Mar 2019]
Proofware: Proof of Useful Work Blockchain Consensus Protocol for Decentralized Applications,"Zhongli Dong, Young Choon Lee, Albert Y. Zomaya","In a blockchain system, consensus protocol as an incentive and security
mechanism, is to ensure the participants to build the block honestly and
effectively. There are different consensus protocols for blockchain, like Proof
of work (PoW), Proof of Stake (PoS), Proof of Space (PoSpace), Proof of
Activities etc. But most of these consensus protocols are not designed for
doing some useful jobs for society because of too much competition and
scalability limitation. Massive electric power and computing resources,
including CPU, RAM, storage and sensors have been wasted to run blockchain
network based on these consensus protocols. Current frameworks and middleware
for building decentralised applications (dApps) are largely limited to simple
and less useful jobs. In this paper, we present Proofware which is designed for
developers to build their dApps easily with existing public/crowd-based
computing resources. Under Proofware, developers can develop and test their own
Proof of Useful Work (PoUW) consensus protocols. Also, rather than depending on
a centralised accounting system, each dApp has an embedded currency system to
keep the whole incentive system decentralised, fair, transparent, stable and
sustainable. Based on Proofware, we have built a crowd based video sharing
application, called OurTube, as a case study. By the OurTube example, it has
shown Proofware significantly improves the productivity to build crowd-based
computing system with the features of cost-effectiveness, anti-censorship,
elasticity and financial sustainability.","Distributed, Parallel, and Cluster Computing (cs.DC)",,[Submitted on 22 Mar 2019]
Learning Mixtures of Separable Dictionaries for Tensor Data: Analysis and Algorithms,"Mohsen Ghassemi, Zahra Shakeri, Anand D. Sarwate, Waheed U. Bajwa","This work addresses the problem of learning sparse representations of tensor
data using structured dictionary learning. It proposes learning a mixture of
separable dictionaries to better capture the structure of tensor data by
generalizing the separable dictionary learning model. Two different approaches
for learning mixture of separable dictionaries are explored and sufficient
conditions for local identifiability of the underlying dictionary are derived
in each case. Moreover, computational algorithms are developed to solve the
problem of learning mixture of separable dictionaries in both batch and online
settings. Numerical experiments are used to show the usefulness of the proposed
model and the efficacy of the developed algorithms.",Machine Learning (cs.LG),; Information Theory (cs.IT); Signal Processing (eess.SP); Machine Learning (stat.ML),"[Submitted on 22 Mar 2019 (v1), last revised 14 Jun 2020 (this version, v2)]"
A Novel Framework for Software Defined Wireless Body Area Network,"Khalid Hasan, Xin-Wen Wu, Kamanashis Biswas, Khandakar Ahmed","Software Defined Networking (SDN) has gained huge popularity in replacing
traditional network by offering flexible and dynamic network management. It has
drawn significant attention of the researchers from both academia and
industries. Particularly, incorporating SDN in Wireless Body Area Network
(WBAN) applications indicates promising benefits in terms of dealing with
challenges like traffic management, authentication, energy efficiency etc.
while enhancing administrative control. This paper presents a novel framework
for Software Defined WBAN (SDWBAN), which brings the concept of SDN technology
into WBAN applications. By decoupling the control plane from data plane and
having more programmatic control would assist to overcome the current lacking
and challenges of WBAN. Therefore, we provide a conceptual framework for SDWBAN
with packet flow model and a future direction of research pertaining to SDWBAN.",Networking and Internet Architecture (cs.NI),,[Submitted on 22 Mar 2019]
Towards Optimal Structured CNN Pruning via Generative Adversarial Learning,"Shaohui Lin, Rongrong Ji, Chenqian Yan, Baochang Zhang, Liujuan Cao, Qixiang Ye, Feiyue Huang, David Doermann","Structured pruning of filters or neurons has received increased focus for
compressing convolutional neural networks. Most existing methods rely on
multi-stage optimizations in a layer-wise manner for iteratively pruning and
retraining which may not be optimal and may be computation intensive. Besides,
these methods are designed for pruning a specific structure, such as filter or
block structures without jointly pruning heterogeneous structures. In this
paper, we propose an effective structured pruning approach that jointly prunes
filters as well as other structures in an end-to-end manner. To accomplish
this, we first introduce a soft mask to scale the output of these structures by
defining a new objective function with sparsity regularization to align the
output of baseline and network with this mask. We then effectively solve the
optimization problem by generative adversarial learning (GAL), which learns a
sparse soft mask in a label-free and an end-to-end manner. By forcing more
scaling factors in the soft mask to zero, the fast iterative
shrinkage-thresholding algorithm (FISTA) can be leveraged to fast and reliably
remove the corresponding structures. Extensive experiments demonstrate the
effectiveness of GAL on different datasets, including MNIST, CIFAR-10 and
ImageNet ILSVRC 2012. For example, on ImageNet ILSVRC 2012, the pruned
ResNet-50 achieves 10.88\% Top-5 error and results in a factor of 3.7x speedup.
This significantly outperforms state-of-the-art methods.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 22 Mar 2019]
Robust Hybrid Precoding for Beam Misalignment in Millimeter-Wave Communications,"Chandan Pradhan, Ang Li, Li Zhuo, Yonghui Li, Branka Vucetic","In this paper, we focus on the phenomenon of beam misalignment in
Millimeter-wave (mmWave) multi-receiver communication systems, and propose
robust hybrid precoding designs that alleviate the performance loss caused by
this effect. We consider two distinct design methodologies: I) the synthesis of
a `flat mainlobe' beam model which maximizes the minimum effective array gain
over the beam misalignment range, and II) the inclusion of the `error
statistics' into the design, where the array response incorporating the
distribution of the misalignment error is derived. For both design
methodologies, we propose a hybrid precoding design that approximates the
robust fully-digital precoder, which is obtained via alternating optimization
based on the gradient projection (GP) method. We also propose a low-complexity
alternative to the GP algorithm based on the least square projection (LSP), and
we further deploy a second-stage digital precoder to mitigate any residual
inter-receiver interference after the hybrid analog-digital precoding.
Numerical results show that the robust hybrid precoding designs can effectively
alleviate the performance degradation incurred by beam misalignment.",Networking and Internet Architecture (cs.NI),; Information Theory (cs.IT),[Submitted on 22 Mar 2019]
DQN with model-based exploration: efficient learning on environments with sparse rewards,"Stephen Zhen Gou, Yuyang Liu","We propose Deep Q-Networks (DQN) with model-based exploration, an algorithm
combining both model-free and model-based approaches that explores better and
learns environments with sparse rewards more efficiently. DQN is a
general-purpose, model-free algorithm and has been proven to perform well in a
variety of tasks including Atari 2600 games since it's first proposed by Minh
et el. However, like many other reinforcement learning (RL) algorithms, DQN
suffers from poor sample efficiency when rewards are sparse in an environment.
As a result, most of the transitions stored in the replay memory have no
informative reward signal, and provide limited value to the convergence and
training of the Q-Network. However, one insight is that these transitions can
be used to learn the dynamics of the environment as a supervised learning
problem. The transitions also provide information of the distribution of
visited states. Our algorithm utilizes these two observations to perform a
one-step planning during exploration to pick an action that leads to states
least likely to be seen, thus improving the performance of exploration. We
demonstrate our agent's performance in two classic environments with sparse
rewards in OpenAI gym: Mountain Car and Lunar Lander.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 22 Mar 2019]
Patient Clustering Improves Efficiency of Federated Machine Learning to predict mortality and hospital stay time using distributed Electronic Medical Records,"Li Huang, Dianbo Liu","Electronic medical records (EMRs) supports the development of machine
learning algorithms for predicting disease incidence, patient response to
treatment, and other healthcare events. But insofar most algorithms have been
centralized, taking little account of the decentralized, non-identically
independently distributed (non-IID), and privacy-sensitive characteristics of
EMRs that can complicate data collection, sharing and learning. To address this
challenge, we introduced a community-based federated machine learning (CBFL)
algorithm and evaluated it on non-IID ICU EMRs. Our algorithm clustered the
distributed data into clinically meaningful communities that captured similar
diagnoses and geological locations, and learnt one model for each community.
Throughout the learning process, the data was kept local on hospitals, while
locally-computed results were aggregated on a server. Evaluation results show
that CBFL outperformed the baseline FL algorithm in terms of Area Under the
Receiver Operating Characteristic Curve (ROC AUC), Area Under the
Precision-Recall Curve (PR AUC), and communication cost between hospitals and
the server. Furthermore, communities' performance difference could be explained
by how dissimilar one community was to others.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 22 Mar 2019]
Transparent Machine Education of Neural Networks for Swarm Shepherding Using Curriculum Design,"Alexander Gee, Hussein Abbass","Swarm control is a difficult problem due to the need to guide a large number
of agents simultaneously. We cast the problem as a shepherding problem, similar
to biological dogs guiding a group of sheep towards a goal. The shepherd needs
to deal with complex and dynamic environments and make decisions in order to
direct the swarm from one location to another. In this paper, we design a novel
curriculum to teach an artificial intelligence empowered agent to shepherd in
the presence of the large state space associated with the shepherding problem
and in a transparent manner. The results show that a properly designed
curriculum could indeed enhance the speed of learning and the complexity of
learnt behaviours.",Computers and Society (cs.CY),; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE),[Submitted on 4 Jan 2019]
Verification of Detectability in Petri Nets Using Verifier Nets,"Hao Lan, Yin Tong, Carla Seatzu, Jin Guo","Detectability describes the property of a system whose current and the
subsequent states can be uniquely determined after a finite number of
observations. In this paper, we developed a novel approach to verifying strong
detectability and periodically strong detectability of bounded labeled Petri
nets. Our approach is based on the analysis of the basis reachability graph of
a special Petri net, called Verifier Net, that is built from the Petri net
model of the given system. Without computing the whole reachability space and
without enumerating all the markings, the proposed approaches are more
efficient.",Systems and Control (eess.SY),,[Submitted on 21 Mar 2019]
Conditional Capacity and Transmit Signal Design for SWIPT Systems with Multiple Nonlinear Energy Harvesting Receivers,"Rania Morsi, Vahid Jamali, Amelie Hagelauer, Derrick Wing Kwan Ng, Robert Schober","We study information-theoretic limits for simultaneous wireless information
and power transfer (SWIPT) systems employing nonlinear radio frequency (RF)
energy harvesting (EH) receivers (Rxs). In particular, we consider a SWIPT
system with one transmitter that broadcasts a common signal to an information
decoding (ID) Rx and multiple EH Rxs. Owing to the nonlinearity of the EH Rxs'
circuitry, the efficiency of wireless power transfer depends on the waveform of
the transmitted signal. We aim to answer the following fundamental question:
What is the optimal input distribution of the transmit signal waveform that
maximizes the information transfer rate at the ID Rx conditioned on individual
minimum required direct-current (DC) powers to be harvested at the EH Rxs?
Specifically, we study the conditional capacity problem of a SWIPT system
impaired by additive white Gaussian noise subject to average-power (AP) and
peak power (PP) constraints at the transmitter and nonlinear EH constraints at
the EH Rxs. To this end, we develop a novel nonlinear EH model that captures
the saturation of the harvested DC power by taking into account the reverse
breakdown current of the rectifying diode. We derive a novel semiclosed-form
expression for the harvested DC power, which simplifies to closed form for low
input RF powers. The derived analytical expressions are shown to closely match
circuit simulation results. We solve the conditional capacity problem for real-
and complex-valued signalling and prove that the optimal input distribution
that maximizes the rate-energy (R-E) region is unique and discrete with a
finite number of mass points. Furthermore, we show that the boundary of the R-E
region saturates for high PP constraints due to the saturation of the harvested
DC power for high input RF powers. In addition, we devise a suboptimal input
distribution whose R-E tradeoff performance is close to optimal.",Information Theory (cs.IT),,"[Submitted on 21 Mar 2019 (v1), last revised 2 Dec 2019 (this version, v2)]"
Blockchain and its Potential in Education,"Cristina Turcu, Cornel Turcu, Iuliana Chiuchisan","The proposed paper presents a literature review regarding the status of
integrating the dynamic blockchain technology in the educational field.
Blockchain is a relatively new technology and the same is its implementation in
education. The emerging need in this area of research, which still is in its
infancy, is justified by the possible use cases; some of these cases are in
piloting phase, while others have already been adopted by educational
institutions. This paper focuses on extending knowledge about blockchain and on
identifying the benefits, risks and the associated challenges regarding the
successful implementation of blockchain-based solutions in the field of
education, fully in line with standards and guidelines for quality assurance.",Computers and Society (cs.CY),; Cryptography and Security (cs.CR),[Submitted on 5 Mar 2019]
Tackling Unit Commitment and Load Dispatch Problems Considering All Constraints with Evolutionary Computation,"Danilo Vasconcellos Vargas, Junichi Murata, Hirotaka Takano","Unit commitment and load dispatch problems are important and complex problems
in power system operations that have being traditionally solved separately. In
this paper, both problems are solved together without approximations or
simplifications. In fact, the problem solved has a massive amount of
grid-connected photovoltaic units, four pump-storage hydro plants as energy
storage units and ten thermal power plants, each with its own set of operation
requirements that need to be satisfied. To face such a complex constrained
optimization problem an adaptive repair method is proposed. By including a
given repair method itself as a parameter to be optimized, the proposed
adaptive repair method avoid any bias in repair choices. Moreover, this results
in a repair method that adapt to the problem and will improve together with the
solution during optimization. Experiments are conducted revealing that the
proposed method is capable of surpassing exact method solutions on a simplified
version of the problem with approximations as well as solve the otherwise
intractable complete problem without simplifications. Moreover, since the
proposed approach can be applied to other problems in general and it may not be
obvious how to choose the constraint handling for a certain constraint, a
guideline is provided explaining the reasoning behind. Thus, this paper open
further possibilities to deal with the ever changing types of generation units
and other similarly complex operation/schedule optimization problems with many
difficult constraints.",Computers and Society (cs.CY),"; Computational Engineering, Finance, and Science (cs.CE); Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY)",[Submitted on 6 Mar 2019]
The Seven Sins of Personal-Data Processing Systems under GDPR,"Supreeth Shastri, Melissa Wasserman, Vijay Chidambaram","In recent years, our society is being plagued by unprecedented levels of
privacy and security breaches. To rein in this trend, the European Union, in
2018, introduced a comprehensive legislation called the General Data Protection
Regulation (GDPR). In this paper, we review GDPR from a system design
perspective, and identify how its regulations conflict with the design,
architecture, and operation of modern systems. We illustrate these conflicts
via the seven GDPR sins: storing data forever; reusing data indiscriminately;
walled gardens and black markets; risk-agnostic data processing; hiding data
breaches; making unexplainable decisions; treating security as a secondary
goal. Our findings reveal a deep-rooted tussle between GDPR requirements and
how modern systems have evolved. We believe that achieving compliance requires
comprehensive, grounds up solutions, and anything short would amount to fixing
a leaky faucet in a sinking ship.",Computers and Society (cs.CY),; Cryptography and Security (cs.CR),"[Submitted on 8 Mar 2019 (v1), last revised 15 May 2019 (this version, v2)]"
Automatically Generating Engaging Presentation Slide Decks,"Thomas Winters, Kory W. Mathewson","Talented public speakers have thousands of hours of practice. One means of
improving public speaking skills is practice through improvisation, e.g.
presenting an improvised presentation using an unseen slide deck. We present
TEDRIC, a novel system capable of generating coherent slide decks based on a
single topic suggestion. It combines semantic word webs with text and image
data sources to create an engaging slide deck with an overarching theme. We
found that audience members perceived the quality of improvised presentations
using these generated slide decks to be on par with presentations using human
created slide decks for the Improvised TED Talk performance format. TEDRIC is
thus a valuable new creative tool for improvisers to perform with, and for
anyone looking to improve their presentation skills.",Computers and Society (cs.CY),,[Submitted on 2 Mar 2019]
A WCET-aware cache coloring technique for reducing interference in real-time systems,"Fabien Bouquillon, Clément Ballabriga, Giuseppe Lipari, Smail Niar","The predictability of a system is the condition to give saferbound on worst
case execution timeof real-time tasks which are running on it. Commercial
off-the-shelf(COTS) processors are in-creasingly used in embedded systems and
contain shared cache memory. This component hasa hard predictable behavior
because its state depends of theexecution history of the this http URL increase
predictability of COTS component we use cache coloring, a technique widely
usedto partition cache memory. Our main contribution is a WCET aware heuristic
which parti-tion task according to the needs of each task. Our experiments are
made with CPLEX an ILPsolver with random tasks set generated running on
preemptive system scheduled with earliestdeadline first(EDF).",Operating Systems (cs.OS),"; Distributed, Parallel, and Cluster Computing (cs.DC)","[Submitted on 22 Mar 2019 (v1), last revised 20 May 2019 (this version, v4)]"
New methodology for facilitating the food wastage quantification. Identifying gaps and data inconsistencies,"Hector Barco Cobalea (1 and 2), Iraia Oribe Garcia (1 and 2), Maria Virginia Vargas Viedma (1 and 2), Cruz Enrique Borges (1 and 2), Cristina Martin Andonegui (1 and 2), Ainhoa Alonso Vicario (1 and 2) ((1) DeustoTech - Fundacion Deusto (2) Facultad Ingenieria, Universidad de Deusto)","The work aims at providing a new methodology to facilitate the process of
quantifying the food waste according to European standards all along the
agrifood chain combining information that is becoming available at local level.
This new methodology generates straightforward and easy-to-interpret results
for the decision making process in the framework of the quantification of the
food waste at local and supralocal scale and it provides adequate procedures
which are easy adaptable to the specific circumstances in each municipality.
Moreover, this method could have applications for larger territorial contexts,
as the national scale, detecting possible points for improvement of the current
official figures at this respect.",Computers and Society (cs.CY),,"[Submitted on 7 Mar 2019 (v1), last revised 6 May 2019 (this version, v2)]"
Statistical Privacy in Distributed Average Consensus on Bounded Real Inputs,"Nirupam Gupta, Jonathan Katz, Nikhil Chopra","This paper proposes a privacy protocol for distributed average consensus
algorithms on bounded real-valued inputs that guarantees statistical privacy of
honest agents' inputs against colluding (passive adversarial) agents, if the
set of colluding agents is not a vertex cut in the underlying communication
network. This implies that privacy of agents' inputs is preserved against $t$
number of arbitrary colluding agents if the connectivity of the communication
network is at least $(t+1)$. A similar privacy protocol has been proposed for
the case of bounded integral inputs in our previous
paper~\cite{gupta2018information}. However, many applications of distributed
consensus concerning distributed control or state estimation deal with
real-valued inputs. Thus, in this paper we propose an extension of the privacy
protocol in~\cite{gupta2018information}, for bounded real-valued agents'
inputs, where bounds are known apriori to all the agents.",Cryptography and Security (cs.CR),; Information Theory (cs.IT); Systems and Control (eess.SY),[Submitted on 20 Mar 2019]
A Novel Independent RNN Approach to Classification of Seizures against Non-seizures,"Xinghua Yao, Qiang Cheng, Guo-Qiang Zhang","In current clinical practices, electroencephalograms (EEG) are reviewed and
analyzed by trained neurologists to provide supports for therapeutic decisions.
Manual reviews can be laborious and error prone. Automatic and accurate
seizure/non-seizure classification methods are desirable. A critical challenge
is that seizure morphologies exhibit considerable variabilities. In order to
capture essential seizure features, this paper leverages an emerging deep
learning model, the independently recurrent neural network (IndRNN), to
construct a new approach for the seizure/non-seizure classification. This new
approach gradually expands the time scales, thereby extracting temporal and
spatial features from the local time duration to the entire record. Evaluations
are conducted with cross-validation experiments across subjects over the noisy
data of CHB-MIT. Experimental results demonstrate that the proposed approach
outperforms the current state-of-the-art methods. In addition, we explore how
the segment length affects the classification performance. Thirteen different
segment lengths are assessed, showing that the classification performance
varies over the segment lengths, and the maximal fluctuating margin is more
than 4%. Thus, the segment length is an important factor influencing the
classification performance.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 22 Mar 2019]
Improving Safety in Reinforcement Learning Using Model-Based Architectures and Human Intervention,"Bharat Prakash, Mohit Khatwani, Nicholas Waytowich, Tinoosh Mohsenin","Recent progress in AI and Reinforcement learning has shown great success in
solving complex problems with high dimensional state spaces. However, most of
these successes have been primarily in simulated environments where failure is
of little or no consequence. Most real-world applications, however, require
training solutions that are safe to operate as catastrophic failures are
inadmissible especially when there is human interaction involved. Currently,
Safe RL systems use human oversight during training and exploration in order to
make sure the RL agent does not go into a catastrophic state. These methods
require a large amount of human labor and it is very difficult to scale up. We
present a hybrid method for reducing the human intervention time by combining
model-based approaches and training a supervised learner to improve sample
efficiency while also ensuring safety. We evaluate these methods on various
grid-world environments using both standard and visual representations and show
that our approach achieves better performance in terms of sample efficiency,
number of catastrophic states reached as well as overall task performance
compared to traditional model-free approaches",Artificial Intelligence (cs.AI),,[Submitted on 22 Mar 2019]
A resnet-based universal method for speckle reduction in optical coherence tomography images,"Cai Ning, Shi Fei, Hu Dianlin, Chen Yang","In this work we propose a ResNet-based universal method for speckle reduction
in optical coherence tomography (OCT) images. The proposed model contains 3
main modules: Convolution-BN-ReLU, Branch and Residual module. Unlike
traditional algorithms, the model can learn from training data instead of
selecting parameters manually such as noise level. Application of this proposed
method to the OCT images shows a more than 22 dB signal-to-noise ratio
improvement in speckle noise reduction with minimal structure blurring. The
proposed method provides strong generalization ability and can process noisy
other types of OCT images without retraining. It outperforms other filtering
methods in suppressing speckle noises and revealing subtle features.",Computer Vision and Pattern Recognition (cs.CV),; Image and Video Processing (eess.IV),[Submitted on 22 Mar 2019]
Unsupervised Deformable Registration for Multi-Modal Images via Disentangled Representations,"Chen Qin, Bibo Shi, Rui Liao, Tommaso Mansi, Daniel Rueckert, Ali Kamen","We propose a fully unsupervised multi-modal deformable image registration
method (UMDIR), which does not require any ground truth deformation fields or
any aligned multi-modal image pairs during training. Multi-modal registration
is a key problem in many medical image analysis applications. It is very
challenging due to complicated and unknown relationships between different
modalities. In this paper, we propose an unsupervised learning approach to
reduce the multi-modal registration problem to a mono-modal one through image
disentangling. In particular, we decompose images of both modalities into a
common latent shape space and separate latent appearance spaces via an
unsupervised multi-modal image-to-image translation approach. The proposed
registration approach is then built on the factorized latent shape code, with
the assumption that the intrinsic shape deformation existing in original image
domain is preserved in this latent space. Specifically, two metrics have been
proposed for training the proposed network: a latent similarity metric defined
in the common shape space and a learningbased image similarity metric based on
an adversarial loss. We examined different variations of our proposed approach
and compared them with conventional state-of-the-art multi-modal registration
methods. Results show that our proposed methods achieve competitive performance
against other methods at substantially reduced computation time.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 22 Mar 2019]
A Large Scale Comparison of Tetrahedral and Hexahedral Elements for Finite Element Analysis,"Teseo Schneider, Yixin Hu, Xifeng Gao, Jeremie Dumas, Denis Zorin, Daniele Panozzo","The Finite Element Method (FEM) is widely used to solve discrete Partial
Differential Equations (PDEs) in engineering applications. The popularity of
FEM led to the development of a large family of variants, and, while their
theoretical properties (such as convergence rate, stability, etc.) are
understood well, their practical performance have not been systematically
studied for large collections of automatically meshed 3D geometry.
We introduce a set of benchmark problems, starting from simple cases with an
analytical solution, moving to commonly used test problem setups, and finally
fabricating solutions for thousands of real-world, automatically meshed
geometries. For all these cases, we use state-of-the-art meshing tools to
create both unstructured (tetrahedral) and structured (hexahedral) meshes, and
compare the performance of different element types for a wide spectrum of
elliptic PDEs ranging from heat diffusion to fluid propagation.
We observe that, while linear tetrahedral elements perform poorly, often
leading to locking artefacts, quadratic tetrahedral elements outperform
hexahedral elements in all settings we tested. This observation suggests that
for most problems in static structural analysis, thermal analysis, and low
reynolds number flows, it is unnecessary to target automatic hex mesh
generation, since high-quality results can be obtained with unstructured
meshes, which can be created robustly and automatically with existing meshing
algorithms.
We released the description of the benchmark problems, meshes, and reference
implementation of our testing infrastructure. This enables statistically
significant comparisons between different FE methods, which we believe will
provide a guide in the development of new meshing and FEA techniques.",Numerical Analysis (math.NA),,"[Submitted on 22 Mar 2019 (v1), last revised 16 Oct 2019 (this version, v2)]"
"A Type-coherent, Expressive Representation as an Initial Step to Language Understanding","Gene Louis Kim, Lenhart Schubert","A growing interest in tasks involving language understanding by the NLP
community has led to the need for effective semantic parsing and inference.
Modern NLP systems use semantic representations that do not quite fulfill the
nuanced needs for language understanding: adequately modeling language
semantics, enabling general inferences, and being accurately recoverable. This
document describes underspecified logical forms (ULF) for Episodic Logic (EL),
which is an initial form for a semantic representation that balances these
needs. ULFs fully resolve the semantic type structure while leaving issues such
as quantifier scope, word sense, and anaphora unresolved; they provide a
starting point for further resolution into EL, and enable certain structural
inferences without further resolution. This document also presents preliminary
results of creating a hand-annotated corpus of ULFs for the purpose of training
a precise ULF parser, showing a three-person pairwise interannotator agreement
of 0.88 on confident annotations. We hypothesize that a divide-and-conquer
approach to semantic parsing starting with derivation of ULFs will lead to
semantic analyses that do justice to subtle aspects of linguistic meaning, and
will enable construction of more accurate semantic parsers.",Computation and Language (cs.CL),; Artificial Intelligence (cs.AI),"[Submitted on 22 Mar 2019 (v1), last revised 28 Mar 2019 (this version, v2)]"
Cliques in projective space and construction of Cyclic Grassmannian Codes,"Ismael Gutiérrez García, Ivan Molina Naizir","The construction of Grassmannian codes in some projective space is of highly
mathematical nature and requires strong computational power for the resulting
searches. In this paper was constructed, using GAP System for Computational
Discrete Algebra and Wolfram Mathematica, cliques in the projective space Pq(n)
and then we use these to produce cyclic Grassmannian codes.",Information Theory (cs.IT),,[Submitted on 22 Mar 2019]
Optimization Methods for Interpretable Differentiable Decision Trees in Reinforcement Learning,"Andrew Silva, Taylor Killian, Ivan Dario Jimenez Rodriguez, Sung-Hyun Son, Matthew Gombolay","Decision trees are ubiquitous in machine learning for their ease of use and
interpretability. Yet, these models are not typically employed in reinforcement
learning as they cannot be updated online via stochastic gradient descent. We
overcome this limitation by allowing for a gradient update over the entire tree
that improves sample complexity affords interpretable policy extraction. First,
we include theoretical motivation on the need for policy-gradient learning by
examining the properties of gradient descent over differentiable decision
trees. Second, we demonstrate that our approach equals or outperforms a neural
network on all domains and can learn discrete decision trees online with
average rewards up to 7x higher than a batch-trained decision tree. Third, we
conduct a user study to quantify the interpretability of a decision tree, rule
list, and a neural network with statistically significant results ($p <
0.001$).",Machine Learning (cs.LG),; Machine Learning (stat.ML),"[Submitted on 22 Mar 2019 (v1), last revised 25 Jun 2020 (this version, v5)]"
Pose Estimation of Periacetabular Osteotomy Fragments with Intraoperative X-Ray Navigation,"Robert B. Grupp, Rachel A. Hegeman, Ryan J. Murphy, Clayton P. Alexander, Yoshito Otake, Benjamin A. McArthur, Mehran Armand, Russell H. Taylor","Objective: State of the art navigation systems for pelvic osteotomies use
optical systems with external fiducials. We propose the use of X-Ray navigation
for pose estimation of periacetabular fragments without fiducials. Methods: A
2D/3D registration pipeline was developed to recover fragment pose. This
pipeline was tested through an extensive simulation study and 6 cadaveric
surgeries. Using osteotomy boundaries in the fluoroscopic images, the
preoperative plan is refined to more accurately match the intraoperative shape.
Results: In simulation, average fragment pose errors were 1.3°/1.7 mm when
the planned fragment matched the intraoperative fragment, 2.2°/2.1 mm when
the plan was not updated to match the true shape, and 1.9°/2.0 mm when the
fragment shape was intraoperatively estimated. In cadaver experiments, the
average pose errors were 2.2°/2.2 mm, 3.8°/2.5 mm, and 3.5°/2.2
mm when registering with the actual fragment shape, a preoperative plan, and an
intraoperatively refined plan, respectively. Average errors of the lateral
center edge angle were less than 2° for all fragment shapes in simulation
and cadaver experiments. Conclusion: The proposed pipeline is capable of
accurately reporting femoral head coverage within a range clinically identified
for long-term joint survivability. Significance: Human interpretation of
fragment pose is challenging and usually restricted to rotation about a single
anatomical axis. The proposed pipeline provides an intraoperative estimate of
rigid pose with respect to all anatomical axes, is compatible with minimally
invasive incisions, and has no dependence on external fiducials.",Computer Vision and Pattern Recognition (cs.CV),; Image and Video Processing (eess.IV),"[Submitted on 22 Mar 2019 (v1), last revised 9 May 2019 (this version, v2)]"
Unsupervised Speech Enhancement Based on Multichannel NMF-Informed Beamforming for Noise-Robust Automatic Speech Recognition,"Kazuki Shimada, Yoshiaki Bando, Masato Mimura, Katsutoshi Itoyama, Kazuyoshi Yoshii, Tatsuya Kawahara","This paper describes multichannel speech enhancement for improving automatic
speech recognition (ASR) in noisy environments. Recently, the minimum variance
distortionless response (MVDR) beamforming has widely been used because it
works well if the steering vector of speech and the spatial covariance matrix
(SCM) of noise are given. To estimating such spatial information, conventional
studies take a supervised approach that classifies each time-frequency (TF) bin
into noise or speech by training a deep neural network (DNN). The performance
of ASR, however, is degraded in an unknown noisy environment. To solve this
problem, we take an unsupervised approach that decomposes each TF bin into the
sum of speech and noise by using multichannel nonnegative matrix factorization
(MNMF). This enables us to accurately estimate the SCMs of speech and noise not
from observed noisy mixtures but from separated speech and noise components. In
this paper we propose online MVDR beamforming by effectively initializing and
incrementally updating the parameters of MNMF. Another main contribution is to
comprehensively investigate the performances of ASR obtained by various types
of spatial filters, i.e., time-invariant and variant versions of MVDR
beamformers and those of rank-1 and full-rank multichannel Wiener filters, in
combination with MNMF. The experimental results showed that the proposed method
outperformed the state-of-the-art DNN-based beamforming method in unknown
environments that did not match training data.",Sound (cs.SD),; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Machine Learning (stat.ML),"[Submitted on 22 Mar 2019 (v1), last revised 31 Mar 2019 (this version, v2)]"
Overcoming Small Minirhizotron Datasets Using Transfer Learning,"Weihuang Xu, Guohao Yu, Alina Zare, Brendan Zurweller, Diane Rowland, Joel Reyes-Cabrera, Felix B Fritschi, Roser Matamala, Thomas E. Juenger","Minirhizotron technology is widely used for studying the development of
roots. Such systems collect visible-wavelength color imagery of plant roots
in-situ by scanning an imaging system within a clear tube driven into the soil.
Automated analysis of root systems could facilitate new scientific discoveries
that would be critical to address the world's pressing food, resource, and
climate issues. A key component of automated analysis of plant roots from
imagery is the automated pixel-level segmentation of roots from their
surrounding soil. Supervised learning techniques appear to be an appropriate
tool for the challenge due to varying local soil and root conditions, however,
lack of enough annotated training data is a major limitation due to the
error-prone and time-consuming manually labeling process. In this paper, we
investigate the use of deep neural networks based on the U-net architecture for
automated, precise pixel-wise root segmentation in minirhizotron imagery. We
compiled two minirhizotron image datasets to accomplish this study: one with
17,550 peanut root images and another with 28 switchgrass root images. Both
datasets were paired with manually labeled ground truth masks. We trained three
neural networks with different architectures on the larger peanut root dataset
to explore the effect of the neural network depth on segmentation performance.
To tackle the more limited switchgrass root dataset, we showed that models
initialized with features pre-trained on the peanut dataset and then fine-tuned
on the switchgrass dataset can improve segmentation performance significantly.
We obtained 99\% segmentation accuracy in switchgrass imagery using only 21
training images. We also observed that features pre-trained on a closely
related but relatively moderate size dataset like our peanut dataset are more
effective than features pre-trained on the large but unrelated ImageNet
dataset.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 22 Mar 2019 (v1), last revised 24 Apr 2020 (this version, v3)]"
heSRPT: Optimal Parallel Scheduling of Jobs With Known Sizes,"Benjamin Berg, Rein Vesilo, Mor Harchol-Balter","When parallelizing a set of jobs across many servers, one must balance a
trade-off between granting priority to short jobs and maintaining the overall
efficiency of the system. When the goal is to minimize the mean flow time of a
set of jobs, it is usually the case that one wants to complete short jobs
before long jobs. However, since jobs usually cannot be parallelized with
perfect efficiency, granting strict priority to the short jobs can result in
very low system efficiency which in turn hurts the mean flow time across jobs.
In this paper, we derive the optimal policy for allocating servers to jobs at
every moment in time in order to minimize mean flow time across jobs. We assume
that jobs follow a sublinear, concave speedup function, and hence jobs
experience diminishing returns from being allocated additional servers. We show
that the optimal policy, heSRPT, will complete jobs according to their size
order, but maintains overall system efficiency by allocating some servers to
each job at every moment in time. We compare heSRPT with state-of-the-art
allocation policies from the literature and show that heSRPT outperforms its
competitors by at least 30%, and often by much more.",Performance (cs.PF),,[Submitted on 22 Mar 2019]
Understanding and taming SSD read performance variability: HDFS case study,"María F. Borge, Florin Dinu, Willy Zwaenepoel","In this paper we analyze the influence that lower layers (file system, OS,
SSD) have on HDFS' ability to extract maximum performance from SSDs on the read
path. We uncover and analyze three surprising performance slowdowns induced by
lower layers that result in HDFS read throughput loss. First, intrinsic
slowdown affects reads from every new file system extent for a variable amount
of time. Second, temporal slowdown appears temporarily and periodically and is
workload-agnostic. Third, in permanent slowdown, some files can individually
and permanently become slower after a period of time. We analyze the impact of
these slowdowns on HDFS and show significant throughput loss. Individually,
each of the slowdowns can cause a read throughput loss of 10-15%. However,
their effect is cumulative. When all slowdowns happen concurrently, read
throughput drops by as much as 30%. We further analyze mitigation techniques
and show that two of the three slowdowns could be addressed via increased IO
request parallelism in the lower layers. Unfortunately, HDFS cannot
automatically adapt to use such additional parallelism. Our results point to a
need for adaptability in storage stacks. The reason is that an access pattern
that maximizes performance in the common case is not necessarily the same one
that can mask performance fluctuations.",Operating Systems (cs.OS),; Performance (cs.PF),[Submitted on 22 Mar 2019]
A Comprehensive Performance Evaluation of a DF-Based Multi-Hop System Over $α-κ-μ$ and $α-κ-μ$-Extreme Fading Channels,"Tau Raphael Rasethuntsa, Sandeep Kumar, Manpreet Kaur","In this work, an integrated performance evaluation of a decode-and-forward
(DF) multi-hop wireless communication system is undertaken over the non-linear
generalized $\alpha-\kappa-\mu$ and $\alpha-\kappa-\mu$-Extreme fading models.
Analytical formulas for the probability density function (PDF) and the
cumulative distribution function (CDF) of the received signal-to-noise ratio
(SNR) as well as its generalized moments and moment generating function (MGF)
are derived. Based on the derived PDFs, novel closed-form expressions for
traditional performance metrics such as amount of fading (AF), outage
probability (OP), bit error rate (BER) under coherent and non-coherent
modulation schemes as well as channel capacity under various adaptive
transmission techniques are derived. Additionally, asymptotic analyses of BER
based on Poincare series expansions of SNR PDFs are carried out and results
show good approximations for low SNR regimes. The correctness of the proposed
solutions has been corroborated by comparing them with Monte Carlo simulation
results.",Information Theory (cs.IT),,[Submitted on 22 Mar 2019]
A Model Counter's Guide to Probabilistic Systems,"Marcell Vazquez-Chanlatte, Markus N. Rabe, Sanjit A. Seshia","In this paper, we systematize the modeling of probabilistic systems for the
purpose of analyzing them with model counting techniques. Starting from
unbiased coin flips, we show how to model biased coins, correlated coins, and
distributions over finite sets. From there, we continue with modeling
sequential systems, such as Markov chains, and revisit the relationship between
weighted and unweighted model counting. Thereby, this work provides a
conceptual framework for deriving #SAT encodings for probabilistic inference.",Logic in Computer Science (cs.LO),; Artificial Intelligence (cs.AI),[Submitted on 22 Mar 2019]
A Double-Edged Sword: Security Threats and Opportunities in One-Sided Network Communication,"Shin-Yeh Tsai, Yiying Zhang","One-sided network communication technologies such as RDMA and
NVMe-over-Fabrics are quickly gaining adoption in production software and in
datacenters. Although appealing for their low CPU utilization and good
performance, they raise new security concerns that could seriously undermine
datacenter software systems building on top of them. At the same time, they
offer unique opportunities to help enhance security. Indeed, one-sided network
communication is a double-edged sword in security. This paper presents our
insights into security implications and opportunities of one-sided
communication.",Cryptography and Security (cs.CR),,"[Submitted on 22 Mar 2019 (v1), last revised 15 May 2019 (this version, v2)]"
Efficient Algorithms for Geometric Partial Matching,"Pankaj K. Agarwal, Hsien-Chih Chang, Allen Xiao","Let $A$ and $B$ be two point sets in the plane of sizes $r$ and $n$
respectively (assume $r \leq n$), and let $k$ be a parameter. A matching
between $A$ and $B$ is a family of pairs in $A \times B$ so that any point of
$A \cup B$ appears in at most one pair. Given two positive integers $p$ and
$q$, we define the cost of matching $M$ to be $c(M) = \sum_{(a, b) \in
M}\|{a-b}\|_p^q$ where $\|{\cdot}\|_p$ is the $L_p$-norm. The geometric partial
matching problem asks to find the minimum-cost size-$k$ matching between $A$
and $B$.
We present efficient algorithms for geometric partial matching problem that
work for any powers of $L_p$-norm matching objective: An exact algorithm that
runs in $O((n + k^2) {\mathop{\mathrm{polylog}}} n)$ time, and a $(1 +
\varepsilon)$-approximation algorithm that runs in $O((n + k\sqrt{k})
{\mathop{\mathrm{polylog}}} n \cdot \log\varepsilon^{-1})$ time. Both
algorithms are based on the primal-dual flow augmentation scheme; the main
improvements involve using dynamic data structures to achieve efficient flow
augmentations. With similar techniques, we give an exact algorithm for the
planar transportation problem running in $O(\min\{n^2, rn^{3/2}\}
{\mathop{\mathrm{polylog}}} n)$ time.",Data Structures and Algorithms (cs.DS),; Computational Geometry (cs.CG),[Submitted on 22 Mar 2019]
3D Face Reconstruction from A Single Image Assisted by 2D Face Images in the Wild,"Xiaoguang Tu, Jian Zhao, Zihang Jiang, Yao Luo, Mei Xie, Yang Zhao, Linxiao He, Zheng Ma, Jiashi Feng","3D face reconstruction from a single 2D image is a challenging problem with
broad applications. Recent methods typically aim to learn a CNN-based 3D face
model that regresses coefficients of 3D Morphable Model (3DMM) from 2D images
to render 3D face reconstruction or dense face alignment. However, the shortage
of training data with 3D annotations considerably limits performance of those
methods. To alleviate this issue, we propose a novel 2D-assisted
self-supervised learning (2DASL) method that can effectively use ""in-the-wild""
2D face images with noisy landmark information to substantially improve 3D face
model learning. Specifically, taking the sparse 2D facial landmarks as
additional information, 2DSAL introduces four novel self-supervision schemes
that view the 2D landmark and 3D landmark prediction as a self-mapping process,
including the 2D and 3D landmark self-prediction consistency, cycle-consistency
over the 2D landmark prediction and self-critic over the predicted 3DMM
coefficients based on landmark predictions. Using these four self-supervision
schemes, the 2DASL method significantly relieves demands on the the
conventional paired 2D-to-3D annotations and gives much higher-quality 3D face
models without requiring any additional 3D annotations. Experiments on multiple
challenging datasets show that our method outperforms state-of-the-arts for
both 3D face reconstruction and dense face alignment by a large margin.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 22 Mar 2019 (v1), last revised 3 May 2020 (this version, v2)]"
Gabidulin Codes with Support Constrained Generator Matrices,"Hikmet Yildiz, Babak Hassibi","Gabidulin codes are the first general construction of linear codes that are
maximum rank distant (MRD). They have found applications in linear network
coding, for example, when the transmitter and receiver are oblivious to the
inner workings and topology of the network (the so-called incoherent regime).
The reason is that Gabidulin codes can be used to map information to linear
subspaces, which in the absence of errors cannot be altered by linear
operations, and in the presence of errors can be corrected if the subspace is
perturbed by a small rank. Furthermore, in distributed coding and distributed
systems, one is led to the design of error correcting codes whose generator
matrix must satisfy a given support constraint. In this paper, we give
necessary and sufficient conditions on the support of the generator matrix that
guarantees the existence of Gabidulin codes and general MRD codes. When the
rate of the code is not very high, this is achieved with the same field size
necessary for Gabidulin codes with no support constraint. When these conditions
are not satisfied, we characterize the largest possible rank distance under the
support constraints and show that they can be achieved by subcodes of Gabidulin
codes. The necessary and sufficient conditions are identical to those that
appear for MDS codes which were recently proven by Yildiz et al. and Lovett in
the context of settling the GM-MDS conjecture.",Information Theory (cs.IT),,"[Submitted on 22 Mar 2019 (v1), last revised 19 Nov 2019 (this version, v2)]"
ERHARD-RNG: A Random Number Generator Built from Repurposed Hardware in Embedded Systems,"Jacob Grycel, Robert J. Walls","Quality randomness is fundamental to cryptographic operations but on embedded
systems good sources are (seemingly) hard to find. Rather than use expensive
custom hardware, our ERHARD-RNG Pseudo-Random Number Generator (PRNG) utilizes
entropy sources that are already common in a range of low-cost embedded
platforms. We empirically evaluate the entropy provided by three sources---SRAM
startup state, oscillator jitter, and device temperature---and integrate those
sources into a full Pseudo-Random Number Generator implementation based on
Fortuna. Our system addresses a number of fundamental challenges affecting
random number generation on embedded systems. For instance, we propose SRAM
startup state as a means to efficiently generate the initial seed---even for
systems that do not have writeable storage. Further, the system's use of
oscillator jitter allows for the continuous collection of entropy-generating
events---even for systems that do not have the user-generated events that are
commonly used in general-purpose systems for entropy, e.g., key presses or
network events.",Cryptography and Security (cs.CR),,"[Submitted on 22 Mar 2019 (v1), last revised 11 Nov 2019 (this version, v2)]"
Macro Action Reinforcement Learning with Sequence Disentanglement using Variational Autoencoder,"Heecheol Kim, Masanori Yamada, Kosuke Miyoshi, Hiroshi Yamakawa","One problem in the application of reinforcement learning to real-world
problems is the curse of dimensionality on the action space. Macro actions, a
sequence of primitive actions, have been studied to diminish the dimensionality
of the action space with regard to the time axis. However, previous studies
relied on humans defining macro actions or assumed macro actions as repetitions
of the same primitive actions. We present Factorized Macro Action Reinforcement
Learning (FaMARL) which autonomously learns disentangled factor representation
of a sequence of actions to generate macro actions that can be directly applied
to general reinforcement learning algorithms. FaMARL exhibits higher scores
than other reinforcement learning algorithms on environments that require an
extensive amount of search.",Machine Learning (cs.LG),; Artificial Intelligence (cs.AI); Robotics (cs.RO); Applications (stat.AP); Machine Learning (stat.ML),"[Submitted on 22 Mar 2019 (v1), last revised 4 Jun 2019 (this version, v2)]"
Joint Switch Upgrade and Controller Deployment in Hybrid Software-Defined Networks,"Zehua Guo, Weikun Chen, Ya-Feng Liu, Yang Xu, Zhi-Li Zhang","To improve traffic management ability, Internet Service Providers (ISPs) are
gradually upgrading legacy network devices to programmable devices that support
Software-Defined Networking (SDN). The coexistence of legacy and SDN devices
gives rise to a hybrid SDN. Existing hybrid SDNs do not consider the potential
performance issues introduced by a centralized SDN controller: flow requests
processed by a highly loaded controller may experience long tail processing
delay; inappropriate multi-controller deployment could increase the propagation
delay of flow requests.
In this paper, we propose to jointly consider the deployment of SDN switches
and their controllers for hybrid SDNs. We formulate the joint problem as an
optimization problem that maximizes the number of flows that can be controlled
and managed by the SDN and minimizes the propagation delay of flow requests
between SDN controllers and switches under a given upgrade budget constraint.
We show this problem is NP-hard. To efficiently solve the problem, we propose
some techniques (e.g., strengthening the constraints and adding additional
valid inequalities) to accelerate the global optimization solver for solving
the problem for small networks and an efficient heuristic algorithm for solving
it for large networks. The simulation results from real network topologies
illustrate the effectiveness of the proposed techniques and show that our
proposed heuristic algorithm uses a small number of controllers to manage a
high amount of flows with good performance.",Networking and Internet Architecture (cs.NI),,"[Submitted on 22 Mar 2019 (v1), last revised 23 Jul 2019 (this version, v2)]"
Few-shot Adaptive Faster R-CNN,"Tao Wang, Xiaopeng Zhang, Li Yuan, Jiashi Feng","To mitigate the detection performance drop caused by domain shift, we aim to
develop a novel few-shot adaptation approach that requires only a few target
domain images with limited bounding box annotations. To this end, we first
observe several significant challenges. First, the target domain data is highly
insufficient, making most existing domain adaptation methods ineffective.
Second, object detection involves simultaneous localization and classification,
further complicating the model adaptation process. Third, the model suffers
from over-adaptation (similar to overfitting when training with a few data
example) and instability risk that may lead to degraded detection performance
in the target domain. To address these challenges, we first introduce a pairing
mechanism over source and target features to alleviate the issue of
insufficient target domain samples. We then propose a bi-level module to adapt
the source trained detector to the target domain: 1) the split pooling based
image level adaptation module uniformly extracts and aligns paired local patch
features over locations, with different scale and aspect ratio; 2) the instance
level adaptation module semantically aligns paired object features while avoids
inter-class confusion. Meanwhile, a source model feature regularization (SMFR)
is applied to stabilize the adaptation process of the two modules. Combining
these contributions gives a novel few-shot adaptive Faster-RCNN framework,
termed FAFRCNN, which effectively adapts to target domain with a few labeled
samples. Experiments with multiple datasets show that our model achieves new
state-of-the-art performance under both the interested few-shot domain
adaptation(FDA) and unsupervised domain adaptation(UDA) setting.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 22 Mar 2019]
Deep Hierarchical Reinforcement Learning Based Recommendations via Multi-goals Abstraction,"Dongyang Zhao, Liang Zhang, Bo Zhang, Lizhou Zheng, Yongjun Bao, Weipeng Yan","The recommender system is an important form of intelligent application, which
assists users to alleviate from information redundancy. Among the metrics used
to evaluate a recommender system, the metric of conversion has become more and
more important. The majority of existing recommender systems perform poorly on
the metric of conversion due to its extremely sparse feedback signal. To tackle
this challenge, we propose a deep hierarchical reinforcement learning based
recommendation framework, which consists of two components, i.e., high-level
agent and low-level agent. The high-level agent catches long-term sparse
conversion signals, and automatically sets abstract goals for low-level agent,
while the low-level agent follows the abstract goals and interacts with
real-time environment. To solve the inherent problem in hierarchical
reinforcement learning, we propose a novel deep hierarchical reinforcement
learning algorithm via multi-goals abstraction (HRL-MG). Our proposed algorithm
contains three characteristics: 1) the high-level agent generates multiple
goals to guide the low-level agent in different stages, which reduces the
difficulty of approaching high-level goals; 2) different goals share the same
state encoder parameters, which increases the update frequency of the
high-level agent and thus accelerates the convergence of our proposed
algorithm; 3) an appreciate benefit assignment function is designed to allocate
rewards in each goal so as to coordinate different goals in a consistent
direction. We evaluate our proposed algorithm based on a real-world e-commerce
dataset and validate its effectiveness.",Machine Learning (cs.LG),; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR),[Submitted on 22 Mar 2019]
Multi-modal Probabilistic Prediction of Interactive Behavior via an Interpretable Model,"Yeping Hu, Wei Zhan, Liting Sun, Masayoshi Tomizuka","For autonomous agents to successfully operate in real world, the ability to
anticipate future motions of surrounding entities in the scene can greatly
enhance their safety levels since potentially dangerous situations could be
avoided in advance. While impressive results have been shown on predicting each
agent's behavior independently, we argue that it is not valid to consider road
entities individually since transitions of vehicle states are highly coupled.
Moreover, as the predicted horizon becomes longer, modeling prediction
uncertainties and multi-modal distributions over future sequences will turn
into a more challenging task. In this paper, we address this challenge by
presenting a multi-modal probabilistic prediction approach. The proposed method
is based on a generative model and is capable of jointly predicting sequential
motions of each pair of interacting agents. Most importantly, our model is
interpretable, which can explain the underneath logic as well as obtain more
reliability to use in real applications. A complicate real-world roundabout
scenario is utilized to implement and examine the proposed method.",Machine Learning (cs.LG),; Machine Learning (stat.ML),"[Submitted on 22 Mar 2019 (v1), last revised 2 Jun 2019 (this version, v2)]"
Learning with Delayed Synaptic Plasticity,"Anil Yaman, Giovanni Iacca, Decebal Constantin Mocanu, George Fletcher, Mykola Pechenizkiy","The plasticity property of biological neural networks allows them to perform
learning and optimize their behavior by changing their configuration. Inspired
by biology, plasticity can be modeled in artificial neural networks by using
Hebbian learning rules, i.e. rules that update synapses based on the neuron
activations and reinforcement signals. However, the distal reward problem
arises when the reinforcement signals are not available immediately after each
network output to associate the neuron activations that contributed to
receiving the reinforcement signal. In this work, we extend Hebbian plasticity
rules to allow learning in distal reward cases. We propose the use of neuron
activation traces (NATs) to provide additional data storage in each synapse to
keep track of the activation of the neurons. Delayed reinforcement signals are
provided after each episode relative to the networks' performance during the
previous episode. We employ genetic algorithms to evolve delayed synaptic
plasticity (DSP) rules and perform synaptic updates based on NATs and delayed
reinforcement signals. We compare DSP with an analogous hill climbing algorithm
that does not incorporate domain knowledge introduced with the NATs, and show
that the synaptic updates performed by the DSP rules demonstrate more effective
training performance relative to the HC algorithm.",Neural and Evolutionary Computing (cs.NE),,"[Submitted on 22 Mar 2019 (v1), last revised 17 Apr 2019 (this version, v2)]"
Concurrent Transmission Scheduling for Perceptual Data Sharing in mmWave Vehicular Networks,"Akihito Taya, Takayuki Nishio, Masahiro Morikura, Koji Yamamoto","Sharing perceptual data with other vehicles enhances the traffic safety of
autonomous vehicles because it helps vehicles locate other vehicles and
pedestrians in their blind spots. Such safety applications require high
throughput and short delay, which cannot be achieved by conventional microwave
vehicular communication systems. Therefore, millimeter-wave (mmWave)
communications are considered to be a key technology for sharing perceptual
data because of their wide bandwidth. One of the challenges of data sharing in
mmWave communications is broadcasting because narrow-beam directional antennas
are used to obtain high gain. Because many vehicles should share their
perceptual data to others within a short time frame in order to enlarge the
areas that can be perceived based on shared perceptual data, an efficient
scheduling for concurrent transmission that improves spatial reuse is required
for perceptual data sharing. This paper proposes a data sharing algorithm that
employs a graph-based concurrent transmission scheduling. The proposed
algorithm realizes concurrent transmission to improve spatial reuse by
designing a rule that is utilized to determine if the two pairs of transmitters
and receivers interfere with each other by considering the radio propagation
characteristics of narrow-beam antennas. A prioritization method that considers
the geographical information in perceptual data is also designed to enlarge
perceivable areas in situations where data sharing time is limited and not all
data can be shared. Simulation results demonstrate that the proposed algorithm
doubles the area of the cooperatively perceivable region compared with a
conventional algorithm that does not consider mmWave communications because the
proposed algorithm achieves high-throughput transmission by improving spatial
reuse. The prioritization also enlarges the perceivable region by a maximum of
20%.",Networking and Internet Architecture (cs.NI),,[Submitted on 22 Mar 2019]
Rule-Based Translation of Application-Level QoS Constraints into SDN Configurations for the IoT,"Jan Seeger, Arne Bröring, Marc-Oliver Pahl, Ermin Sakic","In this paper, we propose an approach for the automated translation of
application-level requirements regarding the logical workflow and its QoS into
a configuration of the underlying network substrate. Our goal is to facilitate
the integration of QoS constraints in the development of industrial IoT
applications to make them more reliable. We follow an approach based on two
semantic models: The first model allows to design the workflow of an IoT
application and to express application-level QoS requirements on its
interactions. The second model captures the configuration of a network and can
be used as input to a north-bound interface of an SDN controller. Finally, we
make use of rule-based semantic reasoning to automatically translate from the
application requirements into SDN parameters.",Networking and Internet Architecture (cs.NI),; Information Theory (cs.IT); Logic in Computer Science (cs.LO),[Submitted on 22 Mar 2019]
Fast Bayesian Uncertainty Estimation of Batch Normalized Single Image Super-Resolution Network,"Aupendu Kar, Prabir Kumar Biswas","In recent years, deep convolutional neural network (CNN) has achieved
unprecedented success in image super-resolution (SR) task. But the black-box
nature of the neural network and due to its lack of transparency, it is hard to
trust the outcome. In this regards, we introduce a Bayesian approach for
uncertainty estimation in super-resolution network. We generate Monte Carlo
(MC) samples from a posterior distribution by using batch mean and variance as
a stochastic parameter in the batch-normalization layer during test time. Those
MC samples not only reconstruct the image from its low-resolution counterpart
but also provides a confidence map of reconstruction which will be very
impactful for practical use. We also introduce a faster approach for estimating
the uncertainty, and it can be useful for real-time applications. We validate
our results using standard datasets for performance analysis and also for
different domain-specific super-resolution task. We also estimate uncertainty
quality using standard statistical metrics and also provides a qualitative
evaluation of uncertainty for SR applications.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 22 Mar 2019]
On Testing Data-Intensive Software Systems,"Michael Felderer, Barbara Russo, Florian Auer","Today's software systems like cyber-physical production systems or big data
systems have to process large volumes and diverse types of data which heavily
influences the quality of these so-called data-intensive systems. However,
traditional software testing approaches rather focus on functional behavior
than on data aspects. Therefore, the role of data in testing has to be
rethought and specific testing approaches for data-intensive software systems
are required. Thus, the aim of this chapter is to contribute to this area by
(1) providing basic terminology and background on data-intensive software
systems and their testing, and (2) presenting the state of the research and the
hot topics in the area. Finally, the directions of research and the new
frontiers on testing data-intensive software systems are discussed.",Software Engineering (cs.SE),,"[Submitted on 22 Mar 2019 (v1), last revised 9 Apr 2019 (this version, v2)]"
Ratiometric control for differentiation of cell populations endowed with synthetic toggle switches,"Davide Salzano, Davide Fiore, Mario di Bernardo","We consider the problem of regulating by means of external control inputs the
ratio of two cell populations. Specifically, we assume that these two cellular
populations are composed of cells belonging to the same strain which embeds
some bistable memory mechanism, e.g. a genetic toggle switch, allowing them to
switch role from one population to another in response to some inputs. We
present three control strategies to regulate the populations' ratio to
arbitrary desired values which take also into account realistic physical and
technological constraints occurring in experimental microfluidic platforms. The
designed controllers are then validated in-silico using stochastic agent-based
simulations.",Systems and Control (eess.SY),,"[Submitted on 22 Mar 2019 (v1), last revised 12 Sep 2019 (this version, v2)]"
Artificial intelligence-based process for metal scrap sorting,"Maximilian Auer, Kai Osswald, Raphael Volz, Joerg Woidasky","Machine learning offers remarkable benefits for improving workplaces and
working conditions amongst others in the recycling industry. Here e.g.
hand-sorting of medium value scrap is labor intensive and requires experienced
and skilled workers. On the one hand, they have to be highly concentrated for
making proper readings and analyses of the material, but on the other hand,
this work is monotonous. Therefore, a machine learning approach is proposed for
a quick and reliable automated identification of alloys in the recycling
industry, while the mere scrap handling is regarded to be left in the hands of
the workers. To this end, a set of twelve tool and high-speed steels from the
field were selected to be identified by their spectrum induced by electric
arcs. For data acquisition, the optical emission spectrometer Thorlabs CCS 100
was used. Spectra have been post-processed to be fed into the supervised
machine learning algorithm. The development of the machine learning software is
conducted according to the steps of the VDI 2221 standard method. For
programming Python 3 as well as the python-library sklearn were used. By
systematic parameter variation, the appropriate machine learning algorithm was
selected and validated. Subsequent validation steps showed that the automated
identification process using a machine learning approach and the optical
emission spectrometry is applicable, reaching a maximum F1 score of 96.9 %.
This performance is as good as the performance of a highly trained worker using
visual grinding spark identification. The tests were based on a self-generated
set of 600 spectra per single alloy (7,200 spectra in total) which were
produced using an industry workshop device.",Machine Learning (cs.LG),; Artificial Intelligence (cs.AI),[Submitted on 22 Mar 2019]
Rods and Rings: Soft Subdivision Planner for R^3 x S^2,"Ching-Hsiang Hsu, Yi-Jen Chiang, Chee Yap","We consider path planning for a rigid spatial robot moving amidst polyhedral
obstacles. Our robot is either a rod or a ring. Being axially-symmetric, their
configuration space is R^3 x S^2 with 5 degrees of freedom (DOF). Correct,
complete and practical path planning for such robots is a long standing
challenge in robotics. While the rod is one of the most widely studied spatial
robots in path planning, the ring seems to be new, and a rare example of a
non-simply-connected robot. This work provides rigorous and complete algorithms
for these robots with theoretical guarantees. We implemented the algorithms in
our open-source Core Library. Experiments show that they are practical,
achieving near real-time performance. We compared our planner to
state-of-the-art sampling planners in OMPL.
Our subdivision path planner is based on the twin foundations of
\epsilon-exactness and soft predicates. Correct implementation is relatively
easy. The technical innovations include subdivision atlases for S^2,
introduction of \Sigma_2 representations for footprints, and extensions of our
feature-based technique for ""opening up the blackbox of collision detection"".",Computational Geometry (cs.CG),,"[Submitted on 22 Mar 2019 (v1), last revised 7 Jun 2019 (this version, v3)]"
Parallel Adaptive Sampling with almost no Synchronization,"Alexander van der Grinten, Eugenio Angriman, Henning Meyerhenke","Approximation via sampling is a widespread technique whenever exact solutions
are too expensive. In this paper, we present techniques for an efficient
parallelization of adaptive (a. k. a. progressive) sampling algorithms on
multi-threaded shared-memory machines. Our basic algorithmic technique requires
no synchronization except for atomic load-acquire and store-release operations.
It does, however, require O(n) memory per thread, where n is the size of the
sampling state. We present variants of the algorithm that either reduce this
memory consumption to O(1) or ensure that deterministic results are obtained.
Using the KADABRA algorithm for betweenness centrality (a popular measure in
network analysis) approximation as a case study, we demonstrate the empirical
performance of our techniques. In particular, on a 32-core machine, our best
algorithm is 2.9x faster than what we could achieve using a straightforward
OpenMP-based parallelization and 65.3x faster than the existing implementation
of KADABRA.","Distributed, Parallel, and Cluster Computing (cs.DC)",,[Submitted on 22 Mar 2019]
An end-to-end Neural Network Framework for Text Clustering,"Jie Zhou, Xingyi Cheng, Jinchao Zhang","The unsupervised text clustering is one of the major tasks in natural
language processing (NLP) and remains a difficult and complex problem.
Conventional \mbox{methods} generally treat this task using separated steps,
including text representation learning and clustering the representations. As
an improvement, neural methods have also been introduced for continuous
representation learning to address the sparsity problem. However, the
multi-step process still deviates from the unified optimization target.
Especially the second step of cluster is generally performed with conventional
methods such as k-Means. We propose a pure neural framework for text clustering
in an end-to-end manner. It jointly learns the text representation and the
clustering model. Our model works well when the context can be obtained, which
is nearly always the case in the field of NLP. We have our method
\mbox{evaluated} on two widely used benchmarks: IMDB movie reviews for
sentiment classification and $20$-Newsgroup for topic categorization. Despite
its simplicity, experiments show the model outperforms previous clustering
methods by a large margin. Furthermore, the model is also verified on English
wiki dataset as a large corpus.",Computation and Language (cs.CL),,[Submitted on 22 Mar 2019]
Commitment Nets in Software Process Improvement,Pekka Abrahamsson,"Several studies have revealed the fact that nearly two-thirds of all software
process improvement (SPI) efforts have failed or have at least fallen short of
expectations. Literature and practice have shown that commitment to SPI at all
organizational levels is essential for the success of any SPI endeavor. A
research model for studying the existence, development and interplay of
SPI-related commitment is introduced in this paper. This study suggests that
software organizations operate through strategic, operational and personal
commitment nets. These nets consist of actors, drivers, concerns, actions,
commitment, and outcomes. The commitment nets model is applied in a study of
four industrial SPI initiatives. The results from two of these cases are
reported here. The results show that SPI is driven through the formation and
reformation of commitment nets. The contents of strategic, operational and
personal commitment nets are laid out and implications are discussed.",Software Engineering (cs.SE),,[Submitted on 22 Mar 2019]
Speed and Energy Optimised Quasi-Delay-Insensitive Block Carry Lookahead Adder,"P. Balasubramanian, D.L. Maskell, N.E. Mastorakis","We present a new asynchronous quasi-delay-insensitive (QDI) block carry
lookahead adder with redundancy carry (BCLARC) realized using delay-insensitive
dual-rail data encoding and 4-phase return-to-zero (RTZ) and 4-phase
return-to-one (RTO) handshaking. The proposed QDI BCLARC is found to be faster
and energy-efficient than the existing asynchronous adders which are QDI and
non-QDI (i.e., relative-timed). Compared to existing asynchronous adders
corresponding to various architectures such as ripple carry adder (RCA),
conventional carry lookahead adder (CCLA), carry select adder (CSLA), BCLARC,
and hybrid BCLARC-RCA, the proposed BCLARC is found to be faster and more
energy-optimised. The cycle time (CT), which is the sum of forward and reverse
latencies, governs the speed; and the product of average power dissipation and
cycle time viz. the power-cycle time product (PCTP) defines the low
power/energy efficiency. For a 32-bit addition, the proposed QDI BCLARC
achieves the following average reductions in design metrics over its
counterparts when considering RTZ and RTO handshaking: i) 20.5% and 19.6%
reductions in CT and PCTP respectively compared to an optimum QDI early output
RCA, ii) 16.5% and 15.8% reductions in CT and PCTP respectively compared to an
optimum relative-timed RCA, iii) 32.9% and 35.9% reductions in CT and PCTP
respectively compared to an optimum uniform input-partitioned QDI early output
CSLA, iv) 47.5% and 47.2% reductions in CT and PCTP respectively compared to an
optimum QDI early output CCLA, v) 14.2% and 27.3% reductions in CT and PCTP
respectively compared to an optimum QDI early output BCLARC, and vi) 12.2% and
11.6% reductions in CT and PCTP respectively compared to an optimum QDI early
output hybrid BCLARC-RCA. The adders were implemented using a 32/28nm CMOS
technology.",Hardware Architecture (cs.AR),,[Submitted on 22 Mar 2019]
Sampling Acquisition Functions for Batch Bayesian Optimization,"Alessandro De Palma, Celestine Mendler-Dünner, Thomas Parnell, Andreea Anghel, Haralampos Pozidis","We present Acquisition Thompson Sampling (ATS), a novel technique for batch
Bayesian Optimization (BO) based on the idea of sampling multiple acquisition
functions from a stochastic process. We define this process through the
dependency of the acquisition functions on a set of model hyper-parameters. ATS
is conceptually simple, straightforward to implement and, unlike other batch BO
methods, it can be employed to parallelize any sequential acquisition function
or to make existing parallel methods scale further. We present experiments on a
variety of benchmark functions and on the hyper-parameter optimization of a
popular gradient boosting tree algorithm. These demonstrate the advantages of
ATS with respect to classical parallel Thompson Sampling for BO, its
competitiveness with two state-of-the-art batch BO methods, and its
effectiveness if applied to existing parallel BO algorithms.",Machine Learning (cs.LG),; Machine Learning (stat.ML),"[Submitted on 22 Mar 2019 (v1), last revised 16 Oct 2019 (this version, v2)]"
A new condition for stability of switched linear systems under restricted minimum dwell time switching,Atreyee Kundu,"We propose matrix commutator based stability characterization for
discrete-time switched linear systems under restricted switching. Given an
admissible minimum dwell time, we identify sufficient conditions on subsystems
such that a switched system is stable under all switching signals that obey the
given restriction. The primary tool for our analysis is commutation relations
between the subsystem matrices. Our stability conditions are robust with
respect to small perturbations in the elements of these matrices. In case of
arbitrary switching (i.e., given minimum dwell time = 1), we recover the prior
result [1,Proposition 1] as a special case of our result.",Systems and Control (eess.SY),,"[Submitted on 22 Mar 2019 (v1), last revised 29 Nov 2019 (this version, v3)]"
Channel Estimation for Orthogonal Time Frequency Space (OTFS) Massive MIMO,"Wenqian Shen, Linglong Dai, Jianping An, Pingzhi Fan, Robert W. Heath Jr","Orthogonal time frequency space (OTFS) modulation outperforms orthogonal
frequency division multiplexing (OFDM) in high-mobility scenarios. One
challenge for OTFS massive MIMO is downlink channel estimation due to the large
number of base station antennas. In this paper, we propose a 3D structured
orthogonal matching pursuit algorithm based channel estimation technique to
solve this problem. First, we show that the OTFS MIMO channel exhibits 3D
structured sparsity: normal sparsity along the delay dimension, block sparsity
along the Doppler dimension, and burst sparsity along the angle dimension.
Based on the 3D structured channel sparsity, we then formulate the downlink
channel estimation problem as a sparse signal recovery problem. Simulation
results show that the proposed algorithm can achieve accurate channel state
information with low pilot overhead.",Information Theory (cs.IT),,[Submitted on 22 Mar 2019]
LINSPECTOR: Multilingual Probing Tasks for Word Representations,"Gözde Gül Şahin, Clara Vania, Ilia Kuznetsov, Iryna Gurevych","Despite an ever growing number of word representation models introduced for a
large number of languages, there is a lack of a standardized technique to
provide insights into what is captured by these models. Such insights would
help the community to get an estimate of the downstream task performance, as
well as to design more informed neural architectures, while avoiding extensive
experimentation which requires substantial computational resources not all
researchers have access to. A recent development in NLP is to use simple
classification tasks, also called probing tasks, that test for a single
linguistic feature such as part-of-speech. Existing studies mostly focus on
exploring the linguistic information encoded by the continuous representations
of English text. However, from a typological perspective the morphologically
poor English is rather an outlier: the information encoded by the word order
and function words in English is often stored on a morphological level in other
languages. To address this, we introduce 15 type-level probing tasks such as
case marking, possession, word length, morphological tag count and pseudoword
identification for 24 languages. We present a reusable methodology for creation
and evaluation of such tests in a multilingual setting. We then present
experiments on several diverse multilingual word embedding models, in which we
relate the probing task performance for a diverse set of languages to a range
of five classic NLP tasks: POS-tagging, dependency parsing, semantic role
labeling, named entity recognition and natural language inference. We find that
a number of probing tests have significantly high positive correlation to the
downstream tasks, especially for morphologically rich languages. We show that
our tests can be used to explore word embeddings or black-box neural models for
linguistic cues in a multilingual setting.",Computation and Language (cs.CL),,"[Submitted on 22 Mar 2019 (v1), last revised 11 Dec 2019 (this version, v2)]"
L1 Adaptive Controller -- Performance Analysis of the Inverse DC Gain Method,Sanchito Banerjee,"This paper presents an analysis of the modified L1 adaptive control law. The
performance of this control law is compared to the original control law. The
modified L1 control law uses the DC gain of the transfer function of the closed
loop plant dynamics. There is slight worsening of the controller performance.
Furthermore, this analysis shows that provided that there is room for slight
performance reduction, L1 adaptive control law can be used to control
non-minimum phase systems without the use of a pole-zero cancellation
technique. L1 adaptive control requires five assumptions before it can be
applied. The stability of matched transmission zeros is no longer a condition
that a system needs to meet as a result of this modification to the adaptive
control law.",Systems and Control (eess.SY),,[Submitted on 22 Mar 2019]
Data Augmentation via Dependency Tree Morphing for Low-Resource Languages,"Gözde Gül Şahin, Mark Steedman","Neural NLP systems achieve high scores in the presence of sizable training
dataset. Lack of such datasets leads to poor system performances in the case
low-resource languages. We present two simple text augmentation techniques
using dependency trees, inspired from image processing. We crop sentences by
removing dependency links, and we rotate sentences by moving the tree fragments
around the root. We apply these techniques to augment the training sets of
low-resource languages in Universal Dependencies project. We implement a
character-level sequence tagging model and evaluate the augmented datasets on
part-of-speech tagging task. We show that crop and rotate provides improvements
over the models trained with non-augmented data for majority of the languages,
especially for languages with rich case marking systems.",Computation and Language (cs.CL),,[Submitted on 22 Mar 2019]
Probabilistic logics based on Riesz spaces,"Robert Furber, Radu Mardare, Matteo Mio","We introduce a novel real-valued endogenous logic for expressing properties
of probabilistic transition systems called Riesz modal logic. The design of the
syntax and semantics of this logic is directly inspired by the theory of Riesz
spaces, a mature field of mathematics at the intersection of universal algebra
and functional analysis. By using powerful results from this theory, we develop
the duality theory of the Riesz modal logic in the form of an
algebra-to-coalgebra correspondence. This has a number of consequences
including: a sound and complete axiomatization, the proof that the logic
characterizes probabilistic bisimulation and other convenient results such as
completion theorems. This work is intended to be the basis for subsequent
research on extensions of Riesz modal logic with fixed-point operators.",Logic in Computer Science (cs.LO),,"[Submitted on 22 Mar 2019 (v1), last revised 24 Jan 2020 (this version, v3)]"
Managing Recurrent Virtual Network Updates in Multi-Tenant Datacenters: A System Perspective,"Zhuotao Liu, Yuan Cao, Xuewu Zhang, Changping Zhu, Fan Zhang","With the advent of software-defined networking, network configuration through
programmable interfaces becomes practical, leading to various on-demand
opportunities for network routing update in multi-tenant datacenters, where
tenants have diverse requirements on network routings such as short latency,
low path inflation, large bandwidth, high reliability, etc. Conventional
solutions that rely on topology search coupled with an objective function
https:// this http URL to find desired
routings have at least two shortcomings: (i) they run into scalability issues
when handling consistent and frequent routing updates and (ii) they restrict
the flexibility and capability to satisfy various routing requirements. To
address these issues, this paper proposes a novel search and optimization
decoupled design, which not only saves considerable topology search costs via
search result reuse, but also avoids possible sub-optimality in greedy routing
search algorithms by making decisions based on the global view of all possible
routings. We implement a prototype of our proposed system, OpReduce, and
perform extensive evaluations to validate its design goals.",Cryptography and Security (cs.CR),; Networking and Internet Architecture (cs.NI),"[Submitted on 22 Mar 2019 (v1), last revised 18 Jun 2020 (this version, v5)]"
Surfing the Web quicker than QUIC via a shared Address Validation,Erik Sy,"QUIC is a performance-optimized secure transport protocol and a building
block of the upcoming HTTP/3 standard. To protect against denial-of-service
attacks, QUIC servers need to validate the IP addresses claimed by their
clients. So far, the QUIC protocol conducts address validation for each
hostname separately using validation tokens. In this work, we review this
practice and introduce a new QUIC transport parameter to allow a shared address
validation across hostnames. This parameter indicates to the client, that an
issued validation token can be used to abbreviate the address validation when
connecting to specific other hostnames. Based on trust-relations between
real-world hostnames we evaluate the performance benefits of our proposal. Our
results suggest that a shared address validation saves a round-trip time on
almost 60% of the required handshakes to different hosts during the first
loading of an average website. Assuming a typical transatlantic connection with
a round-trip time of 90ms. We find that deploying our proposal reduces the
delay overhead to establish all required connections for an average website by
142.2ms.",Cryptography and Security (cs.CR),,[Submitted on 22 Mar 2019]
Disentangled Representation Learning in Cardiac Image Analysis,"Agisilaos Chartsias, Thomas Joyce, Giorgos Papanastasiou, Michelle Williams, David Newby, Rohan Dharmakumar, Sotirios A. Tsaftaris","Typically, a medical image offers spatial information on the anatomy (and
pathology) modulated by imaging specific characteristics. Many imaging
modalities including Magnetic Resonance Imaging (MRI) and Computed Tomography
(CT) can be interpreted in this way. We can venture further and consider that a
medical image naturally factors into some spatial factors depicting anatomy and
factors that denote the imaging characteristics. Here, we explicitly learn this
decomposed (disentangled) representation of imaging data, focusing in
particular on cardiac images. We propose Spatial Decomposition Network (SDNet),
which factorises 2D medical images into spatial anatomical factors and
non-spatial modality factors. We demonstrate that this high-level
representation is ideally suited for several medical image analysis tasks, such
as semi-supervised segmentation, multi-task segmentation and regression, and
image-to-image synthesis. Specifically, we show that our model can match the
performance of fully supervised segmentation models, using only a fraction of
the labelled images. Critically, we show that our factorised representation
also benefits from supervision obtained either when we use auxiliary tasks to
train the model in a multi-task setting (e.g. regressing to known cardiac
indices), or when aggregating multimodal data from different sources (e.g.
pooling together MRI and CT data). To explore the properties of the learned
factorisation, we perform latent-space arithmetic and show that we can
synthesise CT from MR and vice versa, by swapping the modality factors. We also
demonstrate that the factor holding image specific information can be used to
predict the input modality with high accuracy. Code will be made available at
this https URL.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 22 Mar 2019 (v1), last revised 16 Sep 2019 (this version, v4)]"
Aggregated Deep Local Features for Remote Sensing Image Retrieval,"Raffaele Imbriaco, Clint Sebastian, Egor Bondarev, Peter H.N. de With","Remote Sensing Image Retrieval remains a challenging topic due to the special
nature of Remote Sensing Imagery. Such images contain various different
semantic objects, which clearly complicates the retrieval task. In this paper,
we present an image retrieval pipeline that uses attentive, local convolutional
features and aggregates them using the Vector of Locally Aggregated Descriptors
(VLAD) to produce a global descriptor. We study various system parameters such
as the multiplicative and additive attention mechanisms and descriptor
dimensionality. We propose a query expansion method that requires no external
inputs. Experiments demonstrate that even without training, the local
convolutional features and global representation outperform other systems.
After system tuning, we can achieve state-of-the-art or competitive results.
Furthermore, we observe that our query expansion method increases overall
system performance by about 3%, using only the top-three retrieved images.
Finally, we show how dimensionality reduction produces compact descriptors with
increased retrieval performance and fast retrieval computation times, e.g. 50%
faster than the current systems.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 22 Mar 2019]
Using SMT Solvers to Validate Models for AI Problems,"Andrei Arusoaie, Ionut Pistol","Artificial Intelligence problems, ranging form planning/scheduling up to game
control, include an essential crucial step: describing a model which accurately
defines the problem's required data, requirements, allowed transitions and
established goals. The ways in which a model can fail are numerous and often
lead to a failure of search strategies to provide a quick, optimal, or even any
solution. This paper proposes using SMT (Satisfiability Modulo Theories)
solvers, such as Z3, to check the validity of a model. We propose two tests:
checking whether a final(goal) state exists in the model's described problem
space and checking whether the transitions described can provide a path from
the identified initial states to any the goal states (meaning a solution has
been found). The advantage of using an SMT solver for AI model checking is that
they substitute actual search strategies and they work over an abstract
representation of the model, that is, a set of logical formulas. Reasoning at
an abstract level is not as expensive as exploring the entire solution space.
SMT solvers use efficient decision procedures which provide proofs for the
logical formulas corresponding to the AI model. A recent addition to Z3 allowed
us to describe sequences of transitions as a recursive function, thus we can
check if a solution can be found in the defined model.",Artificial Intelligence (cs.AI),; Logic in Computer Science (cs.LO),[Submitted on 22 Mar 2019]
Facilitating Rapid Prototyping in the OODIDA Data Analytics Platform via Active-Code Replacement,"Gregor Ulm, Simon Smith, Adrian Nilsson, Emil Gustavsson, Mats Jirstrand","OODIDA (On-board/Off-board Distributed Data Analytics) is a platform for
distributed real-time analytics. It targets fleets of reference vehicles in the
automotive industry; its users are data analysts. The bulk of the data
analytics tasks are performed by clients (on-board), while a central cloud
server performs supplementary tasks (off-board). OODIDA can be automatically
packaged and deployed, which necessitates restarting parts of the system, or
all of it. This step is potentially disruptive, however. To address this issue,
we added the ability to execute user-defined Python modules on clients as well
as the server. These modules can be replaced without restarting any part of the
system; they can even be replaced between iterations of an ongoing assignment.
This feature is referred to as active-code replacement. It facilitates use
cases such as iterative A/B testing of machine learning algorithms or modifying
experimental algorithms on-the-fly. As a consequence, OODIDA is now very well
suited for rapid prototyping.","Distributed, Parallel, and Cluster Computing (cs.DC)",; Programming Languages (cs.PL); Software Engineering (cs.SE),"[Submitted on 22 Mar 2019 (v1), last revised 25 Feb 2020 (this version, v3)]"
Limitations on Observability of Effects in Cyber-Physical Systems,"Suresh K. Damodaran, Paul D. Rowe","Increased interconnectivity of Cyber-Physical Systems, by design or
otherwise, increases the cyber attack surface and attack vectors. Observing the
effects of these attacks is helpful in detecting them. In this paper, we show
that many attacks on such systems result in a control loop effect we term
Process Model Inconsistency (PMI). Our formal approach elucidates the
relationships among incompleteness, incorrectness, safety, and inconsistency of
process models. We show that incomplete process models lead to inconsistency.
Surprisingly, inconsistency may arise even in complete and correct models. We
illustrate our approach through an Automated Teller Machine (ATM) example, and
describe the practical implications of the theoretical results.",Cryptography and Security (cs.CR),,[Submitted on 22 Mar 2019]
Investigating factors affecting learners perception toward online learning evidence from ClassStart application in Thailand,"Nattaporn Thongsri, Liang Shen, Yukun Bao","Twenty-First Century Education is a design of instructional culture that
empowers learner-centered through the philosophy of ""Less teaching but more
learning"". Due to the development of technology enhance learning in developing
countries such as Thailand, online learning is rapidly growing in the
electronic learning market. ClassStart is a learning management system
developed to support Thailand's educational management and to promote the
student-centred learning processes. It also allows the instructor to analyse
individual learners through system-generated activities. The study of online
learning acceptance is primarily required to successfully achieve online
learning system development. However, the behavioural intention of students to
use online learning systems has not been well examined, in particular, by
focusing specific but representative applications such as ClassStart in this
study. This research takes the usage of ClassStart as research scenario and
investigates the individual acceptance of technology through the Unified Theory
of Acceptance and Use of Technology, as well as technological quality through
the Delone and McLean IS success model. A total of 307 undergraduate students
using ClassStart responded to the survey. The Partial Least Squares method, a
statistics analysis technique based on the Structural Equation Model (SEM), was
used to analyze the data. It was found that performance expectancy, social
influence, information quality and system quality have the significant effect
on intention to use ClassStart.",Computers and Society (cs.CY),,[Submitted on 3 Mar 2019]
The invisible power of fairness. How machine learning shapes democracy,"Elena Beretta, Antonio Santangelo, Bruno Lepri, Antonio Vetrò, Juan Carlos De Martin","Many machine learning systems make extensive use of large amounts of data
regarding human behaviors. Several researchers have found various
discriminatory practices related to the use of human-related machine learning
systems, for example in the field of criminal justice, credit scoring and
advertising. Fair machine learning is therefore emerging as a new field of
study to mitigate biases that are inadvertently incorporated into algorithms.
Data scientists and computer engineers are making various efforts to provide
definitions of fairness. In this paper, we provide an overview of the most
widespread definitions of fairness in the field of machine learning, arguing
that the ideas highlighting each formalization are closely related to different
ideas of justice and to different interpretations of democracy embedded in our
culture. This work intends to analyze the definitions of fairness that have
been proposed to date to interpret the underlying criteria and to relate them
to different ideas of democracy.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 22 Mar 2019]
Substation One-Line Diagram Automatic Generation and Visualization,"Jing Hong, Yue Li, Yiran Xu, Chen Yuan, Hong Fan, Guangyi Liu, Renchang Dai","In Energy Management System (EMS) applications and many other off-line
planning and study tools, one-line diagram (OLND) of the whole system and
stations is a straightforward view for planners and operators to design,
monitor, analyze, and control the power system. Large-scale power system OLND
is usually manually developed and maintained. The work is tedious,
time-consuming and ease to make mistake. Meanwhile, the manually created
diagrams are hard to be shared among the on-line and off-line systems. To save
the time and efforts to draw and maintain OLNDs, and provide the capability to
share the OLNDs, a tool to automatically develop substation based upon Common
Information Model (CIM) standard is needed. Currently, there is no standard
rule to draw the substation OLND. Besides, the substation layouts can be
altered from the typical formats in textbooks based on factors of economy,
efficiency, engineering practice, etc. This paper presents a tool on substation
OLND automatic generation and visualization. This tool takes the substation
CIM/E model as input, then automatically computes the coordinates of all
components and generates the substation OLND based on its components attributes
and connectivity relations. Evaluation of the proposed approach is presented
using a real provincial power system. Over 95\% of substation OLNDs are
decently presented and the rest are corner cases, needing extra effort to do
specific reconfiguration.",Other Computer Science (cs.OH),; Systems and Control (eess.SY),[Submitted on 20 Mar 2019]
WSN and Fog Computing Integration for Intelligent Data Processing,"Viorel Mihai, Cristina Elena Hanganu, Grigore Stamatescu, Dan Popescu","Networked embedded systems endowed with sensing, computing, control and
communication capabilities allow the development of various application
scenarios and represent the building blocks of the Internet of Things (IoT)
paradigm. Traditional data collection methods include multiple field level IoT
systems that can relay data stemming from a network of distributed ground
sensors directly to a cloud platform for storage, analysis and processing. In
such applications however, rapid sensor deployment in unstructured environments
represents a challenge to the overall robustness of the system. We discuss the
fog and mist computing approaches to hierarchically process data along its path
from source to destination. The several stages of intermediate data processing
reduce the computational and communication effort in a gradual manner. A
three-layer topology for smart data monitoring and processing is thus proposed
and illustrated to improve the information to noise ratio in a reference
scenario.","Distributed, Parallel, and Cluster Computing (cs.DC)",,[Submitted on 22 Mar 2019]
Hierarchical Dynamic Loop Self-Scheduling on Distributed-Memory Systems Using an MPI+MPI Approach,"Ahmed Eleliemy, Florina M. Ciorba","Computationally-intensive loops are the primary source of parallelism in
scientific applications. Such loops are often irregular and a balanced
execution of their loop iterations is critical for achieving high performance.
However, several factors may lead to an imbalanced load execution, such as
problem characteristics, algorithmic, and systemic variations. Dynamic loop
self-scheduling (DLS) techniques are devised to mitigate these factors, and
consequently, improve application performance. On distributed-memory systems,
DLS techniques can be implemented using a hierarchical master-worker execution
model and are, therefore, called hierarchical DLS techniques. These techniques
self-schedule loop iterations at two levels of hardware parallelism: across and
within compute nodes. Hybrid programming approaches that combine the message
passing interface (MPI) with open multi-processing (OpenMP) dominate the
implementation of hierarchical DLS techniques. The MPI-3 standard includes the
feature of sharing memory regions among MPI processes. This feature introduced
the MPI+MPI approach that simplifies the implementation of parallel scientific
applications. The present work designs and implements hierarchical DLS
techniques by exploiting the MPI+MPI approach. Four well-known DLS techniques
are considered in the evaluation proposed herein. The results indicate certain
performance advantages of the proposed approach compared to the hybrid
MPI+OpenMP approach.","Distributed, Parallel, and Cluster Computing (cs.DC)",,[Submitted on 22 Mar 2019]
Process Mining of Programmable Logic Controllers: Input/Output Event Logs,"Julian Theis, Ilia Mokhtarian, Houshang Darabi","This paper presents an approach to model an unknown Ladder Logic based
Programmable Logic Controller (PLC) program consisting of Boolean logic and
counters using Process Mining techniques. First, we tap the inputs and outputs
of a PLC to create a data flow log. Second, we propose a method to translate
the obtained data flow log to an event log suitable for Process Mining. In a
third step, we propose a hybrid Petri net (PN) and neural network approach to
approximate the logic of the actual underlying PLC program. We demonstrate the
applicability of our proposed approach on a case study with three simulated
scenarios.",Systems and Control (eess.SY),,[Submitted on 22 Mar 2019]
Was ist eine Professur fuer Kuenstliche Intelligenz?,"Kristian Kersting, Jan Peters, Constantin Rothkopf","The Federal Government of Germany aims to boost the research in the field of
Artificial Intelligence (AI). For instance, 100 new professorships are said to
be established. However, the white paper of the government does not answer what
an AI professorship is at all. In order to give colleagues, politicians, and
citizens an idea, we present a view that is often followed when appointing
professors for AI at German and international universities. We hope that it
will help to establish a guideline with internationally accepted measures and
thus make the public debate more informed.",Other Computer Science (cs.OH),; Artificial Intelligence (cs.AI),[Submitted on 17 Feb 2019]
Trial of an AI: Empowering people to explore law and science challenges,Gaudron Arthur (CAOR),"Artificial Intelligence represents many things: a new market to conquer or a
quality label for tech companies, a threat for traditional industries, a menace
for democracy, or a blessing for our busy everyday life. The press abounds in
examples illustrating these aspects, but one should draw not hasty and
premature conclusions. The first successes in AI have been a surprise for
society at large-including researchers in the field. Today, after the initial
stupefaction, we have examples of the system reactions: traditional companies
are heavily investing in AI, social platforms are monitored during elections,
data collection is more and more regulated, etc. The resilience of an
organization (i.e. its capacity to resist to a shock) relies deeply on the
perception of its environment. Future problems have to be anticipated, while
unforeseen events occurring have to be quickly identified in order to be
mitigated as fast as possible. The author states that this clear perception
starts with a common definition of AI in terms of capacities and limits. AI
practitioners should make notions and concepts accessible to the general public
and the impacted fields (e.g. industries, law, education). It is a truism that
only law experts would have the potential to estimate IA impacts on judicial
system. However, questions remain on how to connect different kind of expertise
and what is the appropriate level of detail required for the knowledge
exchanges. And the same consideration is true for dissemination towards
society. Ultimately, society will live with decisions made by the ""experts"". It
sounds wise to involve society in the decision process rather than risking to
pay consequences later. Therefore, society also needs the key concepts to
understand AI impact on their life. This was the purpose of the trial of an IA
that took place in October 2018 at the Court of Appeal of Paris: gathering
experts from various fields to expose challenges in law and science towards a
general public.",Other Computer Science (cs.OH),; Artificial Intelligence (cs.AI); Computers and Society (cs.CY),[Submitted on 5 Mar 2019]
An empirical assessment of best-answer prediction models in technical Q&A sites,"Fabio Calefato, Filippo Lanubile, Nicole Novielli","Technical Q&A sites have become essential for software engineers as they
constantly seek help from other experts to solve their work problems. Despite
their success, many questions remain unresolved, sometimes because the asker
does not acknowledge any helpful answer. In these cases, an information seeker
can only browse all the answers within a question thread to assess their
quality as potential solutions. We approach this time-consuming problem as a
binary-classification task where a best-answer prediction model is built to
identify the accepted answer among those within a resolved question thread, and
the candidate solutions to those questions that have received answers but are
still unresolved. In this paper, we report on a study aimed at assessing 26
best-answer prediction models in two steps. First, we study how models perform
when predicting best answers in Stack Overflow, the most popular Q&A site for
software engineers. Then, we assess performance in a cross-platform setting
where the prediction models are trained on Stack Overflow and tested on other
technical Q&A sites. Our findings show that the choice of the classifier and
automated parameter tuning have a large impact on the prediction of the best
answer. We also demonstrate that our approach to the best-answer prediction
problem is generalizable across technical Q&A sites. Finally, we provide
practical recommendations to Q&A platform designers to curate and preserve the
crowdsourced knowledge shared through these sites.",Software Engineering (cs.SE),,[Submitted on 22 Mar 2019]
Best-of-Three Voting on Dense Graphs,"Nan Kang, Nicolas Rivera","Given a graph $G$ of $n$ vertices, where each vertex is initially attached an
opinion of either red or blue. We investigate a random process known as the
Best-of-three voting. In this process, at each time step, every vertex chooses
three neighbours at random and adopts the majority colour. We study this
process for a class of graphs with minimum degree $d = n^{\alpha}$\,, where
$\alpha = \Omega\left( (\log \log n)^{-1} \right)$. We prove that if initially
each vertex is red with probability greater than $1/2+\delta$, and blue
otherwise, where $\delta \geq (\log d)^{-C}$ for some $C>0$, then with high
probability this dynamic reaches a final state where all vertices are red
within $O\left( \log \log n\right) + O\left( \log \left( \delta^{-1} \right)
\right)$ steps.",Discrete Mathematics (cs.DM),"; Distributed, Parallel, and Cluster Computing (cs.DC); Probability (math.PR)",[Submitted on 22 Mar 2019]
EMTk - The Emotion Mining Toolkit,"Fabio Calefato, Filippo Lanubile, Nicole Novielli, Luigi Quaranta","The Emotion Mining Toolkit (EMTk) is a suite of modules and datasets offering
a comprehensive solution for mining sentiment and emotions from technical text
contributed by developers on communication channels. The toolkit is written in
Java, Python, and R, and is released under the MIT open source license. In this
paper, we describe its architecture and the benchmark against the previous,
standalone versions of our sentiment analysis tools. Results show large
improvements in terms of speed.",Software Engineering (cs.SE),,"[Submitted on 22 Mar 2019 (v1), last revised 19 May 2019 (this version, v2)]"
Why do developers take breaks from contributing to OSS projects? A preliminary analysis,"Giuseppe Iaffaldano, Igor Steinmacher, Fabio Calefato, Marco Gerosa, Filippo Lanubile","Creating a successful and sustainable Open Source Software (OSS) project
often depends on the strength and the health of the community behind it.
Current literature explains the contributors' lifecycle, starting with the
motivations that drive people to contribute and barriers to joining OSS
projects, covering developers' evolution until they become core members.
However, the stages when developers leave the projects are still weakly
explored and are not well-defined in existing developers' lifecycle models. In
this position paper, we enrich the knowledge about the leaving stage by
identifying sleeping and dead states, representing temporary and permanent
brakes that developers take from contributing. We conducted a preliminary set
of semi-structured interviews with active developers. We analyzed the answers
by focusing on defining and understanding the reasons for the transitions
to/from sleeping and dead states. This paper raises new questions that may
guide further discussions and research, which may ultimately benefit OSS
communities.",Software Engineering (cs.SE),,[Submitted on 22 Mar 2019]
The Multi-Event-Class Synchronization (MECS) Algorithm,"Paolo Alborno, Gualtiero Volpe, Maurizio Mancini, Radoslaw Niewiadomski, Stefano Piana, Antonio Camurri","Synchronization is a fundamental component of computational models of human
behavior, at both intra-personal and inter-personal level. Event
synchronization analysis was originally conceived with the aim of providing a
simple and robust method to measure synchronization between two time series. In
this paper we propose a novel method extending the state-of-the-art of the
event synchronization techniques: the Multi-Event-Class Synchronization (MECS)
algorithm. MECS measures the synchronization between relevant events belonging
to different event classes that are detected in multiple time series. Its
motivation emerged from the need to model non-verbal multimodal signals in
Human-Computer Interaction. Using MECS, synchronization can be computed between
events belonging to the same class (intra-class synchronization) or between
events belonging to different classes (inter-class synchronization). In the
paper we also show how our technique can deal with macro-events (i.e., sets of
events satisfying constraints) and macro-classes (i.e., sets of classes). In
the last part of the paper, we apply the proposed method to two types of data
i) artificial and 2) real-world case study concerning analysis of human
multimodal behavior.",Human-Computer Interaction (cs.HC),,"[Submitted on 22 Mar 2019 (v1), last revised 8 Apr 2019 (this version, v2)]"
Iterative Reinforcement Learning Based Design of Dynamic Locomotion Skills for Cassie,"Zhaoming Xie, Patrick Clary, Jeremy Dao, Pedro Morais, Jonathan Hurst, Michiel van de Panne","Deep reinforcement learning (DRL) is a promising approach for developing
legged locomotion skills. However, the iterative design process that is
inevitable in practice is poorly supported by the default methodology. It is
difficult to predict the outcomes of changes made to the reward functions,
policy architectures, and the set of tasks being trained on. In this paper, we
propose a practical method that allows the reward function to be fully
redefined on each successive design iteration while limiting the deviation from
the previous iteration. We characterize policies via sets of Deterministic
Action Stochastic State (DASS) tuples, which represent the deterministic policy
state-action pairs as sampled from the states visited by the trained stochastic
policy. New policies are trained using a policy gradient algorithm which then
mixes RL-based policy gradients with gradient updates defined by the DASS
tuples. The tuples also allow for robust policy distillation to new network
architectures. We demonstrate the effectiveness of this iterative-design
approach on the bipedal robot Cassie, achieving stable walking with different
gait styles at various speeds. We demonstrate the successful transfer of
policies learned in simulation to the physical robot without any dynamics
randomization, and that variable-speed walking policies for the physical robot
can be represented by a small dataset of 5-10k tuples.",Robotics (cs.RO),,[Submitted on 22 Mar 2019]
Evaluation of a deep learning system for the joint automated detection of diabetic retinopathy and age-related macular degeneration,"Cristina González-Gonzalo, Verónica Sánchez-Gutiérrez, Paula Hernández-Martínez, Inés Contreras, Yara T. Lechanteur, Artin Domanian, Bram van Ginneken, Clara I. Sánchez","Purpose: To validate the performance of a commercially-available,
CE-certified deep learning (DL) system, RetCAD v.1.3.0 (Thirona, Nijmegen, The
Netherlands), for the joint automatic detection of diabetic retinopathy (DR)
and age-related macular degeneration (AMD) in color fundus (CF) images on a
dataset with mixed presence of eye diseases.
Methods: Evaluation of joint detection of referable DR and AMD was performed
on a DR-AMD dataset with 600 images acquired during routine clinical practice,
containing referable and non-referable cases of both diseases. Each image was
graded for DR and AMD by an experienced ophthalmologist to establish the
reference standard (RS), and by four independent observers for comparison with
human performance. Validation was furtherly assessed on Messidor (1200 images)
for individual identification of referable DR, and the Age-Related Eye Disease
Study (AREDS) dataset (133821 images) for referable AMD, against the
corresponding RS.
Results: Regarding joint validation on the DR-AMD dataset, the system
achieved an area under the ROC curve (AUC) of 95.1% for detection of referable
DR (SE=90.1%, SP=90.6%). For referable AMD, the AUC was 94.9% (SE=91.8%,
SP=87.5%). Average human performance for DR was SE=61.5% and SP=97.8%; for AMD,
SE=76.5% and SP=96.1%. Regarding detection of referable DR in Messidor, AUC was
97.5% (SE=92.0%, SP=92.1%); for referable AMD in AREDS, AUC was 92.7%
(SE=85.8%, SP=86.0%).
Conclusions: The validated system performs comparably to human experts at
simultaneous detection of DR and AMD. This shows that DL systems can facilitate
access to joint screening of eye diseases and become a quick and reliable
support for ophthalmological experts.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 22 Mar 2019]
Monte Carlo Neural Fictitious Self-Play: Approach to Approximate Nash equilibrium of Imperfect-Information Games,"Li Zhang, Wei Wang, Shijian Li, Gang Pan","Researchers on artificial intelligence have achieved human-level intelligence
in large-scale perfect-information games, but it is still a challenge to
achieve (nearly) optimal results (in other words, an approximate Nash
Equilibrium) in large-scale imperfect-information games (i.e. war games,
football coach or business strategies). Neural Fictitious Self Play (NFSP) is
an effective algorithm for learning approximate Nash equilibrium of
imperfect-information games from self-play without prior domain knowledge.
However, it relies on Deep Q-Network, which is off-line and is hard to converge
in online games with changing opponent strategy, so it can't approach
approximate Nash equilibrium in games with large search scale and deep search
depth. In this paper, we propose Monte Carlo Neural Fictitious Self Play
(MC-NFSP), an algorithm combines Monte Carlo tree search with NFSP, which
greatly improves the performance on large-scale zero-sum imperfect-information
games. Experimentally, we demonstrate that the proposed Monte Carlo Neural
Fictitious Self Play can converge to approximate Nash equilibrium in games with
large-scale search depth while the Neural Fictitious Self Play can't.
Furthermore, we develop Asynchronous Neural Fictitious Self Play (ANFSP). It
use asynchronous and parallel architecture to collect game experience. In
experiments, we show that parallel actor-learners have a further accelerated
and stabilizing effect on training.",Artificial Intelligence (cs.AI),,"[Submitted on 22 Mar 2019 (v1), last revised 6 Apr 2019 (this version, v2)]"
NOMA in the Uplink: Delay Analysis with Imperfect CSI and Finite-Length Coding,"Sebastian Schiessl, Mikael Skoglund, James Gross","We study whether using non-orthogonal multiple access (NOMA) in the uplink of
a mobile network can improve the performance over orthogonal multiple access
(OMA) when the system requires ultra-reliable low-latency communications
(URLLC). To answer this question, we first consider an ideal system model with
perfect channel state information (CSI) at the transmitter and long codewords,
where we determine the optimal decoding orders when the decoder uses successive
interference cancellation (SIC) and derive closed-form expressions for the
optimal rate when joint decoding is used. While joint decoding performs well
even under tight delay constraints, NOMA with SIC decoding often performs worse
than OMA. For low-latency systems, we must also consider the impact of
finite-length channel coding, as well as rate adaptation based imperfect CSI.
We derive closed-form approximations for the corresponding outage or error
probabilities and find that those effects create a larger performance penalty
for NOMA than for OMA. Thus, NOMA with SIC decoding may often be unsuitable for
URLLC.",Information Theory (cs.IT),,[Submitted on 22 Mar 2019]
Comparison of Hand-held WEMI Target Detection Algorithms,"Connor H. McCurley, James Bocinsky, Alina Zare","Wide-band Electromagnetic Induction Sensors (WEMI) have been used for a
number of years in subsurface detection of explosive hazards. While WEMI
sensors have proven effective at localizing objects exhibiting large magnetic
responses, detecting objects lacking or containing very low amounts of
conductive materials can be challenging. In this paper, we compare a number of
target detection algorithms in the literature in terms of detection
performance. In the comparison, methods are tested on two real-world data sets:
one containing relatively low amounts of ground noise pollution, and the other
demonstrating highly-magnetic soil interference. Results are quantitatively
evaluated through receiver-operator characteristic (ROC) curves and are used to
highlight the strengths and weaknesses of the compared approaches in hand-held
explosive hazard detection.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 22 Mar 2019]
Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence,"Chi Sun, Luyao Huang, Xipeng Qiu","Aspect-based sentiment analysis (ABSA), which aims to identify fine-grained
opinion polarity towards a specific aspect, is a challenging subtask of
sentiment analysis (SA). In this paper, we construct an auxiliary sentence from
the aspect and convert ABSA to a sentence-pair classification task, such as
question answering (QA) and natural language inference (NLI). We fine-tune the
pre-trained model from BERT and achieve new state-of-the-art results on
SentiHood and SemEval-2014 Task 4 datasets.",Computation and Language (cs.CL),,[Submitted on 22 Mar 2019]
A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering,"Ajay Kumar Tanwani, Nitesh Mor, John Kubiatowicz, Joseph E. Gonzalez, Ken Goldberg","The growing demand of industrial, automotive and service robots presents a
challenge to the centralized Cloud Robotics model in terms of privacy,
security, latency, bandwidth, and reliability. In this paper, we present a `Fog
Robotics' approach to deep robot learning that distributes compute, storage and
networking resources between the Cloud and the Edge in a federated manner. Deep
models are trained on non-private (public) synthetic images in the Cloud; the
models are adapted to the private real images of the environment at the Edge
within a trusted network and subsequently, deployed as a service for
low-latency and secure inference/prediction for other robots in the network. We
apply this approach to surface decluttering, where a mobile robot picks and
sorts objects from a cluttered floor by learning a deep object recognition and
a grasp planning model. Experiments suggest that Fog Robotics can improve
performance by sim-to-real domain adaptation in comparison to exclusively using
Cloud or Edge resources, while reducing the inference cycle time by 4\times to
successfully declutter 86% of objects over 213 attempts.",Robotics (cs.RO),,[Submitted on 22 Mar 2019]
Improving Search with Supervised Learning in Trick-Based Card Games,"Christopher Solinas, Douglas Rebstock, Michael Buro","In trick-taking card games, a two-step process of state sampling and
evaluation is widely used to approximate move values. While the evaluation
component is vital, the accuracy of move value estimates is also fundamentally
linked to how well the sampling distribution corresponds the true distribution.
Despite this, recent work in trick-taking card game AI has mainly focused on
improving evaluation algorithms with limited work on improving sampling. In
this paper, we focus on the effect of sampling on the strength of a player and
propose a novel method of sampling more realistic states given move history. In
particular, we use predictions about locations of individual cards made by a
deep neural network --- trained on data from human gameplay - in order to
sample likely worlds for evaluation. This technique, used in conjunction with
Perfect Information Monte Carlo (PIMC) search, provides a substantial increase
in cardplay strength in the popular trick-taking card game of Skat.",Artificial Intelligence (cs.AI),,[Submitted on 22 Mar 2019]
Optimizing the Access to Healthcare Services in Dense Refugee Hosting Urban Areas: A Case for Istanbul,"M. Tarik Altuncu, Ayse Seyyide Kaptaner, Nur Sevencan","With over 3.5 million refugees, Turkey continues to host the world's largest
refugee population. This introduced several challenges in many areas including
access to healthcare system. Refugees have legal rights to free healthcare
services in Turkey's public hospitals. With the aim of increasing healthcare
access for refugees, we looked at where the lack of infrastructure is felt the
most. Our study attempts to address these problems by assessing whether Migrant
Health Centers' locations are optimal. The aim of this study is to improve
refugees' access to healthcare services in Istanbul by improving the locations
of health facilities available to them. We used call data records provided by
Turk Telekom.",Computers and Society (cs.CY),,[Submitted on 21 Feb 2019]
On the Importance of Video Action Recognition for Visual Lipreading,Xinshuo Weng,"We focus on the word-level visual lipreading, which requires to decode the
word from the speaker's video. Recently, many state-of-the-art visual
lipreading methods explore the end-to-end trainable deep models, involving the
use of 2D convolutional networks (e.g., ResNet) as the front-end visual feature
extractor and the sequential model (e.g., Bi-LSTM or Bi-GRU) as the back-end.
Although a deep 2D convolution neural network can provide informative
image-based features, it ignores the temporal motion existing between the
adjacent frames. In this work, we investigate the spatial-temporal capacity
power of I3D (Inflated 3D ConvNet) for visual lipreading. We demonstrate that,
after pre-trained on the large-scale video action recognition dataset (e.g.,
Kinetics), our models show a considerable improvement of performance on the
task of lipreading. A comparison between a set of video model architectures and
input data representation is also reported. Our extensive experiments on LRW
shows that a two-stream I3D model with RGB video and optical flow as the inputs
achieves the state-of-the-art performance.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 22 Mar 2019 (v1), last revised 16 Sep 2019 (this version, v2)]"
"""The Perfect One"": Understanding Communication Practices and Challenges with Animated GIFs","Jialun ""Aaron"" Jiang, Casey Fiesler, Jed R. Brubaker","Animated GIFs are increasingly popular in text-based communication. Finding
the perfect GIF can make conversations funny, interesting, and engaging, but
GIFs also introduce potentials for miscommunication. Through 24 in-depth
qualitative interviews, this empirical, exploratory study examines the nuances
of communication practices with animated GIFs to better understand why and how
GIFs can send unintentional messages. We find participants leverage contexts
like source material and interpersonal relationship to find the perfect GIFs
for different communication scenarios, while these contexts are also the
primary reason for miscommunication and some technical usability issues in
GIFs. This paper concludes with a discussion of the important role that
different types of context play in the use and interpretations of GIFs, and
argues that nonverbal communication tools should account for complex contexts
and common ground that communication media rely on.",Human-Computer Interaction (cs.HC),,[Submitted on 22 Mar 2019]
Key technologies to accelerate the ICT Green evolution -- An operator's point of view,"Azeddine Gati, Fatma Ezzahra Salem, Ana Maria Galindo Serrano, Didier Marquet, Stephane Le Masson, Thomas Rivera, Dinh-Thuy Phan-Huy, Zwi Altman, Jean-Baptiste Landre, Olivier Simon, Esther Le Rouzic, Fabrice Bourgart, Stephane Gosselin, Marc Vautier, Eric Gourdin, Taoufik En-Najjary, Mamdouh El-Tabach, Raluca-Maria Indre, Guillaume Gerard, Gwenaelle Delsart","The exponential growth in networks' traffic accompanied by the multiplication
of new services like those promised by the 5G led to a huge increase in the
infrastructures' energy consumption. All over the world, many telecom operators
are facing the problem of energy consumption and Green networking since many
years and they all convey today that it turned from sustainable development
initiative to an OPEX issue. Therefore, the challenge to make the ICT sector
more energy-efficient and environment-friendly has become a fundamental
objective not only to green networks but also in the domain of green services
that enable the ICT sectors to help other industrial sector to clean their own
energy consumption. The present paper is a point of view of a European telecom
operator regarding green networking. We address some technological advancements
that would enable to accelerate this ICT green evolution after more than 15
years of field experience and international collaborative research projects.
Basically, the paper is a global survey of the evolution of the ICT industry in
green networks including optical and wireless networks and from hardware
improvement to the software era as well as the green orchestration.",Networking and Internet Architecture (cs.NI),,[Submitted on 22 Mar 2019]
"Efficient energy, cost reduction, and QoS based routing protocol for wireless sensor networks","Ghassan Samara, Mohammad Aljaidi","Recent developments and widespread in wireless sensor network have led to
many routing protocols, many of these protocols consider the efficiency of
energy as the ultimate factor to maximize the WSN lifetime. The quality of
Service (QoS) requirements for different applications of wireless sensor
networks has posed additional challenges. Imaging and data transmission needs
both QoS aware routing and energy to ensure the efficient use of sensors. In
this paper, we propose an Efficient, Energy-Aware, Least Cost, (ECQSR) quality
of service routing protocol for sensor networks which can run efficiently with
best-effort traffic processing. The protocol aims to maximize the lifetime of
the network out of balancing energy consumption across multiple nodes, by using
the concept of service differentiation, finding lower cost by finding the
shortest path using nearest neighbor algorithm (NN), also put certain
constraints on the delay of the path for real-time data from where link cost
that captures energy nodes reserve, energy of the transmission, error rate and
other parameters. The results show that the proposed protocol improves the
network lifetime and low power consumption.",Networking and Internet Architecture (cs.NI),,[Submitted on 23 Mar 2019]
Understanding Childhood Vulnerability in The City of Surrey,"Cody Griffith, Varoon Mathur, Catherine Lin, Kevin Zhu","Understanding the community conditions that best support universal access and
improved childhood outcomes allows ultimately to improve decision-making in the
areas of planning and investment across the early stages of childhood
development. Here we describe two different data-driven approaches to
visualizing the lived experiences of children throughout the City of Surrey,
combining data derived from both public and private sources. In one approach,
we find specifically that the Early Development Instrument measuring childhood
vulnerabilities across varying domains can be used to cluster neighborhoods,
and that census variables can help explain similarities between neighborhoods
within these clusters. In our second approach, we use program registration data
from the City of Surrey's Community and Recreation Services Division. We also
find a critical age of entry and exit for each program related to early
childhood development and beyond, and find that certain neighborhoods and
recreational programs have larger retention rates than others. This report
details the journey of using data to tell the story of these neighborhoods, and
provides a lens to which community initiatives can be strategically crafted
through their use.",Computers and Society (cs.CY),; Machine Learning (cs.LG); Machine Learning (stat.ML),[Submitted on 25 Mar 2019]
Anti-Turing Machine,Viacheslav Dubeyko,"The invention of CPU-centric computing paradigm was incredible breakthrough
of computer science that revolutionized our everyday life dramatically.
However, the CPU- centric paradigm is based on the Turing machine concept and,
as a result, expensive and power-hungry data transferring between the memory
and CPU core is inevitable operation. Anti-Turing machine paradigm can be based
on two fundamental principles: (1) data-centric computing, and (2)
decentralized computing. Anti-Turing machine is able to execute a special type
of programs. The commands of such program have to be addressed to the 2D or 3D
persistent memory space is able to process data in-place. This program should
not define the position or structure of data but it has to define the goal of
data processing activity. Generally speaking, it needs to consider the whole
memory space like the data transformation space. But the data placement,
particular algorithm implementation, and strategy of algorithm execution are
out of scope of the program.",Other Computer Science (cs.OH),,[Submitted on 22 Mar 2019]
A Hybrid Approach to Persistent Coverage in Stochastic Environments,"William Bentz, Dimitra Panagou","This paper considers the persistent coverage of a 2-D manifold that has been
embedded in 3-D space. The manifold is subject to continual impact by intruders
which travel at constant velocities along arbitrarily oriented straight-line
trajectories. The trajectories of intruders are estimated online with an
extended Kalman filter and their predicted impact points contribute normally
distributed decay terms to the coverage level. A formal hybrid control strategy
is presented that allows for power-constrained 3-D free-flyer agents to
persistently monitor the domain, track and intercept intruders, and
periodically deploy from and return to a single charging station on the
manifold. Guarantees on intruder interception with respect to agent power
lifespans are formally proven. The efficacy of the algorithm is demonstrated
through simulation.",Multiagent Systems (cs.MA),,"[Submitted on 22 Mar 2019 (v1), last revised 5 Aug 2019 (this version, v2)]"
Capsule Networks with Max-Min Normalization,"Zhen Zhao, Ashley Kleinhans, Gursharan Sandhu, Ishan Patel, K. P. Unnikrishnan","Capsule Networks (CapsNet) use the Softmax function to convert the logits of
the routing coefficients into a set of normalized values that signify the
assignment probabilities between capsules in adjacent layers. We show that the
use of Softmax prevents capsule layers from forming optimal couplings between
lower and higher-level capsules. Softmax constrains the dynamic range of the
routing coefficients and leads to probabilities that remain mostly uniform
after several routing iterations. Instead, we propose the use of Max-Min
normalization. Max-Min performs a scale-invariant normalization of the logits
that allows each lower-level capsule to take on an independent value,
constrained only by the bounds of normalization. Max-Min provides consistent
improvement in test accuracy across five datasets and allows more routing
iterations without a decrease in network performance. A single CapsNet trained
using Max-Min achieves an improved test error of 0.20% on the MNIST dataset.
With a simple 3-model majority vote, we achieve a test error of 0.17% on MNIST.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 22 Mar 2019]
Compliance Shaping for Control of Strength Amplification Exoskeletons with Elastic Cuffs,"Gray Cortright Thomas, Jeremiah M. Coholich, Luis Sentis","Exoskeletons which amplify the strength of their operators can enable
heavy-duty manipulation of unknown objects. However, this type of behavior is
difficult to accomplish; it requires the exoskeleton to sense and amplify the
operator's interaction forces while remaining stable. But, the goals of
amplification and robust stability when connected to the operator fundamentally
conflict. As a solution, we introduce a design with a spring in series with the
force sensitive cuff. This allows us to design an exoskeleton compliance
behavior which is nominally passive, even with high amplification ratios. In
practice, time delay and discrete time filters prevent our strategy from
actually achieving passivity, but the designed compliance still makes the
exoskeleton more robust to spring-like human behaviors. Our exoskeleton is
actuated by a series elastic actuator (SEA), which introduces another spring
into the system. We show that shaping the cuff compliance for the exoskeleton
can be made into approximately the same problem as shaping the spring
compliance of an SEA. We therefore introduce a feedback controller and gain
tuning method which takes advantage of an existing compliance shaping technique
for SEAs. We call our strategy the ""double compliance shaping"" method. With
large amplification ratios, this controller tends to amplify nonlinear
transmission friction effects, so we additionally propose a ""transmission
disturbance observer"" to mitigate this drawback. Our methods are validated on a
single-degree-of-freedom elbow exoskeleton.",Robotics (cs.RO),; Systems and Control (eess.SY); Dynamical Systems (math.DS); Optimization and Control (math.OC),[Submitted on 22 Mar 2019]
Stochastic phase-cohesiveness of discrete-time Kuramoto oscillators in a frequency-dependent tree network,"Matin Jafarian, Mohammad H. Mamduhi, Karl H. Johansson","This paper presents the notion of stochastic phase-cohesiveness based on the
concept of recurrent Markov chains and studies the conditions under which a
discrete-time stochastic Kuramoto model is phase-cohesive. It is assumed that
the exogenous frequencies of the oscillators are combined with random variables
representing uncertainties. A bidirectional tree network is considered such
that each oscillator is coupled to its neighbors with a coupling law which
depends on its own noisy exogenous frequency. In addition, an undirected tree
network is studied. For both cases, a sufficient condition for the common
coupling strength and a necessary condition for the sampling-period are derived
such that the stochastic phase-cohesiveness is achieved. The analysis is
performed within the stochastic systems framework and validated by means of
numerical simulations.",Systems and Control (eess.SY),,[Submitted on 22 Mar 2019]
Symbolic Regression Methods for Reinforcement Learning,"Jiří Kubalík, Jan Žegklitz, Erik Derner, Robert Babuška","Reinforcement learning algorithms can be used to optimally solve dynamic
decision-making and control problems. With continuous-valued state and input
variables, reinforcement learning algorithms must rely on function
approximators to represent the value function and policy mappings. Commonly
used numerical approximators, such as neural networks or basis function
expansions, have two main drawbacks: they are black-box models offering no
insight in the mappings learned, and they require significant trial and error
tuning of their meta-parameters. In this paper, we propose a new approach to
constructing smooth value functions by means of symbolic regression. We
introduce three off-line methods for finding value functions based on a state
transition model: symbolic value iteration, symbolic policy iteration, and a
direct solution of the Bellman equation. The methods are illustrated on four
nonlinear control problems: velocity control under friction, one-link and
two-link pendulum swing-up, and magnetic manipulation. The results show that
the value functions not only yield well-performing policies, but also are
compact, human-readable and mathematically tractable. This makes them
potentially suitable for further analysis of the closed-loop system. A
comparison with alternative approaches using neural networks shows that our
method constructs well-performing value functions with substantially fewer
parameters.",Machine Learning (cs.LG),; Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Machine Learning (stat.ML),[Submitted on 22 Mar 2019]
Distributed estimation and control of node centrality in undirected asymmetric networks,"Eduardo Montijano, Gabriele Oliva, Andrea Gasparri","Measures of node centrality that describe the importance of a node within a
network are crucial for understanding the behavior of social networks and
graphs. In this paper, we address the problems of distributed estimation and
control of node centrality in undirected graphs with asymmetric weight values.
In particular, we focus our attention on $\alpha$-centrality, which can be seen
as a generalization of eigenvector centrality. In this setting, we first
consider a distributed protocol where agents compute their $\alpha$-centrality,
focusing on the convergence properties of the method; then, we combine the
estimation method with a consensus algorithm to achieve a consensus value
weighted by the influence of each node in the network. Finally, we formulate an
$\alpha$-centrality control problem which is naturally decoupled and, thus,
suitable for a distributed setting and we apply this formulation to protect the
most valuable nodes in a network against a targeted attack, by making every
node in the network equally important in terms of {\alpha}-centrality.
Simulations results are provided to corroborate the theoretical findings.",Systems and Control (eess.SY),,"[Submitted on 22 Mar 2019 (v1), last revised 5 Jul 2020 (this version, v4)]"
"Quality of Experience from Cache Hierarchies: Keep your low-bitrate close, and high-bitrate closer","Wenjie Li, Sharief M.A. Oteafy, Marwan Fayed, Hossam S. Hassanein","Recent studies into streaming media delivery suggest that performance gains
from cache hierarchies such as Information-Centric Networks (ICNs) may be
negated by Dynamic Adaptive Streaming (DAS), the de facto method for retrieving
multimedia content. The bitrate adaptation mechanisms that drive video
streaming clash with caching hierarchies in ways that affect users' Quality of
Experience (QoE). Cache performance also diminishes as consumers dynamically
select content encoded at different bitrates. In this paper we use the evidence
to draw a novel insight: in a cache hierarchy for adaptive streaming content,
bitrates should be prioritized over or alongside popularity and hit rates. We
build on this insight to propose RippleCache as a family of cache placement
schemes that safeguard high-bitrate content at the edge and push low-bitrate
content into the network core. Doing so reduces contention of cache resources,
as well as congestion in the network. To validate RippleCache claims we
construct two separate implementations. We design RippleClassic as a benchmark
solution that optimizes content placement by maximizing a measure for cache
hierarchies shown to have high correlation with QoE. In addition, our
lighter-weight RippleFinder is then re-designed with distributed execution for
application in large-scale systems. RippleCache performance gains are
reinforced by evaluations in NS-3 against state-of-the-art baseline approaches,
using standard measures of QoE as defined by the DASH Industry Forum.
Measurements show that RippleClassic and RippleFinder deliver content that
suffers less oscillation and rebuffering, as well as the highest levels of
video quality, indicating overall improvements to QoE.",Networking and Internet Architecture (cs.NI),,[Submitted on 22 Mar 2019]
Explaining Reinforcement Learning to Mere Mortals: An Empirical Study,"Andrew Anderson, Jonathan Dodge, Amrita Sadarangani, Zoe Juozapaitis, Evan Newman, Jed Irvine, Souti Chattopadhyay, Alan Fern, Margaret Burnett","We present a user study to investigate the impact of explanations on
non-experts' understanding of reinforcement learning (RL) agents. We
investigate both a common RL visualization, saliency maps (the focus of
attention), and a more recent explanation type, reward-decomposition bars
(predictions of future types of rewards). We designed a 124 participant,
four-treatment experiment to compare participants' mental models of an RL agent
in a simple Real-Time Strategy (RTS) game. Our results show that the
combination of both saliency and reward bars were needed to achieve a
statistically significant improvement in mental model score over the control.
In addition, our qualitative analysis of the data reveals a number of effects
for further study.",Human-Computer Interaction (cs.HC),; Artificial Intelligence (cs.AI),"[Submitted on 22 Mar 2019 (v1), last revised 18 Jun 2019 (this version, v2)]"
An Interaction Framework for Studying Co-Creative AI,"Matthew Guzdial, Mark Riedl","Machine learning has been applied to a number of creative, design-oriented
tasks. However, it remains unclear how to best empower human users with these
machine learning approaches, particularly those users without technical
expertise. In this paper we propose a general framework for turn-based
interaction between human users and AI agents designed to support human
creativity, called {co-creative systems}. The framework can be used to better
understand the space of possible designs of co-creative systems and reveal
future research directions. We demonstrate how to apply this framework in
conjunction with a pair of recent human subject studies, comparing between the
four human-AI systems employed in these studies and generating hypotheses
towards future studies.",Human-Computer Interaction (cs.HC),; Artificial Intelligence (cs.AI),[Submitted on 22 Mar 2019]
Barrier Functions in Cascaded Controller: Safe Quadrotor Control,"Mouhyemen Khan, Munzir Zafar, Abhijit Chatterjee","Safe control for inherently unstable systems such as quadrotors is crucial.
Imposing multiple dynamic constraints simultaneously on the states for safety
regulation can be a challenging problem. In this paper, we propose a quadratic
programming (QP) based approach on a cascaded control architecture for
quadrotors to enforce safety. Safety regions are constructed using control
barrier functions (CBF) while explicitly considering the nonlinear
underactuated dynamics of the quadrotor. The safety regions constructed using
CBFs establish a non-conservative forward invariant safe region for quadrotor
navigation. Barriers imposed across the cascaded architecture allows
independent safety regulation in quadrotor's altitude and lateral domains.
Despite barriers appearing in a cascaded fashion, we show preservation of
safety for quadrotor motion in SE(3). We demonstrate the feasibility of our
method on a quadrotor in simulation with static and dynamic constraints
enforced on position and velocity spaces simultaneously.",Systems and Control (eess.SY),,"[Submitted on 22 Mar 2019 (v1), last revised 17 Feb 2020 (this version, v2)]"
SLING: Using Dynamic Analysis to Infer Program Invariants in Separation Logic,"Ton Chanh Le, Guolong Zheng, ThanhVu Nguyen","We introduce a new dynamic analysis technique to discover invariants in
separation logic for heap-manipulating programs. First, we use a debugger to
obtain rich program execution traces at locations of interest on sample inputs.
These traces consist of heap and stack information of variables that point to
dynamically allocated data structures. Next, we iteratively analyze separate
memory regions related to each pointer variable and search for a formula over
predefined heap predicates in separation logic to model these regions. Finally,
we combine the computed formulae into an invariant that describes the shape of
explored memory regions.
We present SLING, a tool that implements these ideas to automatically
generate invariants in separation logic at arbitrary locations in C programs,
e.g., program pre and postconditions and loop invariants. Preliminary results
on existing benchmarks show that SLING can efficiently generate correct and
useful invariants for programs that manipulate a wide variety of complex data
structures.",Programming Languages (cs.PL),,"[Submitted on 22 Mar 2019 (v1), last revised 29 Jun 2019 (this version, v2)]"
Graph Temporal Logic Inference for Classification and Identification,"Zhe Xu, Alexander J Nettekoven, A. Agung Julius, Ufuk Topcu","Inferring spatial-temporal properties from data is important for many complex
systems, such as additive manufacturing systems, swarm robotic systems and
biological networks. Such systems can often be modeled as a labeled graph where
labels on the nodes and edges represent relevant measurements such as
temperatures and distances. We introduce graph temporal logic (GTL) which can
express properties such as ""whenever a node's label is above 10, for the next 3
time units there are always at least two neighboring nodes with an edge label
of at most 2 where the node labels are above 5"". This paper is a first attempt
to infer spatial (graph) temporal logic formulas from data for classification
and identification. For classification, we infer a GTL formula that classifies
two sets of graph temporal trajectories with minimal misclassification rate.
For identification, we infer a GTL formula that is informative and is satisfied
by the graph temporal trajectories in the dataset with high probability. The
informativeness of a GTL formula is measured by the information gain with
respect to given prior knowledge represented by a prior probability
distribution. We implement the proposed approach to classify the graph patterns
of tensile specimens built from selective laser sintering (SLS) process with
varying strengths, and to identify informative spatial-temporal patterns from
experimental data of the SLS cooldown process and simulation data of a swarm of
robots.",Logic in Computer Science (cs.LO),,[Submitted on 22 Mar 2019]
Instance and Output Optimal Parallel Algorithms for Acyclic Joins,"Xiao Hu, Ke Yi","Massively parallel join algorithms have received much attention in recent
years, while most prior work has focused on worst-optimal algorithms. However,
the worst-case optimality of these join algorithms relies on hard instances
having very large output sizes, which rarely appear in practice. A stronger
notion of optimality is {\em output-optimal}, which requires an algorithm to be
optimal within the class of all instances sharing the same input and output
size. An even stronger optimality is {\em instance-optimal}, i.e., the
algorithm is optimal on every single instance, but this may not always be
achievable.
In the traditional RAM model of computation, the classical Yannakakis
algorithm is instance-optimal on any acyclic join. But in the massively
parallel computation (MPC) model, the situation becomes much more complicated.
We first show that for the class of r-hierarchical joins, instance-optimality
can still be achieved in the MPC model. Then, we give a new MPC algorithm for
an arbitrary acyclic join with load $O ({\IN \over p} + {\sqrt{\IN \cdot \OUT}
\over p})$, where $\IN,\OUT$ are the input and output sizes of the join, and
$p$ is the number of servers in the MPC model. This improves the MPC version of
the Yannakakis algorithm by an $O (\sqrt{\OUT \over \IN} )$ factor.
Furthermore, we show that this is output-optimal when $\OUT = O(p \cdot \IN)$,
for every acyclic but non-r-hierarchical join. Finally, we give the first
output-sensitive lower bound for the triangle join in the MPC model, showing
that it is inherently more difficult than acyclic joins.",Databases (cs.DB),,"[Submitted on 22 Mar 2019 (v1), last revised 28 Mar 2019 (this version, v2)]"
Pre-trained Language Model Representations for Language Generation,"Sergey Edunov, Alexei Baevski, Michael Auli","Pre-trained language model representations have been successful in a wide
range of language understanding tasks. In this paper, we examine different
strategies to integrate pre-trained representations into sequence to sequence
models and apply it to neural machine translation and abstractive
summarization. We find that pre-trained representations are most effective when
added to the encoder network which slows inference by only 14%. Our experiments
in machine translation show gains of up to 5.3 BLEU in a simulated
resource-poor setup. While returns diminish with more labeled data, we still
observe improvements when millions of sentence-pairs are available. Finally, on
abstractive summarization we achieve a new state of the art on the full text
version of CNN/DailyMail.",Computation and Language (cs.CL),,"[Submitted on 22 Mar 2019 (v1), last revised 1 Apr 2019 (this version, v2)]"
Generative Adversarial Minority Oversampling,"Sankha Subhra Mullick, Shounak Datta, Swagatam Das","Class imbalance is a long-standing problem relevant to a number of real-world
applications of deep learning. Oversampling techniques, which are effective for
handling class imbalance in classical learning systems, can not be directly
applied to end-to-end deep learning systems. We propose a three-player
adversarial game between a convex generator, a multi-class classifier network,
and a real/fake discriminator to perform oversampling in deep learning systems.
The convex generator generates new samples from the minority classes as convex
combinations of existing instances, aiming to fool both the discriminator as
well as the classifier into misclassifying the generated samples. Consequently,
the artificial samples are generated at critical locations near the peripheries
of the classes. This, in turn, adjusts the classifier induced boundaries in a
way which is more likely to reduce misclassification from the minority classes.
Extensive experiments on multiple class imbalanced image datasets establish the
efficacy of our proposal.",Computer Vision and Pattern Recognition (cs.CV),; Machine Learning (cs.LG),"[Submitted on 22 Mar 2019 (v1), last revised 26 Aug 2020 (this version, v3)]"
Time Series Imputation,"Samuel Arcadinho, Paulo Mateus","Multivariate time series is a very active topic in the research community and
many machine learning tasks are being used in order to extract information from
this type of data. However, in real-world problems data has missing values,
which may difficult the application of machine learning techniques to extract
information. In this paper we focus on the task of imputation of time series.
Many imputation methods for time series are based on regression methods.
Unfortunately, these methods perform poorly when the variables are categorical.
To address this case, we propose a new imputation method based on Expectation
Maximization over dynamic Bayesian networks. The approach is assessed with
synthetic and real data, and it outperforms several state-of-the art methods.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 22 Mar 2019]
Regularized Learning for Domain Adaptation under Label Shifts,"Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, Animashree Anandkumar","We propose Regularized Learning under Label shifts (RLLS), a principled and a
practical domain-adaptation algorithm to correct for shifts in the label
distribution between a source and a target domain. We first estimate importance
weights using labeled source data and unlabeled target data, and then train a
classifier on the weighted source samples. We derive a generalization bound for
the classifier on the target domain which is independent of the (ambient) data
dimensions, and instead only depends on the complexity of the function class.
To the best of our knowledge, this is the first generalization bound for the
label-shift problem where the labels in the target domain are not available.
Based on this bound, we propose a regularized estimator for the small-sample
regime which accounts for the uncertainty in the estimated weights. Experiments
on the CIFAR-10 and MNIST datasets show that RLLS improves classification
accuracy, especially in the low sample and large-shift regimes, compared to
previous methods.",Machine Learning (cs.LG),; Machine Learning (stat.ML),[Submitted on 22 Mar 2019]
Ultra-Reliable and Low-Latency Communications Using Proactive Multi-cell Association,"Chun-Hung Liu, Di-Chun Liang, Kwang-Cheng Chen, Rung-Hung Gau","Attaining reliable communications traditionally relies on a closed-loop
methodology but inevitably incurs a good amount of networking latency thanks to
complicated feedback mechanism and signaling storm. Such a closed-loop
methodology thus shackles the current cellular network with a tradeoff between
high reliability and low latency. To completely avoid the latency induced by
closed-loop communications, this paper aims to study how to jointly employ
open-loop communications and multi-cell association in a heterogeneous network
(HetNet) so as to achieve ultra-reliable and low-latency communications
(URLLC). We first introduce how URLLC mobile users in a large-scale HetNet
adopt the proposed proactive multi-cell association (PMCA) scheme to form their
virtual cell that consists of multiple access points (APs) and then analyze the
communication reliability and latency performances. We show that the
communication reliability can be significantly improved by the PMCA scheme and
maximized by optimizing the densities of the users and the APs. The analyses of
the uplink and downlink delays are also accomplished, which show that extremely
low latency can be fulfilled in the virtual cell of a single user if the PMCA
scheme is adopted and the radio resources of each AP are appropriately
allocated.",Information Theory (cs.IT),,"[Submitted on 23 Mar 2019 (v1), last revised 4 Aug 2020 (this version, v4)]"
Fast LLMMSE filter for low-dose CT imaging,"Fengling Wang, Bowen Lin, Shujun Fu, Shiling Xie, Zhigang Zhao, Yuliang Li","Low-dose X-ray CT technology is one of important directions of current
research and development of medical imaging equipment. A fast algorithm of
blockwise sinogram filtering is presented for realtime low-dose CT imaging. A
nonstationary Gaussian noise model of low-dose sinogram data is proposed in the
low-mA (tube current) CT protocol. Then, according to the linear minimum mean
square error principle, an adaptive blockwise algorithm is built to filter
contaminated sinogram data caused by photon starvation. A moving sum technique
is used to speed the algorithm into a linear time one, regardless of the block
size and thedata range. The proposedfast filtering givesa better performance in
noise reduction and detail preservation in the reconstructed images,which is
verified in experiments on simulated and real data compared with some related
filtering methods.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 23 Mar 2019]
Residual Pyramid Learning for Single-Shot Semantic Segmentation,"Xiaoyu Chen, Xiaotian Lou, Lianfa Bai, Jing Han","Pixel-level semantic segmentation is a challenging task with a huge amount of
computation, especially if the size of input is large. In the segmentation
model, apart from the feature extraction, the extra decoder structure is often
employed to recover spatial information. In this paper, we put forward a method
for single-shot segmentation in a feature residual pyramid network (RPNet),
which learns the main and residuals of segmentation by decomposing the label at
different levels of residual blocks. Specifically speaking, we use the residual
features to learn the edges and details, and the identity features to learn the
main part of targets. At testing time, the predicted residuals are used to
enhance the details of the top-level prediction. Residual learning blocks split
the network into several shallow sub-networks which facilitates the training of
the RPNet. We then evaluate the proposed method and compare it with recent
state-of-the-art methods on CamVid and Cityscapes. The proposed single-shot
segmentation based on RPNet achieves impressive results with high efficiency on
pixel-level segmentation.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 23 Mar 2019]
Impedance control of a cable-driven SEA with mixed $H_2/H_\infty$ synthesis,"Ningbo Yu, Wulin Zou","Purpose: This paper presents an impedance control method with mixed
$H_2/H_\infty$ synthesis and relaxed passivity for a cable-driven series
elastic actuator to be applied for physical human-robot interaction.
Design/methodology/approach: To shape the system's impedance to match a
desired dynamic model, the impedance control problem was reformulated into an
impedance matching structure. The desired competing performance requirements as
well as constraints from the physical system can be characterized with
weighting functions for respective signals. Considering the frequency
properties of human movements, the passivity constraint for stable human-robot
interaction, which is required on the entire frequency spectrum and may bring
conservative solutions, has been relaxed in such a way that it only restrains
the low frequency band. Thus, impedance control became a mixed $H_2/H_\infty$
synthesis problem, and a dynamic output feedback controller can be obtained.
Findings: The proposed impedance control strategy has been tested for various
desired impedance with both simulation and experiments on the cable-driven
series elastic actuator platform. The actual interaction torque tracked well
the desired torque within the desired norm bounds, and the control input was
regulated below the motor velocity limit. The closed loop system can guarantee
relaxed passivity at low frequency. Both simulation and experimental results
have validated the feasibility and efficacy of the proposed method.
Originality/value: This impedance control strategy with mixed $H_2/H_\infty$
synthesis and relaxed passivity provides a novel, effective and less
conservative method for physical human-robot interaction control.",Robotics (cs.RO),; Systems and Control (eess.SY); Dynamical Systems (math.DS); Optimization and Control (math.OC),[Submitted on 23 Mar 2019]
Passivity guaranteed stiffness control with multiple frequency band specifications for a cable-driven series elastic actuator,"Ningbo Yu, Wulin Zou, Yubo Sun","Impedance control and specifically stiffness control are widely applied for
physical human-robot interaction. The series elastic actuator (SEA) provides
inherent compliance, safety and further benefits. This paper aims to improve
the stiffness control performance of a cable-driven SEA. Existing impedance
controllers were designed within the full frequency domain, though human-robot
interaction commonly falls in the low frequency range. We enhance the stiffness
rendering performance under formulated constraints of passivity, actuator
limitation, disturbance attenuation, noise rejection at their specific
frequency ranges. Firstly, we reformulate this multiple frequency-band
optimization problem into the $H_\infty$ synthesis framework. Then, the
performance goals are quantitatively characterized by respective restricted
frequency-domain specifications as norm bounds. Further, a structured
controller is directly synthesized to satisfy all the competing performance
requirements. Both simulation and experimental results showed that the produced
controller enabled good interaction performance for each desired stiffness
varying from 0 to 1 times of the physical spring constant. Compared with the
passivity-based PID method, the proposed $H_\infty$ synthesis method achieved
more accurate and robust stiffness control performance with guaranteed
passivity.",Robotics (cs.RO),; Systems and Control (eess.SY); Dynamical Systems (math.DS); Optimization and Control (math.OC),[Submitted on 23 Mar 2019]
Trifocal Relative Pose from Lines at Points and its Efficient Solution,"Ricardo Fabbri, Timothy Duff, Hongyi Fan, Margaret Regan, David da Costa de Pinho, Elias Tsigaridas, Charles Wampler, Jonathan Hauenstein, Benjamin Kimia, Anton Leykin, Tomas Pajdla","We present a new minimal problem for relative pose estimation mixing point
features with lines incident at points observed in three views and its
efficient homotopy continuation solver. We demonstrate the generality of the
approach by analyzing and solving an additional problem with mixed point and
line correspondences in three views. The minimal problems include
correspondences of (i) three points and one line and (ii) three points and two
lines through two of the points which is reported and analyzed here for the
first time. These are difficult to solve, as they have 216 and - as shown here
- 312 solutions, but cover important practical situations when line and point
features appear together, e.g., in urban scenes or when observing curves. We
demonstrate that even such difficult problems can be solved robustly using a
suitable homotopy continuation technique and we provide an implementation
optimized for minimal problems that can be integrated into engineering
applications. Our simulated and real experiments demonstrate our solvers in the
camera geometry computation task in structure from motion. We show that new
solvers allow for reconstructing challenging scenes where the standard two-view
initialization of structure from motion fails.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 23 Mar 2019 (v1), last revised 16 Apr 2019 (this version, v3)]"
PML: An Interpreter-Based Access Control Policy Language for Web Services,"Yang Luo, Qingni Shen, Zhonghai Wu","Access control is an important component for web services such as a cloud.
Current clouds tend to design the access control mechanism together with the
policy language on their own. It leads to two issues: (i) a cloud user has to
learn different policy languages to use multiple clouds, and (ii) a cloud
service provider has to customize an authorization mechanism based on its
business requirement, which brings high development cost. In this work, a new
access control policy language called PERM modeling language (PML) is proposed
to express various access control models such as access control list (ACL),
role-based access control (RBAC) and attribute-based access control (ABAC),
etc. PML's enforcement mechanism is designed in an interpreter-on-interpreter
manner, which not only secures the authorization code with sandboxing, but also
extends PML to all programming languages that support Lua. PML is already
adopted by real-world projects such as Intel's RMD, VMware's Dispatch, Orange's
Gobis and so on, which proves PML's usability. The performance evaluation on
OpenStack, CloudStack and Amazon Web Services (AWS) shows PML's enforcement
overhead per request is under 5.9us.",Cryptography and Security (cs.CR),,[Submitted on 23 Mar 2019]
Joint Active User Detection and Channel Estimation in Massive Access Systems Exploiting Reed-Muller Sequences,"Jue Wang, Zhaoyang Zhang, Lajos Hanzo","The requirements to support massive connectivity and low latency in massive
Machine Type Communications (mMTC) bring a huge challenge in the design of its
random access (RA) procedure, which usually calls for efficient joint active
user detection and channel estimation. In this paper, we exploit the vast
sequence space and the beneficial nested structure of the length-$2^m$
second-order Reed-Muller (RM) sequences for designing an efficient RA scheme,
which is capable of reliably detecting multiple active users from the set of
unknown potential users with a size as large as $2^{m(m-1)/2}$, whilst
simultaneously estimating their channel state information as well. Explicitly,
at the transmitter each user is mapped to a specially designed RM sequence,
which facilitates reliable joint sequence detection and channel estimation
based on a single transmission event. To elaborate, as a first step, at the
receiver we exploit the elegant nested structure of the RM sequences using a
layer-by-layer RM detection algorithm for the single-user (single-sequence)
scenario. Then an iterative RM detection and channel estimation algorithm is
conceived for the multi-user (multi-sequence) scenario. As a benefit of the
information exchange between the RM sequence detector and channel estimator, a
compelling performance vs. complexity trade-off is struck, as evidenced both by
our analytical and numerical results.",Information Theory (cs.IT),,[Submitted on 23 Mar 2019]
Photorealistic Style Transfer via Wavelet Transforms,"Jaejun Yoo, Youngjung Uh, Sanghyuk Chun, Byeongkyu Kang, Jung-Woo Ha","Recent style transfer models have provided promising artistic results.
However, given a photograph as a reference style, existing methods are limited
by spatial distortions or unrealistic artifacts, which should not happen in
real photographs. We introduce a theoretically sound correction to the network
architecture that remarkably enhances photorealism and faithfully transfers the
style. The key ingredient of our method is wavelet transforms that naturally
fits in deep networks. We propose a wavelet corrected transfer based on
whitening and coloring transforms (WCT$^2$) that allows features to preserve
their structural information and statistical properties of VGG feature space
during stylization. This is the first and the only end-to-end model that can
stylize a $1024\times1024$ resolution image in 4.7 seconds, giving a pleasing
and photorealistic quality without any post-processing. Last but not least, our
model provides a stable video stylization without temporal constraints. Our
code, generated images, and pre-trained models are all available at
this https URL.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 23 Mar 2019 (v1), last revised 29 Sep 2019 (this version, v2)]"
Scene Understanding for Autonomous Manipulation with Deep Learning,Anh Nguyen,"Over the past few years, deep learning techniques have achieved tremendous
success in many visual understanding tasks such as object detection, image
segmentation, and caption generation. Despite this thriving in computer vision
and natural language processing, deep learning has not yet shown significant
impact in robotics. Due to the gap between theory and application, there are
many challenges when applying the results of deep learning to the real robotic
systems. In this study, our long-term goal is to bridge the gap between
computer vision and robotics by developing visual methods that can be used in
real robots. In particular, this work tackles two fundamental visual problems
for autonomous robotic manipulation: affordance detection and fine-grained
action understanding. Theoretically, we propose different deep architectures to
further improves the state of the art in each problem. Empirically, we show
that the outcomes of our proposed methods can be applied in real robots and
allow them to perform useful manipulation tasks.",Computer Vision and Pattern Recognition (cs.CV),; Robotics (cs.RO),[Submitted on 23 Mar 2019]
TTR-Based Reward for Reinforcement Learning with Implicit Model Priors,"Xubo Lyu, Mo Chen","Model-free reinforcement learning (RL) is a powerful approach for learning
control policies directly from high-dimensional state and observation. However,
it tends to be data-inefficient, which is especially costly in robotic learning
tasks. On the other hand, optimal control does not require data if the system
model is known, but cannot scale to models with high-dimensional states and
observations. To exploit benefits of both model-free RL and optimal control, we
propose time-to-reach-based (TTR-based) reward shaping, an optimal
control-inspired technique to alleviate data inefficiency while retaining
advantages of model-free RL. This is achieved by summarizing key system model
information using a TTR function to greatly speed up the RL process, as shown
in our simulation results. The TTR function is defined as the minimum time
required to move from any state to the goal under assumed system dynamics
constraints. Since the TTR function is computationally intractable for systems
with high-dimensional states, we compute it for approximate, lower-dimensional
system models that still captures key dynamic behaviors. Our approach can be
flexibly and easily incorporated into any model-free RL algorithm without
altering the original algorithm structure, and is compatible with any other
techniques that may facilitate the RL process. We evaluate our approach on two
representative robotic learning tasks and three well-known model-free RL
algorithms, and show significant improvements in data efficiency and
performance.",Robotics (cs.RO),,"[Submitted on 23 Mar 2019 (v1), last revised 13 Oct 2020 (this version, v3)]"
Fast Underwater Image Enhancement for Improved Visual Perception,"Md Jahidul Islam, Youya Xia, Junaed Sattar","In this paper, we present a conditional generative adversarial network-based
model for real-time underwater image enhancement. To supervise the adversarial
training, we formulate an objective function that evaluates the perceptual
image quality based on its global content, color, local texture, and style
information. We also present EUVP, a large-scale dataset of a paired and
unpaired collection of underwater images (of `poor' and `good' quality) that
are captured using seven different cameras over various visibility conditions
during oceanic explorations and human-robot collaborative experiments. In
addition, we perform several qualitative and quantitative evaluations which
suggest that the proposed model can learn to enhance underwater image quality
from both paired and unpaired training. More importantly, the enhanced images
provide improved performances of standard models for underwater object
detection, human pose estimation, and saliency prediction. These results
validate that it is suitable for real-time preprocessing in the autonomy
pipeline by visually-guided underwater robots. The model and associated
training pipelines are available at this https URL.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 23 Mar 2019 (v1), last revised 9 Feb 2020 (this version, v3)]"
Progressive DNN Compression: A Key to Achieve Ultra-High Weight Pruning and Quantization Rates using ADMM,"Shaokai Ye, Xiaoyu Feng, Tianyun Zhang, Xiaolong Ma, Sheng Lin, Zhengang Li, Kaidi Xu, Wujie Wen, Sijia Liu, Jian Tang, Makan Fardad, Xue Lin, Yongpan Liu, Yanzhi Wang","Weight pruning and weight quantization are two important categories of DNN
model compression. Prior work on these techniques are mainly based on
heuristics. A recent work developed a systematic frame-work of DNN weight
pruning using the advanced optimization technique ADMM (Alternating Direction
Methods of Multipliers), achieving one of state-of-art in weight pruning
results. In this work, we first extend such one-shot ADMM-based framework to
guarantee solution feasibility and provide fast convergence rate, and
generalize to weight quantization as well. We have further developed a
multi-step, progressive DNN weight pruning and quantization framework, with
dual benefits of (i) achieving further weight pruning/quantization thanks to
the special property of ADMM regularization, and (ii) reducing the search space
within each step. Extensive experimental results demonstrate the superior
performance compared with prior work. Some highlights: (i) we achieve 246x,36x,
and 8x weight pruning on LeNet-5, AlexNet, and ResNet-50 models, respectively,
with (almost) zero accuracy loss; (ii) even a significant 61x weight pruning in
AlexNet (ImageNet) results in only minor degradation in actual accuracy
compared with prior work; (iii) we are among the first to derive notable weight
pruning results for ResNet and MobileNet models; (iv) we derive the first
lossless, fully binarized (for all layers) LeNet-5 for MNIST and VGG-16 for
CIFAR-10; and (v) we derive the first fully binarized (for all layers) ResNet
for ImageNet with reasonable accuracy loss.",Neural and Evolutionary Computing (cs.NE),; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG),"[Submitted on 23 Mar 2019 (v1), last revised 30 Mar 2019 (this version, v2)]"
Effective Definability of the Reachability Relation in Timed Automata,"Martin Fränzle, Karin Quaas, Mahsa Shirmohammadi, James Worrell","We give a new proof of the result of Comon and Jurski that the binary
reachability relation of a timed automaton is definable in linear arithmetic.",Formal Languages and Automata Theory (cs.FL),,[Submitted on 23 Mar 2019]
Auto-ReID: Searching for a Part-aware ConvNet for Person Re-Identification,"Ruijie Quan, Xuanyi Dong, Yu Wu, Linchao Zhu, Yi Yang","Prevailing deep convolutional neural networks (CNNs) for person
re-IDentification (reID) are usually built upon ResNet or VGG backbones, which
were originally designed for classification. Because reID is different from
classification, the architecture should be modified accordingly. We propose to
automatically search for a CNN architecture that is specifically suitable for
the reID task. There are three aspects to be tackled. First, body structural
information plays an important role in reID but it is not encoded in backbones.
Second, Neural Architecture Search (NAS) automates the process of architecture
design without human effort, but no existing NAS methods incorporate the
structure information of input images. Third, reID is essentially a retrieval
task but current NAS algorithms are merely designed for classification. To
solve these problems, we propose a retrieval-based search algorithm over a
specifically designed reID search space, named Auto-ReID. Our Auto-ReID enables
the automated approach to find an efficient and effective CNN architecture for
reID. Extensive experiments demonstrate that the searched architecture achieves
state-of-the-art performance while reducing 50% parameters and 53% FLOPs
compared to others.",Computer Vision and Pattern Recognition (cs.CV),,"[Submitted on 23 Mar 2019 (v1), last revised 20 Aug 2019 (this version, v4)]"
What Synthesis is Missing: Depth Adaptation Integrated with Weak Supervision for Indoor Scene Parsing,"Keng-Chi Liu, Yi-Ting Shen, Jan P. Klopp, Liang-Gee Chen","Scene Parsing is a crucial step to enable autonomous systems to understand
and interact with their surroundings. Supervised deep learning methods have
made great progress in solving scene parsing problems, however, come at the
cost of laborious manual pixel-level annotation. To alleviate this effort
synthetic data as well as weak supervision have both been investigated.
Nonetheless, synthetically generated data still suffers from severe domain
shift while weak labels are often imprecise. Moreover, most existing works for
weakly supervised scene parsing are limited to salient foreground objects. The
aim of this work is hence twofold: Exploit synthetic data where feasible and
integrate weak supervision where necessary. More concretely, we address this
goal by utilizing depth as transfer domain because its synthetic-to-real
discrepancy is much lower than for color. At the same time, we perform weak
localization from easily obtainable image level labels and integrate both using
a novel contour-based scheme. Our approach is implemented as a teacher-student
learning framework to solve the transfer learning problem by generating a
pseudo ground truth. Using only depth-based adaptation, this approach already
outperforms previous transfer learning approaches on the popular indoor scene
parsing SUN RGB-D dataset. Our proposed two-stage integration more than halves
the gap towards fully supervised methods when compared to previous
state-of-the-art in transfer learning.",Computer Vision and Pattern Recognition (cs.CV),,[Submitted on 23 Mar 2019]
Large-System Analysis of Massive MIMO with Optimal M-MMSE Processing,"Luca Sanguinetti, Emil Björnson, Abla Kammoun","We consider the uplink of a Massive MIMO network with $L$ cells, each
comprising a BS with $M$ antennas and $K$ single-antenna user equipments.
Recently, [1] studied the asymptotic spectral efficiency of such networks with
optimal multicell minimum mean-squared error (M-MMSE) processing when $M\to
\infty$ and $K$ is kept fixed. Remarkably, [1] proved that, for practical
channels with spatial correlation, the spectral efficiency grows unboundedly,
even with pilot contamination. In this paper, we extend the analysis from [1]
to the alternative regime in which $M,K\to \infty$ with a given ratio. Tools
from random matrix theory are used to compute low-complexity approximations
which are proved to be asymptotically tight, but accurate for realistic system
dimensions, as shown by simulations.",Information Theory (cs.IT),,"[Submitted on 23 Mar 2019 (v1), last revised 25 Jun 2019 (this version, v3)]"
